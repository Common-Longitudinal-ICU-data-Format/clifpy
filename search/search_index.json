{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>CLIFpy is a Python package that implements the Common Longitudinal ICU data Format (CLIF) specification. It provides a standardized interface for working with critical care data in the CLIF format, enabling healthcare researchers and data scientists to analyze ICU data across different healthcare systems.</p> <ul> <li> <p>\ud83d\ude80 Getting Started</p> <p>Install with <code>pip</code> and get started with CLIFpy with these tutorials.</p> </li> <li> <p>\ud83d\udcd6 User Guide</p> <p>In depth explanation and discussion of the concepts and working of different features available in CLIFpy.</p> </li> <li> <p>\ud83d\udd28 How-to Guides</p> <p>Practical guides to help you achieve specific goals. Take a look at these guides to learn how to use CLIFpy to solve real-world problems.</p> </li> <li> <p>\ud83d\udcc4 API Reference</p> <p>Technical descriptions of how CLIFpy classes and methods work.</p> </li> </ul>"},{"location":"#license","title":"License","text":"<p>CLIFpy is released under the Apache License 2.0. See the LICENSE file for details.</p>"},{"location":"BaseTable/","title":"BaseTable class for pyCLIF tables.","text":"<p>This module provides the base class that all pyCLIF table classes inherit from. It handles common functionality including data loading, validation, and reporting.</p>"},{"location":"BaseTable/#overview","title":"Overview","text":"<p>The <code>BaseTable</code> class is the foundational component of all table classes in clifpy. It implements the common functionality that every CLIF table needs, following an inheritance pattern where specific tables (patient, hospitalization, adt, etc.) inherit from it.</p>"},{"location":"BaseTable/#design-pattern","title":"Design Pattern","text":"<p>BaseTable implements the Template Method Pattern where: - Common behavior is defined in the base class - Specific behavior is implemented in child classes - Extensibility is provided through method overriding</p>"},{"location":"BaseTable/#core-responsibilities","title":"Core Responsibilities","text":""},{"location":"BaseTable/#1-data-management","title":"1. Data Management","text":"<pre><code># Stores the actual data\nself.df: pd.DataFrame = None\n\n# Configuration\nself.data_directory: str    # Path to data files\nself.filetype: str         # File format (parquet, csv, etc.)\nself.timezone: str         # Timezone for datetime conversions\nself.output_directory: str # Where to save validation outputs\n</code></pre>"},{"location":"BaseTable/#2-schema-management","title":"2. Schema Management","text":"<pre><code># Automatically loads YAML schema based on table name\nself.schema: Dict = None  # Loaded from clifpy/schemas/{table_name}_schema.yaml\n</code></pre>"},{"location":"BaseTable/#3-validation-system","title":"3. Validation System","text":"<pre><code>self.errors: List[Dict] = []  # Stores validation errors and warnings\n</code></pre>"},{"location":"BaseTable/#4-logging-system","title":"4. Logging System","text":"<pre><code>self.logger: logging.Logger  # Per-table logger that writes to output directory\n</code></pre>"},{"location":"BaseTable/#key-methods","title":"Key Methods","text":""},{"location":"BaseTable/#constructor-__init__","title":"Constructor (<code>__init__</code>)","text":"<pre><code>def __init__(\n    self,\n    data_directory: str,\n    filetype: str, \n    timezone: str,\n    output_directory: Optional[str] = None,\n    data: Optional[pd.DataFrame] = None\n)\n</code></pre> <p>Parameters: - <code>data_directory</code>: Path to directory containing data files - <code>filetype</code>: File format (\"parquet\", \"csv\", etc.) - <code>timezone</code>: Timezone for datetime columns (default: \"UTC\")  - <code>output_directory</code>: Where to save validation outputs (optional) - <code>data</code>: Pre-loaded DataFrame (optional)</p> <p>What it does: 1. Stores configuration parameters 2. Sets up output directory (creates if doesn't exist) 3. Determines table name from class name 4. Sets up logging system 5. Loads YAML schema for the table 6. If data provided, automatically runs validation</p>"},{"location":"BaseTable/#class-method-from_file","title":"Class Method: <code>from_file()</code>","text":"<pre><code>@classmethod\ndef from_file(\n    cls,\n    data_directory: str,\n    filetype: str,\n    timezone: str = \"UTC\", \n    output_directory: Optional[str] = None,\n    sample_size: Optional[int] = None,\n    columns: Optional[List[str]] = None,\n    filters: Optional[Dict[str, Any]] = None\n)\n</code></pre> <p>Alternative constructor that loads data from files with additional options: - <code>sample_size</code>: Limit number of rows to load - <code>columns</code>: Only load specific columns - <code>filters</code>: Apply filters during loading</p> <p>Example: <pre><code>patient_table = patient.from_file(\n    data_directory=\"/path/to/data\",\n    filetype=\"parquet\",\n    timezone=\"US/Eastern\",\n    sample_size=1000  # Load only first 1000 rows\n)\n</code></pre></p>"},{"location":"BaseTable/#validation-methods","title":"Validation Methods","text":""},{"location":"BaseTable/#validate","title":"<code>validate()</code>","text":"<p>Runs comprehensive validation on the loaded data: - Schema validation (required columns, data types, categories) - Enhanced validation (missing data, duplicates, statistics) - Table-specific validation (can be overridden by child classes)</p>"},{"location":"BaseTable/#isvalid-bool","title":"<code>isvalid() -&gt; bool</code>","text":"<p>Returns <code>True</code> if no errors were found in the last validation run.</p> <pre><code>if table.isvalid():\n    print(\"\u2705 Data passed all validations!\")\nelse:\n    print(f\"\u274c Found {len(table.errors)} validation issues\")\n</code></pre>"},{"location":"BaseTable/#how-tables-inherit-from-basetable","title":"How Tables Inherit from BaseTable","text":""},{"location":"BaseTable/#basic-inheritance-pattern","title":"Basic Inheritance Pattern","text":"<pre><code>class patient(BaseTable):\n    \"\"\"Patient table with demographic information.\"\"\"\n\n    def __init__(self, data_directory: str = None, filetype: str = None, \n                 timezone: str = \"UTC\", output_directory: Optional[str] = None,\n                 data: Optional[pd.DataFrame] = None):\n        # Handle backward compatibility\n        if data_directory is None and filetype is None and data is not None:\n            data_directory = \".\"\n            filetype = \"parquet\" \n\n        # Call parent constructor\n        super().__init__(\n            data_directory=data_directory,\n            filetype=filetype, \n            timezone=timezone,\n            output_directory=output_directory,\n            data=data\n        )\n\n    # Add patient-specific methods\n    def get_demographics_summary(self):\n        \"\"\"Return demographic breakdown of patients.\"\"\"\n        # Implementation here\n        pass\n</code></pre>"},{"location":"BaseTable/#table-specific-methods","title":"Table-Specific Methods","text":"<p>Child classes can add methods specific to their domain:</p> <pre><code># hospitalization.py\nclass hospitalization(BaseTable):\n    def get_mortality_rate(self) -&gt; float:\n        \"\"\"Calculate in-hospital mortality rate.\"\"\"\n        if 'discharge_category' not in self.df.columns:\n            return 0.0\n        total = len(self.df)\n        expired = len(self.df[self.df['discharge_category'] == 'Expired'])\n        return (expired / total) * 100 if total &gt; 0 else 0.0\n\n    def calculate_length_of_stay(self) -&gt; pd.DataFrame:\n        \"\"\"Calculate length of stay for each hospitalization.\"\"\"\n        # Implementation here\n        pass\n\n# adt.py  \nclass adt(BaseTable):\n    def get_location_categories(self) -&gt; List[str]:\n        \"\"\"Return unique location categories.\"\"\"\n        if 'location_category' not in self.df.columns:\n            return []\n        return self.df['location_category'].dropna().unique().tolist()\n\n    def filter_by_location_category(self, location: str) -&gt; pd.DataFrame:\n        \"\"\"Filter records by location category (e.g., 'icu', 'ward').\"\"\"\n        # Implementation here\n        pass\n</code></pre>"},{"location":"BaseTable/#validation-flow","title":"Validation Flow","text":"<p>When you create a table instance, BaseTable automatically:</p> <ol> <li>Schema Loading: Reads <code>{table_name}_schema.yaml</code> from the schemas directory</li> <li>Logging Setup: Creates log files in the output directory</li> <li>Data Validation (if data provided):</li> <li>\u2705 Required columns - Ensures all mandatory columns are present</li> <li>\u2705 Data types - Validates column data types match schema</li> <li>\u2705 Categorical values - Checks values against permitted categories</li> <li>\u2705 Datetime timezones - Validates timezone-aware datetime columns</li> <li>\u2705 Missing data analysis - Calculates missing data statistics</li> <li>\u2705 Duplicate detection - Checks composite keys for uniqueness</li> <li>\u2705 Statistical analysis - Generates summaries and skewness analysis</li> <li>\u2705 Unit validation - For tables like vitals/labs, validates measurement units</li> <li>\u2705 Numeric ranges - Checks values fall within expected clinical ranges</li> </ol>"},{"location":"BaseTable/#output-files-generated","title":"Output Files Generated","text":"<p>BaseTable creates several files during validation in the output directory:</p> File Type Example Purpose Log files <code>validation_log_patient.log</code> Detailed validation logs with timestamps Missing data <code>missing_data_stats_patient.csv</code> Missing value counts and percentages Statistics <code>summary_statistics_patient.csv</code> Q1, Q3, median for numeric columns Skewness <code>skewness_analysis_patient.csv</code> Distribution analysis for numeric columns Validation errors <code>validation_errors_patient.csv</code> Summary of all validation issues"},{"location":"BaseTable/#usage-examples","title":"Usage Examples","text":""},{"location":"BaseTable/#method-1-direct-instantiation-with-data","title":"Method 1: Direct Instantiation with Data","text":"<pre><code># When you already have a DataFrame\npatient_table = patient(\n    data_directory=\"./data\",      # Required for schema/logging\n    filetype=\"parquet\",           # Required for metadata\n    timezone=\"UTC\",               # Timezone for datetime columns  \n    output_directory=\"./output\",  # Where to save validation files\n    data=my_dataframe            # Your pre-loaded DataFrame\n)\n</code></pre>"},{"location":"BaseTable/#method-2-load-from-file","title":"Method 2: Load from File","text":"<pre><code># Load data from files\npatient_table = patient.from_file(\n    data_directory=\"./data\",\n    filetype=\"parquet\", \n    timezone=\"US/Eastern\",\n    columns=['patient_id', 'age_at_admission', 'sex_category'],  # Only load specific columns\n    sample_size=5000  # Only load first 5000 rows\n)\n</code></pre>"},{"location":"BaseTable/#method-3-demo-data-recommended-for-learning","title":"Method 3: Demo Data (Recommended for Learning)","text":"<pre><code># Use built-in demo datasets\nfrom clifpy.data import load_demo_patient\n\npatient_table = load_demo_patient()  # Uses Method 1 internally\n</code></pre>"},{"location":"BaseTable/#all-methods-result-in-same-capabilities","title":"All Methods Result in Same Capabilities:","text":"<pre><code># Check validation status\nprint(f\"Valid: {patient_table.isvalid()}\")\nprint(f\"Errors: {len(patient_table.errors)}\")  \nprint(f\"Records: {len(patient_table.df)}\")\n\n# Access the data\ndf = patient_table.df\nprint(df.head())\n\n# Use table-specific methods (if implemented)\nif hasattr(patient_table, 'get_demographics_summary'):\n    demographics = patient_table.get_demographics_summary()\n</code></pre>"},{"location":"BaseTable/#benefits-of-this-design","title":"Benefits of This Design","text":""},{"location":"BaseTable/#1-code-reuse","title":"1. Code Reuse","text":"<ul> <li>All tables get validation, logging, and schema loading automatically</li> <li>No duplicate code across table implementations</li> <li>Consistent behavior across all table types</li> </ul>"},{"location":"BaseTable/#2-consistency","title":"2. Consistency","text":"<ul> <li>Same API across all table types: <code>validate()</code>, <code>isvalid()</code>, <code>from_file()</code></li> <li>Standardized output file formats and naming conventions</li> <li>Uniform error handling and logging</li> </ul>"},{"location":"BaseTable/#3-extensibility","title":"3. Extensibility","text":"<ul> <li>Easy to add new tables by inheriting from BaseTable</li> <li>Can override specific methods for table-specific behavior</li> <li>Template method pattern allows customization while preserving structure</li> </ul>"},{"location":"BaseTable/#4-separation-of-concerns","title":"4. Separation of Concerns","text":"<ul> <li>BaseTable: Infrastructure (validation, logging, I/O, schema management)</li> <li>Child classes: Domain-specific methods and business logic</li> <li>Validator module: Reusable validation functions</li> <li>Schema files: Data structure definitions</li> </ul>"},{"location":"BaseTable/#5-maintainability","title":"5. Maintainability","text":"<ul> <li>Changes to validation logic automatically apply to all tables</li> <li>Schema changes are managed in separate YAML files  </li> <li>Logging and error handling centralized in one place</li> </ul>"},{"location":"BaseTable/#advanced-features","title":"Advanced Features","text":""},{"location":"BaseTable/#custom-validation","title":"Custom Validation","text":"<p>Tables can override validation methods for specific requirements:</p> <pre><code>class vitals(BaseTable):\n    def _run_table_specific_validations(self):\n        \"\"\"Add vitals-specific validation rules.\"\"\"\n        super()._run_table_specific_validations()\n\n        # Custom validation for vital signs ranges\n        if 'vital_category' in self.df.columns and 'vital_value' in self.df.columns:\n            # Check for physiologically impossible values\n            extreme_values = self.df[\n                (self.df['vital_category'] == 'heart_rate') &amp; \n                ((self.df['vital_value'] &lt; 0) | (self.df['vital_value'] &gt; 300))\n            ]\n            if not extreme_values.empty:\n                self.errors.append({\n                    \"type\": \"extreme_vital_values\",\n                    \"message\": f\"Found {len(extreme_values)} extreme heart rate values\",\n                    \"count\": len(extreme_values)\n                })\n</code></pre>"},{"location":"BaseTable/#custom-output-methods","title":"Custom Output Methods","text":"<pre><code>class hospitalization(BaseTable):\n    def save_mortality_report(self, filename: str = None):\n        \"\"\"Save detailed mortality analysis to file.\"\"\"\n        if filename is None:\n            filename = os.path.join(self.output_directory, f'mortality_report_{self.table_name}.csv')\n\n        mortality_data = self.analyze_mortality_by_demographics()\n        mortality_data.to_csv(filename, index=False)\n        self.logger.info(f\"Saved mortality report to {filename}\")\n</code></pre>"},{"location":"BaseTable/#best-practices","title":"Best Practices","text":""},{"location":"BaseTable/#1-when-to-inherit-from-basetable","title":"1. When to Inherit from BaseTable","text":"<ul> <li>\u2705 Always for CLIF table implementations</li> <li>\u2705 When you need validation and schema management</li> <li>\u2705 For tables that will be used in production workflows</li> </ul>"},{"location":"BaseTable/#2-method-naming-conventions","title":"2. Method Naming Conventions","text":"<ul> <li>Use descriptive names: <code>get_mortality_rate()</code> not <code>mortality()</code></li> <li>Follow existing patterns: <code>filter_by_*()</code>, <code>get_*()</code>, <code>calculate_*()</code></li> <li>Return appropriate types: DataFrames for subsets, numbers for metrics</li> </ul>"},{"location":"BaseTable/#3-error-handling","title":"3. Error Handling","text":"<pre><code>def custom_method(self):\n    \"\"\"Custom analysis method with proper error handling.\"\"\"\n    try:\n        if self.df is None or self.df.empty:\n            self.logger.warning(\"No data available for analysis\")\n            return None\n\n        # Your analysis here\n        result = self.df.groupby('category').mean()\n\n        self.logger.info(f\"Analysis completed successfully with {len(result)} groups\")\n        return result\n\n    except Exception as e:\n        self.logger.error(f\"Analysis failed: {str(e)}\")\n        return None\n</code></pre>"},{"location":"BaseTable/#future-enhancements","title":"Future Enhancements","text":"<p>The BaseTable design supports future enhancements such as:</p> <ul> <li>Caching: Store validation results to avoid re-computation</li> <li>Streaming: Handle large datasets that don't fit in memory  </li> <li>Parallel processing: Run validation checks in parallel</li> <li>Custom validators: Plugin system for domain-specific validation rules</li> <li>Data lineage: Track data transformations and sources</li> <li>Version control: Schema versioning and migration support</li> </ul>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to CLIFpy will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#unreleased","title":"Unreleased","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Comprehensive documentation with MkDocs</li> <li>Enhanced docstrings for all modules and classes</li> <li>API reference documentation</li> <li>User guide and examples</li> </ul>"},{"location":"changelog/#001-2024-01-xx","title":"0.0.1 - 2024-01-XX","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>Initial release of CLIFpy</li> <li>Core implementation of CLIF 2.0.0 specification</li> <li>All 9 CLIF table implementations:</li> <li>Patient demographics</li> <li>ADT (Admission, Discharge, Transfer)</li> <li>Hospitalization</li> <li>Laboratory results</li> <li>Vital signs</li> <li>Respiratory support</li> <li>Continuous medication administration</li> <li>Patient assessments</li> <li>Patient positioning</li> <li>Data validation against mCIDE schemas</li> <li>Timezone handling and conversion</li> <li>ClifOrchestrator for multi-table management</li> <li>Comprehensive test suite</li> <li>Demo dataset based on MIMIC-IV</li> <li>Example notebooks</li> </ul>"},{"location":"changelog/#features","title":"Features","text":"<ul> <li>Load data from CSV or Parquet files</li> <li>Schema-based validation</li> <li>Advanced filtering and querying</li> <li>Clinical calculations</li> <li>Summary statistics and reporting</li> <li>Memory-efficient data loading options</li> </ul>"},{"location":"contributing/","title":"Contributing to CLIFpy","text":"<p>We welcome contributions to CLIFpy! This guide will help you get started.</p>"},{"location":"contributing/#getting-started","title":"Getting Started","text":"<ol> <li>Fork the repository on GitHub</li> <li>Clone your fork locally:    <pre><code>git clone https://github.com/YOUR_USERNAME/CLIFpy.git\ncd CLIFpy\n</code></pre></li> <li>Create a virtual environment:    <pre><code>python -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n</code></pre></li> <li>Install in development mode with all dependencies:    <pre><code>pip install -e \".[docs]\"\n</code></pre></li> </ol>"},{"location":"contributing/#development-workflow","title":"Development Workflow","text":"<ol> <li> <p>Create a new branch for your feature or fix:    <pre><code>git checkout -b feature/your-feature-name\n</code></pre></p> </li> <li> <p>Make your changes and ensure:</p> </li> <li>Code follows the existing style</li> <li>All tests pass</li> <li>New features include tests</li> <li> <p>Documentation is updated</p> </li> <li> <p>Run tests:    <pre><code>pytest tests/\n</code></pre></p> </li> <li> <p>Commit your changes:    <pre><code>git add .\ngit commit -m \"feat: add new feature\"\n</code></pre></p> </li> <li> <p>Push to your fork:    <pre><code>git push origin feature/your-feature-name\n</code></pre></p> </li> <li> <p>Create a Pull Request on GitHub</p> </li> </ol>"},{"location":"contributing/#code-style","title":"Code Style","text":"<ul> <li>Follow PEP 8 guidelines</li> <li>Use meaningful variable and function names</li> <li>Add type hints where appropriate</li> <li>Include docstrings for all public functions and classes</li> </ul>"},{"location":"contributing/#documentation","title":"Documentation","text":"<ul> <li>Update docstrings for any API changes</li> <li>Add examples to docstrings where helpful</li> <li>Update user guide if adding new features</li> <li>Build docs locally to verify:   <pre><code>mkdocs serve\n</code></pre></li> </ul>"},{"location":"contributing/#testing","title":"Testing","text":"<ul> <li>Write tests for new functionality</li> <li>Ensure all tests pass before submitting PR</li> <li>Aim for high test coverage</li> <li>Use pytest fixtures for common test data</li> </ul>"},{"location":"contributing/#commit-messages","title":"Commit Messages","text":"<p>Follow conventional commits format: - <code>feat:</code> - New feature - <code>fix:</code> - Bug fix - <code>docs:</code> - Documentation changes - <code>test:</code> - Test additions or changes - <code>refactor:</code> - Code refactoring - <code>chore:</code> - Maintenance tasks</p>"},{"location":"contributing/#questions","title":"Questions?","text":"<ul> <li>Open an issue for bugs or feature requests</li> <li>Join discussions in existing issues</li> <li>Reach out to maintainers if you need help</li> </ul> <p>Thank you for contributing to CLIFpy!</p>"},{"location":"wide_dataset/","title":"Wide Dataset Creation with pyCLIF","text":"<p>The pyCLIF library now includes powerful functionality for creating wide datasets by joining multiple CLIF tables with automatic pivoting of category-based data. This feature is designed to replicate and enhance the sophisticated wide dataset creation logic from the original notebook while making it reusable and configurable.</p>"},{"location":"wide_dataset/#overview","title":"Overview","text":"<p>The wide dataset functionality allows you to: - Automatically join multiple CLIF tables (patient, hospitalization, ADT, and optional tables) - Pivot category-based data from vitals, labs, medications, and assessments - Sample or filter hospitalizations for targeted analysis - Handle time-based alignment of events across different tables - Save results in multiple formats (DataFrame, CSV, Parquet)</p>"},{"location":"wide_dataset/#quick-start","title":"Quick Start","text":"<pre><code>from pyclif import CLIF\n\n# Initialize with your data\nclif = CLIF(\n    data_dir=\"/path/to/CLIF_data\",\n    filetype='parquet',\n    timezone=\"US/Eastern\"\n)\n\n# Create a wide dataset (tables auto-loaded as needed)\nwide_df = clif.create_wide_dataset(\n    optional_tables=['vitals', 'labs'],\n    category_filters={\n        'vitals': ['map', 'heart_rate', 'spo2'],\n        'labs': ['hemoglobin', 'wbc', 'sodium']\n    },\n    sample=True  # 20 random hospitalizations\n)\n</code></pre>"},{"location":"wide_dataset/#core-functionality","title":"Core Functionality","text":""},{"location":"wide_dataset/#base-tables-always-included","title":"Base Tables (Always Included)","text":"<ul> <li>patient: Demographics and patient information</li> <li>hospitalization: Admission/discharge details</li> <li>adt: Admission, discharge, and transfer events</li> </ul>"},{"location":"wide_dataset/#optional-tables-user-specified","title":"Optional Tables (User-Specified)","text":"<ul> <li>vitals: Vital signs (pivoted by <code>vital_category</code>)</li> <li>labs: Laboratory results (pivoted by <code>lab_category</code>)</li> <li>medication_admin_continuous: Continuous medications (pivoted by <code>med_category</code>)</li> <li>patient_assessments: Clinical assessments (pivoted by <code>assessment_category</code>)</li> <li>respiratory_support: Respiratory support data</li> </ul>"},{"location":"wide_dataset/#parameters","title":"Parameters","text":""},{"location":"wide_dataset/#create_wide_dataset-parameters","title":"<code>create_wide_dataset()</code> Parameters","text":"Parameter Type Default Description <code>optional_tables</code> List[str] None List of optional tables to include <code>category_filters</code> Dict[str, List[str]] None Categories to pivot for each table <code>sample</code> bool False If True, randomly select 20 hospitalizations <code>hospitalization_ids</code> List[str] None Specific hospitalization IDs to include <code>output_format</code> str 'dataframe' Output format: 'dataframe', 'csv', 'parquet' <code>save_to_data_location</code> bool False Save output to data directory <code>output_filename</code> str None Custom filename (auto-generated if None) <code>auto_load</code> bool True Automatically load missing tables"},{"location":"wide_dataset/#usage-examples","title":"Usage Examples","text":""},{"location":"wide_dataset/#example-1-sample-mode","title":"Example 1: Sample Mode","text":"<p>Create a wide dataset with 20 random hospitalizations:</p> <pre><code>wide_df = clif.create_wide_dataset(\n    optional_tables=['vitals', 'labs'],\n    category_filters={\n        'vitals': ['map', 'heart_rate', 'spo2', 'respiratory_rate'],\n        'labs': ['hemoglobin', 'wbc', 'sodium', 'potassium']\n    },\n    sample=True,\n    save_to_data_location=True,\n    output_format='parquet'\n)\n</code></pre>"},{"location":"wide_dataset/#example-2-specific-hospitalizations","title":"Example 2: Specific Hospitalizations","text":"<p>Target specific encounters for analysis:</p> <pre><code>target_ids = ['12345', '67890', '11111']\nwide_df = clif.create_wide_dataset(\n    hospitalization_ids=target_ids,\n    optional_tables=['medication_admin_continuous', 'patient_assessments'],\n    category_filters={\n        'medication_admin_continuous': ['norepinephrine', 'propofol', 'fentanyl'],\n        'patient_assessments': ['gcs_total', 'rass', 'sbt_delivery_pass_fail']\n    },\n    output_filename='targeted_encounters'\n)\n</code></pre>"},{"location":"wide_dataset/#example-3-comprehensive-dataset","title":"Example 3: Comprehensive Dataset","text":"<p>Create a full wide dataset with all optional tables:</p> <pre><code>wide_df = clif.create_wide_dataset(\n    optional_tables=['vitals', 'labs', 'medication_admin_continuous', 'patient_assessments'],\n    category_filters={\n        'vitals': ['map', 'heart_rate', 'spo2', 'respiratory_rate', 'temp_c'],\n        'labs': ['hemoglobin', 'wbc', 'sodium', 'potassium', 'creatinine'],\n        'medication_admin_continuous': ['norepinephrine', 'epinephrine', 'propofol'],\n        'patient_assessments': ['gcs_total', 'rass', 'sbt_delivery_pass_fail']\n    },\n    save_to_data_location=True\n)\n</code></pre>"},{"location":"wide_dataset/#available-categories","title":"Available Categories","text":""},{"location":"wide_dataset/#vitals-categories","title":"Vitals Categories","text":"<p>Common vital sign categories include: - <code>map</code>, <code>heart_rate</code>, <code>sbp</code>, <code>dbp</code>, <code>spo2</code>, <code>respiratory_rate</code>, <code>temp_c</code>, <code>weight_kg</code>, <code>height_cm</code></p>"},{"location":"wide_dataset/#labs-categories","title":"Labs Categories","text":"<p>Common laboratory categories include: - <code>hemoglobin</code>, <code>wbc</code>, <code>sodium</code>, <code>potassium</code>, <code>creatinine</code>, <code>bun</code>, <code>glucose</code>, <code>lactate</code></p>"},{"location":"wide_dataset/#medication-categories","title":"Medication Categories","text":"<p>Common continuous medication categories include: - <code>norepinephrine</code>, <code>epinephrine</code>, <code>phenylephrine</code>, <code>vasopressin</code>, <code>dopamine</code> - <code>propofol</code>, <code>fentanyl</code>, <code>midazolam</code>, <code>lorazepam</code>, <code>morphine</code></p>"},{"location":"wide_dataset/#assessment-categories","title":"Assessment Categories","text":"<p>Common assessment categories include: - <code>gcs_total</code>, <code>rass</code>, <code>sbt_delivery_pass_fail</code>, <code>sat_delivery_pass_fail</code> - <code>sbt_screen_pass_fail</code>, <code>sat_screen_pass_fail</code></p>"},{"location":"wide_dataset/#output-structure","title":"Output Structure","text":"<p>The resulting wide dataset includes:</p>"},{"location":"wide_dataset/#core-columns","title":"Core Columns","text":"<ul> <li>Patient demographics (<code>patient_id</code>, <code>sex_category</code>, <code>race_category</code>, etc.)</li> <li>Hospitalization details (<code>hospitalization_id</code>, <code>admission_dttm</code>, <code>discharge_dttm</code>, etc.)</li> <li>Event timing (<code>event_time</code>, <code>day_number</code>, <code>hosp_id_day_key</code>)</li> <li>Location information (from ADT table)</li> </ul>"},{"location":"wide_dataset/#pivoted-columns","title":"Pivoted Columns","text":"<ul> <li>Individual columns for each specified category (e.g., <code>map</code>, <code>heart_rate</code>, <code>norepinephrine</code>)</li> <li>Values aligned by timestamp and hospitalization</li> </ul>"},{"location":"wide_dataset/#time-based-features","title":"Time-Based Features","text":"<ul> <li><code>day_number</code>: Sequential day number within each hospitalization</li> <li><code>hosp_id_day_key</code>: Unique identifier combining hospitalization and day</li> <li><code>event_time</code>: Timestamp for each record</li> </ul>"},{"location":"wide_dataset/#auto-loading-feature","title":"Auto-Loading Feature","text":"<p>The function automatically loads required tables if they haven't been loaded yet:</p> <pre><code># No need to manually load tables\nclif = CLIF(data_dir=\"/path/to/data\", filetype='parquet')\n\n# Tables will be auto-loaded as needed\nwide_df = clif.create_wide_dataset(\n    optional_tables=['vitals', 'labs']  # These will be loaded automatically\n)\n</code></pre>"},{"location":"wide_dataset/#error-handling","title":"Error Handling","text":"<p>The function includes robust error handling:</p> <ul> <li>Missing tables: Warns and skips if optional tables aren't available</li> <li>Missing columns: Handles alternative timestamp column names</li> <li>Missing categories: Adds NaN columns for standard assessments/medications</li> <li>Empty data: Gracefully handles cases where no data remains after filtering</li> </ul>"},{"location":"wide_dataset/#performance-considerations","title":"Performance Considerations","text":""},{"location":"wide_dataset/#memory-optimization","title":"Memory Optimization","text":"<ul> <li>Use <code>sample=True</code> for testing and development</li> <li>Specify <code>hospitalization_ids</code> for targeted analysis</li> <li>Use <code>category_filters</code> to limit pivoted columns</li> </ul>"},{"location":"wide_dataset/#output-management","title":"Output Management","text":"<ul> <li>Use <code>save_to_data_location=True</code> for large datasets</li> <li>Choose <code>output_format='parquet'</code> for better compression</li> <li>Set <code>output_format='dataframe'</code> only for immediate analysis</li> </ul>"},{"location":"wide_dataset/#implementation-details","title":"Implementation Details","text":""},{"location":"wide_dataset/#temporal-alignment","title":"Temporal Alignment","text":"<p>The function creates a unified timeline by: 1. Collecting all unique timestamps from included tables 2. Creating a cartesian product of hospitalizations \u00d7 timestamps 3. Joining table-specific data based on matching timestamps</p>"},{"location":"wide_dataset/#pivoting-logic","title":"Pivoting Logic","text":"<p>Category-based tables are pivoted using DuckDB for performance: - Creates unique combination IDs (<code>hospitalization_id_YYYYMMDDHHMM</code>) - Pivots on category columns using <code>PIVOT</code> SQL operation - Handles missing values and duplicate timestamps</p>"},{"location":"wide_dataset/#data-integration","title":"Data Integration","text":"<p>Tables are joined using a combination of: - Hospitalization IDs for patient-level data - Timestamp-based combo IDs for time-series data - Left joins to preserve all timestamps</p>"},{"location":"wide_dataset/#best-practices","title":"Best Practices","text":"<ol> <li>Start Small: Use <code>sample=True</code> for initial testing</li> <li>Filter Categories: Specify only needed categories to reduce memory usage</li> <li>Save Large Datasets: Use file output for datasets &gt; 1GB</li> <li>Check Data Quality: Validate timestamp alignment and missing values</li> <li>Document Choices: Record which categories and filters were used</li> </ol>"},{"location":"wide_dataset/#troubleshooting","title":"Troubleshooting","text":""},{"location":"wide_dataset/#common-issues","title":"Common Issues","text":"<p>Memory Errors <pre><code># Use sampling or filtering\nwide_df = clif.create_wide_dataset(sample=True)  # or\nwide_df = clif.create_wide_dataset(hospitalization_ids=small_list)\n</code></pre></p> <p>Missing Columns <pre><code># Check available categories in your data first\nprint(clif.vitals.df['vital_category'].unique())\n</code></pre></p> <p>Empty Results <pre><code># Verify data exists for your filters\nprint(clif.hospitalization.df['hospitalization_id'].nunique())\n</code></pre></p>"},{"location":"wide_dataset/#integration-with-existing-workflow","title":"Integration with Existing Workflow","text":"<p>The wide dataset function is designed to integrate seamlessly with existing pyCLIF workflows:</p> <pre><code># Traditional approach\nclif = CLIF(data_dir=\"/path/to/data\")\nclif.initialize(['patient', 'vitals', 'labs'])\n\n# Enhanced with wide dataset\nwide_df = clif.create_wide_dataset(\n    optional_tables=['vitals', 'labs'],\n    category_filters={'vitals': ['map'], 'labs': ['hemoglobin']}\n)\n\n# Continue with analysis\nanalysis_results = analyze_wide_dataset(wide_df)\n</code></pre> <p>This functionality brings the power of the original notebook's wide dataset creation into a reusable, configurable, and robust function that can be easily integrated into any pyCLIF workflow.</p>"},{"location":"api/","title":"API Reference","text":"<p>This section contains the complete API documentation for CLIFpy, automatically generated from the source code docstrings.</p>"},{"location":"api/#core-components","title":"Core Components","text":""},{"location":"api/#cliforchestrator","title":"ClifOrchestrator","text":"<p>The main orchestration class for managing multiple CLIF tables with consistent configuration.</p>"},{"location":"api/#basetable","title":"BaseTable","text":"<p>The base class that all CLIF table implementations inherit from, providing common functionality for data loading, validation, and reporting.</p>"},{"location":"api/#table-classes","title":"Table Classes","text":""},{"location":"api/#tables-overview","title":"Tables Overview","text":"<p>Complete API documentation for all CLIF table implementations:</p> <ul> <li>Patient - Patient demographics and identification</li> <li>Adt - Admission, discharge, and transfer events  </li> <li>Hospitalization - Hospital stay information</li> <li>Labs - Laboratory test results</li> <li>Vitals - Vital signs measurements</li> <li>RespiratorySupport - Ventilation and oxygen therapy</li> <li>MedicationAdminContinuous - Continuous medication infusions</li> <li>PatientAssessments - Clinical assessment scores</li> <li>Position - Patient positioning data</li> </ul>"},{"location":"api/#utilities","title":"Utilities","text":""},{"location":"api/#utility-functions","title":"Utility Functions","text":"<p>Helper functions for data loading, validation, and I/O operations:</p> <ul> <li>io - Data loading utilities</li> <li>validator - Data validation functions</li> </ul>"},{"location":"api/#quick-links","title":"Quick Links","text":"<ul> <li>ClifOrchestrator API - Multi-table management</li> <li>BaseTable API - Common table functionality</li> <li>Table Classes API - Individual table implementations</li> <li>Utilities API - Helper functions</li> </ul>"},{"location":"api/#usage-example","title":"Usage Example","text":"<pre><code>from clifpy.clif_orchestrator import ClifOrchestrator\nfrom clifpy.tables import Patient, Labs, Vitals\n\n# Using the orchestrator\norchestrator = ClifOrchestrator(\n    data_directory='/path/to/data',\n    filetype='parquet',\n    timezone='US/Central'\n)\norchestrator.initialize(tables=['patient', 'labs', 'vitals'])\n\n# Using individual tables\npatient = Patient.from_file('/path/to/data', 'parquet')\npatient.validate()\n</code></pre>"},{"location":"api/base-table/","title":"BaseTable","text":""},{"location":"api/base-table/#clifpy.tables.base_table.BaseTable","title":"clifpy.tables.base_table.BaseTable","text":"<pre><code>BaseTable(\n    data_directory,\n    filetype,\n    timezone,\n    output_directory=None,\n    data=None,\n)\n</code></pre> <p>Base class for all pyCLIF table classes.</p> <p>Provides common functionality for loading data, running validations, and generating reports. All table-specific classes should inherit from this.</p> <p>Attributes:</p> Name Type Description <code>data_directory</code> <code>str</code> <p>Path to the directory containing data files</p> <code>filetype</code> <code>str</code> <p>Type of data file (csv, parquet, etc.)</p> <code>timezone</code> <code>str</code> <p>Timezone for datetime columns</p> <code>output_directory</code> <code>str</code> <p>Directory for saving output files and logs</p> <code>table_name</code> <code>str</code> <p>Name of the table (from class name)</p> <code>df</code> <code>DataFrame</code> <p>The loaded data</p> <code>schema</code> <code>dict</code> <p>The YAML schema for this table</p> <code>errors</code> <code>List[dict]</code> <p>Validation errors from last validation run</p> <code>logger</code> <code>Logger</code> <p>Logger for this table</p> <p>Initialize the BaseTable.</p> <p>Parameters:</p> Name Type Description Default <code>data_directory</code> <code>str</code> <p>Path to the directory containing data files</p> required <code>filetype</code> <code>str</code> <p>Type of data file (csv, parquet, etc.)</p> required <code>timezone</code> <code>str</code> <p>Timezone for datetime columns</p> required <code>output_directory</code> <code>str</code> <p>Directory for saving output files and logs. If not provided, creates an 'output' directory in the current working directory.</p> <code>None</code> <code>data</code> <code>DataFrame</code> <p>Pre-loaded data to use instead of loading from file</p> <code>None</code> Source code in <code>clifpy/tables/base_table.py</code> <pre><code>def __init__(\n    self, \n    data_directory: str,\n    filetype: str,\n    timezone: str,\n    output_directory: Optional[str] = None,\n    data: Optional[pd.DataFrame] = None\n):\n    \"\"\"\n    Initialize the BaseTable.\n\n    Parameters:\n        data_directory (str): Path to the directory containing data files\n        filetype (str): Type of data file (csv, parquet, etc.)\n        timezone (str): Timezone for datetime columns\n        output_directory (str, optional): Directory for saving output files and logs.\n            If not provided, creates an 'output' directory in the current working directory.\n        data (pd.DataFrame, optional): Pre-loaded data to use instead of loading from file\n    \"\"\"\n    # Store configuration\n    self.data_directory = data_directory\n    self.filetype = filetype\n    self.timezone = timezone\n\n    # Set output directory\n    if output_directory is None:\n        output_directory = os.path.join(os.getcwd(), 'output')\n    self.output_directory = output_directory\n    os.makedirs(self.output_directory, exist_ok=True)\n\n    # Derive snake_case table name from PascalCase class name\n    # Example: Adt -&gt; adt, RespiratorySupport -&gt; respiratory_support\n    self.table_name = ''.join(['_' + c.lower() if c.isupper() else c for c in self.__class__.__name__]).lstrip('_')\n\n    # Initialize data and validation state\n    self.df: Optional[pd.DataFrame] = data\n    self.errors: List[Dict[str, Any]] = []\n    self.schema: Optional[Dict[str, Any]] = None\n    self._validated: bool = False\n\n    # Setup logging\n    self._setup_logging()\n\n    # Load schema\n    self._load_schema()\n</code></pre>"},{"location":"api/base-table/#clifpy.tables.base_table.BaseTable.from_file","title":"from_file  <code>classmethod</code>","text":"<pre><code>from_file(\n    data_directory,\n    filetype,\n    timezone=\"UTC\",\n    output_directory=None,\n    sample_size=None,\n    columns=None,\n    filters=None,\n)\n</code></pre> <p>Load data from file and create a table instance.</p> <p>Parameters:</p> Name Type Description Default <code>data_directory</code> <code>str</code> <p>Path to the directory containing data files</p> required <code>filetype</code> <code>str</code> <p>Type of data file (csv, parquet, etc.)</p> required <code>timezone</code> <code>str</code> <p>Timezone for datetime columns (default: UTC)</p> <code>'UTC'</code> <code>output_directory</code> <code>str</code> <p>Directory for saving output files and logs</p> <code>None</code> <code>sample_size</code> <code>int</code> <p>Number of rows to load</p> <code>None</code> <code>columns</code> <code>List[str]</code> <p>Specific columns to load</p> <code>None</code> <code>filters</code> <code>Dict</code> <p>Filters to apply when loading</p> <code>None</code> <p>Returns:</p> Type Description <p>Instance of the table class with loaded data</p> Source code in <code>clifpy/tables/base_table.py</code> <pre><code>@classmethod\ndef from_file(\n    cls, \n    data_directory: str,\n    filetype: str,\n    timezone: str = \"UTC\",\n    output_directory: Optional[str] = None,\n    sample_size: Optional[int] = None,\n    columns: Optional[List[str]] = None,\n    filters: Optional[Dict[str, Any]] = None\n):\n    \"\"\"\n    Load data from file and create a table instance.\n\n    Parameters:\n        data_directory (str): Path to the directory containing data files\n        filetype (str): Type of data file (csv, parquet, etc.)\n        timezone (str): Timezone for datetime columns (default: UTC)\n        output_directory (str, optional): Directory for saving output files and logs\n        sample_size (int, optional): Number of rows to load\n        columns (List[str], optional): Specific columns to load\n        filters (Dict, optional): Filters to apply when loading\n\n    Returns:\n        Instance of the table class with loaded data\n    \"\"\"\n    # Derive snake_case table name from PascalCase class name\n    table_name = ''.join(['_' + c.lower() if c.isupper() else c for c in cls.__name__]).lstrip('_')\n\n    # Load data using existing io utility\n    data = load_data(\n        table_name, \n        data_directory, \n        filetype, \n        sample_size=sample_size,\n        columns=columns,\n        filters=filters,\n        site_tz=timezone\n    )\n\n    # Create instance with loaded data\n    return cls(\n        data_directory=data_directory,\n        filetype=filetype,\n        timezone=timezone,\n        output_directory=output_directory,\n        data=data\n    )\n</code></pre>"},{"location":"api/base-table/#clifpy.tables.base_table.BaseTable.get_summary","title":"get_summary","text":"<pre><code>get_summary()\n</code></pre> <p>Get a summary of the table data.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>Dict[str, Any]</code> <p>Summary statistics and information about the table</p> Source code in <code>clifpy/tables/base_table.py</code> <pre><code>def get_summary(self) -&gt; Dict[str, Any]:\n    \"\"\"\n    Get a summary of the table data.\n\n    Returns:\n        dict: Summary statistics and information about the table\n    \"\"\"\n    if self.df is None:\n        return {\"status\": \"No data loaded\"}\n\n    summary = {\n        \"table_name\": self.table_name,\n        \"num_rows\": len(self.df),\n        \"num_columns\": len(self.df.columns),\n        \"columns\": list(self.df.columns),\n        \"memory_usage_mb\": self.df.memory_usage(deep=True).sum() / 1024 / 1024,\n        \"validation_run\": self._validated,\n        \"validation_errors\": len(self.errors) if self._validated else None,\n        \"is_valid\": self.isvalid()\n    }\n\n    # Add basic statistics for numeric columns\n    numeric_cols = self.df.select_dtypes(include=['number']).columns\n    if len(numeric_cols) &gt; 0:\n        summary[\"numeric_columns\"] = list(numeric_cols)\n        summary[\"numeric_stats\"] = self.df[numeric_cols].describe().to_dict()\n\n    # Add missing data summary\n    missing_counts = self.df.isnull().sum()\n    if missing_counts.any():\n        summary[\"missing_data\"] = missing_counts[missing_counts &gt; 0].to_dict()\n\n    return summary\n</code></pre>"},{"location":"api/base-table/#clifpy.tables.base_table.BaseTable.isvalid","title":"isvalid","text":"<pre><code>isvalid()\n</code></pre> <p>Check if the data is valid based on the last validation run.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if validation has been run and no errors were found,   False if validation found errors or hasn't been run yet</p> Source code in <code>clifpy/tables/base_table.py</code> <pre><code>def isvalid(self) -&gt; bool:\n    \"\"\"\n    Check if the data is valid based on the last validation run.\n\n    Returns:\n        bool: True if validation has been run and no errors were found,\n              False if validation found errors or hasn't been run yet\n    \"\"\"\n    if not self._validated:\n        print(\"Validation has not been run yet. Please call validate() first.\")\n        return False\n    return not self.errors\n</code></pre>"},{"location":"api/base-table/#clifpy.tables.base_table.BaseTable.save_summary","title":"save_summary","text":"<pre><code>save_summary()\n</code></pre> <p>Save table summary to a JSON file.</p> Source code in <code>clifpy/tables/base_table.py</code> <pre><code>def save_summary(self):\n    \"\"\"Save table summary to a JSON file.\"\"\"\n    try:\n        import json\n\n        summary = self.get_summary()\n\n        # Save to JSON\n        summary_file = os.path.join(\n            self.output_directory,\n            f'summary_{self.table_name}.json'\n        )\n\n        with open(summary_file, 'w') as f:\n            json.dump(summary, f, indent=2, default=str)\n\n        self.logger.info(f\"Saved summary to {summary_file}\")\n\n    except Exception as e:\n        self.logger.error(f\"Error saving summary: {str(e)}\")\n</code></pre>"},{"location":"api/base-table/#clifpy.tables.base_table.BaseTable.validate","title":"validate","text":"<pre><code>validate()\n</code></pre> <p>Run comprehensive validation on the data.</p> <p>This method runs all validation checks including: - Schema validation (required columns, data types, categories) - Missing data analysis - Duplicate checking - Statistical analysis - Table-specific validations (if overridden in child class)</p> Source code in <code>clifpy/tables/base_table.py</code> <pre><code>def validate(self):\n    \"\"\"\n    Run comprehensive validation on the data.\n\n    This method runs all validation checks including:\n    - Schema validation (required columns, data types, categories)\n    - Missing data analysis\n    - Duplicate checking\n    - Statistical analysis\n    - Table-specific validations (if overridden in child class)\n    \"\"\"\n    if self.df is None:\n        self.logger.warning(\"No dataframe to validate\")\n        print(\"No dataframe to validate.\")\n        return\n\n    self.logger.info(\"Starting validation\")\n    self.errors = []\n    self._validated = True\n\n    try:\n        # Run basic schema validation\n        if self.schema:\n            self.logger.info(\"Running schema validation\")\n            schema_errors = validator.validate_dataframe(self.df, self.schema)\n            self.errors.extend(schema_errors)\n\n            if schema_errors:\n                self.logger.warning(f\"Schema validation found {len(schema_errors)} errors\")\n            else:\n                self.logger.info(\"Schema validation passed\")\n\n        # Run enhanced validations (these will be implemented in Phase 3)\n        self._run_enhanced_validations()\n\n        # Run table-specific validations (can be overridden in child classes)\n        self._run_table_specific_validations()\n\n        # Log validation results\n        if not self.errors:\n            self.logger.info(\"Validation completed successfully\")\n            print(\"Validation completed successfully.\")\n        else:\n            self.logger.warning(f\"Validation completed with {len(self.errors)} error(s)\")\n            print(f\"Validation completed with {len(self.errors)} error(s). See `errors` attribute.\")\n\n            # Save errors to CSV\n            self._save_validation_errors()\n\n    except Exception as e:\n        self.logger.error(f\"Error during validation: {str(e)}\")\n        self.errors.append({\n            \"type\": \"validation_error\",\n            \"message\": str(e)\n        })\n</code></pre>"},{"location":"api/orchestrator/","title":"ClifOrchestrator","text":""},{"location":"api/orchestrator/#clifpy.clif_orchestrator.ClifOrchestrator","title":"clifpy.clif_orchestrator.ClifOrchestrator","text":"<pre><code>ClifOrchestrator(\n    data_directory,\n    filetype=\"csv\",\n    timezone=\"UTC\",\n    output_directory=None,\n)\n</code></pre> <p>Orchestrator class for managing multiple CLIF table objects.</p> <p>This class provides a centralized interface for loading, managing, and validating multiple CLIF tables with consistent configuration.</p> <p>Attributes:</p> Name Type Description <code>data_directory</code> <code>str</code> <p>Path to the directory containing data files</p> <code>filetype</code> <code>str</code> <p>Type of data file (csv, parquet, etc.)</p> <code>timezone</code> <code>str</code> <p>Timezone for datetime columns</p> <code>output_directory</code> <code>str</code> <p>Directory for saving output files and logs</p> <code>patient</code> <code>Patient</code> <p>Patient table object</p> <code>hospitalization</code> <code>Hospitalization</code> <p>Hospitalization table object</p> <code>adt</code> <code>Adt</code> <p>ADT table object</p> <code>labs</code> <code>Labs</code> <p>Labs table object</p> <code>vitals</code> <code>Vitals</code> <p>Vitals table object</p> <code>medication_admin_continuous</code> <code>MedicationAdminContinuous</code> <p>Medication administration table object</p> <code>patient_assessments</code> <code>PatientAssessments</code> <p>Patient assessments table object</p> <code>respiratory_support</code> <code>RespiratorySupport</code> <p>Respiratory support table object</p> <code>position</code> <code>Position</code> <p>Position table object</p> <p>Initialize the ClifOrchestrator.</p> <p>Parameters:</p> Name Type Description Default <code>data_directory</code> <code>str</code> <p>Path to the directory containing data files</p> required <code>filetype</code> <code>str</code> <p>Type of data file (csv, parquet, etc.)</p> <code>'csv'</code> <code>timezone</code> <code>str</code> <p>Timezone for datetime columns</p> <code>'UTC'</code> <code>output_directory</code> <code>str</code> <p>Directory for saving output files and logs. If not provided, creates an 'output' directory in the current working directory.</p> <code>None</code> Source code in <code>clifpy/clif_orchestrator.py</code> <pre><code>def __init__(\n    self,\n    data_directory: str,\n    filetype: str = 'csv',\n    timezone: str = 'UTC',\n    output_directory: Optional[str] = None\n):\n    \"\"\"\n    Initialize the ClifOrchestrator.\n\n    Parameters:\n        data_directory (str): Path to the directory containing data files\n        filetype (str): Type of data file (csv, parquet, etc.)\n        timezone (str): Timezone for datetime columns\n        output_directory (str, optional): Directory for saving output files and logs.\n            If not provided, creates an 'output' directory in the current working directory.\n    \"\"\"\n    self.data_directory = data_directory\n    self.filetype = filetype\n    self.timezone = timezone\n\n    # Set output directory (same logic as BaseTable)\n    if output_directory is None:\n        output_directory = os.path.join(os.getcwd(), 'output')\n    self.output_directory = output_directory\n    os.makedirs(self.output_directory, exist_ok=True)\n\n    # Initialize all table attributes to None\n    self.patient = None\n    self.hospitalization = None\n    self.adt = None\n    self.labs = None\n    self.vitals = None\n    self.medication_admin_continuous = None\n    self.patient_assessments = None\n    self.respiratory_support = None\n    self.position = None\n\n    print('ClifOrchestrator initialized.')\n</code></pre>"},{"location":"api/orchestrator/#clifpy.clif_orchestrator.ClifOrchestrator.get_loaded_tables","title":"get_loaded_tables","text":"<pre><code>get_loaded_tables()\n</code></pre> <p>Return list of currently loaded table names.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: List of loaded table names</p> Source code in <code>clifpy/clif_orchestrator.py</code> <pre><code>def get_loaded_tables(self) -&gt; List[str]:\n    \"\"\"\n    Return list of currently loaded table names.\n\n    Returns:\n        List[str]: List of loaded table names\n    \"\"\"\n    loaded = []\n    for table_name in ['patient', 'hospitalization', 'adt', 'labs', 'vitals',\n                      'medication_admin_continuous', 'patient_assessments',\n                      'respiratory_support', 'position']:\n        if getattr(self, table_name) is not None:\n            loaded.append(table_name)\n    return loaded\n</code></pre>"},{"location":"api/orchestrator/#clifpy.clif_orchestrator.ClifOrchestrator.get_tables_obj_list","title":"get_tables_obj_list","text":"<pre><code>get_tables_obj_list()\n</code></pre> <p>Return list of loaded table objects.</p> <p>Returns:</p> Name Type Description <code>List</code> <code>List</code> <p>List of loaded table objects</p> Source code in <code>clifpy/clif_orchestrator.py</code> <pre><code>def get_tables_obj_list(self) -&gt; List:\n    \"\"\"\n    Return list of loaded table objects.\n\n    Returns:\n        List: List of loaded table objects\n    \"\"\"\n    table_objects = []\n    for table_name in ['patient', 'hospitalization', 'adt', 'labs', 'vitals',\n                      'medication_admin_continuous', 'patient_assessments',\n                      'respiratory_support', 'position']:\n        table_obj = getattr(self, table_name)\n        if table_obj is not None:\n            table_objects.append(table_obj)\n    return table_objects\n</code></pre>"},{"location":"api/orchestrator/#clifpy.clif_orchestrator.ClifOrchestrator.initialize","title":"initialize","text":"<pre><code>initialize(\n    tables=None,\n    sample_size=None,\n    columns=None,\n    filters=None,\n)\n</code></pre> <p>Initialize specified tables with optional filtering and column selection.</p> <p>Parameters:</p> Name Type Description Default <code>tables</code> <code>List[str]</code> <p>List of table names to load. Defaults to ['patient'].</p> <code>None</code> <code>sample_size</code> <code>int</code> <p>Number of rows to load for each table.</p> <code>None</code> <code>columns</code> <code>Dict[str, List[str]]</code> <p>Dictionary mapping table names to lists of columns to load.</p> <code>None</code> <code>filters</code> <code>Dict[str, Dict]</code> <p>Dictionary mapping table names to filter dictionaries.</p> <code>None</code> Source code in <code>clifpy/clif_orchestrator.py</code> <pre><code>def initialize(\n    self,\n    tables: Optional[List[str]] = None,\n    sample_size: Optional[int] = None,\n    columns: Optional[Dict[str, List[str]]] = None,\n    filters: Optional[Dict[str, Dict[str, Any]]] = None\n):\n    \"\"\"\n    Initialize specified tables with optional filtering and column selection.\n\n    Parameters:\n        tables (List[str], optional): List of table names to load. Defaults to ['patient'].\n        sample_size (int, optional): Number of rows to load for each table.\n        columns (Dict[str, List[str]], optional): Dictionary mapping table names to lists of columns to load.\n        filters (Dict[str, Dict], optional): Dictionary mapping table names to filter dictionaries.\n    \"\"\"\n    if tables is None:\n        tables = ['patient']\n\n    for table in tables:\n        # Get table-specific columns and filters if provided\n        table_columns = columns.get(table) if columns else None\n        table_filters = filters.get(table) if filters else None\n\n        if table == 'patient':\n            self.load_patient_data(sample_size, table_columns, table_filters)\n        elif table == 'hospitalization':\n            self.load_hospitalization_data(sample_size, table_columns, table_filters)\n        elif table == 'adt':\n            self.load_adt_data(sample_size, table_columns, table_filters)\n        elif table == 'labs':\n            self.load_labs_data(sample_size, table_columns, table_filters)\n        elif table == 'vitals':\n            self.load_vitals_data(sample_size, table_columns, table_filters)\n        elif table == 'medication_admin_continuous':\n            self.load_medication_admin_continuous_data(sample_size, table_columns, table_filters)\n        elif table == 'patient_assessments':\n            self.load_patient_assessments_data(sample_size, table_columns, table_filters)\n        elif table == 'respiratory_support':\n            self.load_respiratory_support_data(sample_size, table_columns, table_filters)\n        elif table == 'position':\n            self.load_position_data(sample_size, table_columns, table_filters)\n        else:\n            print(f\"Warning: Unknown table '{table}', skipping.\")\n</code></pre>"},{"location":"api/orchestrator/#clifpy.clif_orchestrator.ClifOrchestrator.load_adt_data","title":"load_adt_data","text":"<pre><code>load_adt_data(sample_size=None, columns=None, filters=None)\n</code></pre> <p>Load ADT data and create Adt table object.</p> <p>Parameters:</p> Name Type Description Default <code>sample_size</code> <code>int</code> <p>Number of rows to load</p> <code>None</code> <code>columns</code> <code>List[str]</code> <p>Specific columns to load</p> <code>None</code> <code>filters</code> <code>Dict</code> <p>Filters to apply when loading</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Adt</code> <p>The loaded Adt table object</p> Source code in <code>clifpy/clif_orchestrator.py</code> <pre><code>def load_adt_data(\n    self,\n    sample_size: Optional[int] = None,\n    columns: Optional[List[str]] = None,\n    filters: Optional[Dict[str, Any]] = None\n):\n    \"\"\"\n    Load ADT data and create Adt table object.\n\n    Parameters:\n        sample_size (int, optional): Number of rows to load\n        columns (List[str], optional): Specific columns to load\n        filters (Dict, optional): Filters to apply when loading\n\n    Returns:\n        Adt: The loaded Adt table object\n    \"\"\"\n    self.adt = Adt.from_file(\n        data_directory=self.data_directory,\n        filetype=self.filetype,\n        timezone=self.timezone,\n        output_directory=self.output_directory,\n        sample_size=sample_size,\n        columns=columns,\n        filters=filters\n    )\n    return self.adt\n</code></pre>"},{"location":"api/orchestrator/#clifpy.clif_orchestrator.ClifOrchestrator.load_hospitalization_data","title":"load_hospitalization_data","text":"<pre><code>load_hospitalization_data(\n    sample_size=None, columns=None, filters=None\n)\n</code></pre> <p>Load hospitalization data and create Hospitalization table object.</p> <p>Parameters:</p> Name Type Description Default <code>sample_size</code> <code>int</code> <p>Number of rows to load</p> <code>None</code> <code>columns</code> <code>List[str]</code> <p>Specific columns to load</p> <code>None</code> <code>filters</code> <code>Dict</code> <p>Filters to apply when loading</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Hospitalization</code> <p>The loaded Hospitalization table object</p> Source code in <code>clifpy/clif_orchestrator.py</code> <pre><code>def load_hospitalization_data(\n    self,\n    sample_size: Optional[int] = None,\n    columns: Optional[List[str]] = None,\n    filters: Optional[Dict[str, Any]] = None\n):\n    \"\"\"\n    Load hospitalization data and create Hospitalization table object.\n\n    Parameters:\n        sample_size (int, optional): Number of rows to load\n        columns (List[str], optional): Specific columns to load\n        filters (Dict, optional): Filters to apply when loading\n\n    Returns:\n        Hospitalization: The loaded Hospitalization table object\n    \"\"\"\n    self.hospitalization = Hospitalization.from_file(\n        data_directory=self.data_directory,\n        filetype=self.filetype,\n        timezone=self.timezone,\n        output_directory=self.output_directory,\n        sample_size=sample_size,\n        columns=columns,\n        filters=filters\n    )\n    return self.hospitalization\n</code></pre>"},{"location":"api/orchestrator/#clifpy.clif_orchestrator.ClifOrchestrator.load_labs_data","title":"load_labs_data","text":"<pre><code>load_labs_data(\n    sample_size=None, columns=None, filters=None\n)\n</code></pre> <p>Load labs data and create Labs table object.</p> <p>Parameters:</p> Name Type Description Default <code>sample_size</code> <code>int</code> <p>Number of rows to load</p> <code>None</code> <code>columns</code> <code>List[str]</code> <p>Specific columns to load</p> <code>None</code> <code>filters</code> <code>Dict</code> <p>Filters to apply when loading</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Labs</code> <p>The loaded Labs table object</p> Source code in <code>clifpy/clif_orchestrator.py</code> <pre><code>def load_labs_data(\n    self,\n    sample_size: Optional[int] = None,\n    columns: Optional[List[str]] = None,\n    filters: Optional[Dict[str, Any]] = None\n):\n    \"\"\"\n    Load labs data and create Labs table object.\n\n    Parameters:\n        sample_size (int, optional): Number of rows to load\n        columns (List[str], optional): Specific columns to load\n        filters (Dict, optional): Filters to apply when loading\n\n    Returns:\n        Labs: The loaded Labs table object\n    \"\"\"\n    self.labs = Labs.from_file(\n        data_directory=self.data_directory,\n        filetype=self.filetype,\n        timezone=self.timezone,\n        output_directory=self.output_directory,\n        sample_size=sample_size,\n        columns=columns,\n        filters=filters\n    )\n    return self.labs\n</code></pre>"},{"location":"api/orchestrator/#clifpy.clif_orchestrator.ClifOrchestrator.load_medication_admin_continuous_data","title":"load_medication_admin_continuous_data","text":"<pre><code>load_medication_admin_continuous_data(\n    sample_size=None, columns=None, filters=None\n)\n</code></pre> <p>Load medication administration continuous data and create MedicationAdminContinuous table object.</p> <p>Parameters:</p> Name Type Description Default <code>sample_size</code> <code>int</code> <p>Number of rows to load</p> <code>None</code> <code>columns</code> <code>List[str]</code> <p>Specific columns to load</p> <code>None</code> <code>filters</code> <code>Dict</code> <p>Filters to apply when loading</p> <code>None</code> <p>Returns:</p> Name Type Description <code>MedicationAdminContinuous</code> <p>The loaded MedicationAdminContinuous table object</p> Source code in <code>clifpy/clif_orchestrator.py</code> <pre><code>def load_medication_admin_continuous_data(\n    self,\n    sample_size: Optional[int] = None,\n    columns: Optional[List[str]] = None,\n    filters: Optional[Dict[str, Any]] = None\n):\n    \"\"\"\n    Load medication administration continuous data and create MedicationAdminContinuous table object.\n\n    Parameters:\n        sample_size (int, optional): Number of rows to load\n        columns (List[str], optional): Specific columns to load\n        filters (Dict, optional): Filters to apply when loading\n\n    Returns:\n        MedicationAdminContinuous: The loaded MedicationAdminContinuous table object\n    \"\"\"\n    self.medication_admin_continuous = MedicationAdminContinuous.from_file(\n        data_directory=self.data_directory,\n        filetype=self.filetype,\n        timezone=self.timezone,\n        output_directory=self.output_directory,\n        sample_size=sample_size,\n        columns=columns,\n        filters=filters\n    )\n    return self.medication_admin_continuous\n</code></pre>"},{"location":"api/orchestrator/#clifpy.clif_orchestrator.ClifOrchestrator.load_patient_assessments_data","title":"load_patient_assessments_data","text":"<pre><code>load_patient_assessments_data(\n    sample_size=None, columns=None, filters=None\n)\n</code></pre> <p>Load patient assessments data and create PatientAssessments table object.</p> <p>Parameters:</p> Name Type Description Default <code>sample_size</code> <code>int</code> <p>Number of rows to load</p> <code>None</code> <code>columns</code> <code>List[str]</code> <p>Specific columns to load</p> <code>None</code> <code>filters</code> <code>Dict</code> <p>Filters to apply when loading</p> <code>None</code> <p>Returns:</p> Name Type Description <code>PatientAssessments</code> <p>The loaded PatientAssessments table object</p> Source code in <code>clifpy/clif_orchestrator.py</code> <pre><code>def load_patient_assessments_data(\n    self,\n    sample_size: Optional[int] = None,\n    columns: Optional[List[str]] = None,\n    filters: Optional[Dict[str, Any]] = None\n):\n    \"\"\"\n    Load patient assessments data and create PatientAssessments table object.\n\n    Parameters:\n        sample_size (int, optional): Number of rows to load\n        columns (List[str], optional): Specific columns to load\n        filters (Dict, optional): Filters to apply when loading\n\n    Returns:\n        PatientAssessments: The loaded PatientAssessments table object\n    \"\"\"\n    self.patient_assessments = PatientAssessments.from_file(\n        data_directory=self.data_directory,\n        filetype=self.filetype,\n        timezone=self.timezone,\n        output_directory=self.output_directory,\n        sample_size=sample_size,\n        columns=columns,\n        filters=filters\n    )\n    return self.patient_assessments\n</code></pre>"},{"location":"api/orchestrator/#clifpy.clif_orchestrator.ClifOrchestrator.load_patient_data","title":"load_patient_data","text":"<pre><code>load_patient_data(\n    sample_size=None, columns=None, filters=None\n)\n</code></pre> <p>Load patient data and create Patient table object.</p> <p>Parameters:</p> Name Type Description Default <code>sample_size</code> <code>int</code> <p>Number of rows to load</p> <code>None</code> <code>columns</code> <code>List[str]</code> <p>Specific columns to load</p> <code>None</code> <code>filters</code> <code>Dict</code> <p>Filters to apply when loading</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Patient</code> <p>The loaded Patient table object</p> Source code in <code>clifpy/clif_orchestrator.py</code> <pre><code>def load_patient_data(\n    self,\n    sample_size: Optional[int] = None,\n    columns: Optional[List[str]] = None,\n    filters: Optional[Dict[str, Any]] = None\n):\n    \"\"\"\n    Load patient data and create Patient table object.\n\n    Parameters:\n        sample_size (int, optional): Number of rows to load\n        columns (List[str], optional): Specific columns to load\n        filters (Dict, optional): Filters to apply when loading\n\n    Returns:\n        Patient: The loaded Patient table object\n    \"\"\"\n    self.patient = Patient.from_file(\n        data_directory=self.data_directory,\n        filetype=self.filetype,\n        timezone=self.timezone,\n        output_directory=self.output_directory,\n        sample_size=sample_size,\n        columns=columns,\n        filters=filters\n    )\n    return self.patient\n</code></pre>"},{"location":"api/orchestrator/#clifpy.clif_orchestrator.ClifOrchestrator.load_position_data","title":"load_position_data","text":"<pre><code>load_position_data(\n    sample_size=None, columns=None, filters=None\n)\n</code></pre> <p>Load position data and create Position table object.</p> <p>Parameters:</p> Name Type Description Default <code>sample_size</code> <code>int</code> <p>Number of rows to load</p> <code>None</code> <code>columns</code> <code>List[str]</code> <p>Specific columns to load</p> <code>None</code> <code>filters</code> <code>Dict</code> <p>Filters to apply when loading</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Position</code> <p>The loaded Position table object</p> Source code in <code>clifpy/clif_orchestrator.py</code> <pre><code>def load_position_data(\n    self,\n    sample_size: Optional[int] = None,\n    columns: Optional[List[str]] = None,\n    filters: Optional[Dict[str, Any]] = None\n):\n    \"\"\"\n    Load position data and create Position table object.\n\n    Parameters:\n        sample_size (int, optional): Number of rows to load\n        columns (List[str], optional): Specific columns to load\n        filters (Dict, optional): Filters to apply when loading\n\n    Returns:\n        Position: The loaded Position table object\n    \"\"\"\n    self.position = Position.from_file(\n        data_directory=self.data_directory,\n        filetype=self.filetype,\n        timezone=self.timezone,\n        output_directory=self.output_directory,\n        sample_size=sample_size,\n        columns=columns,\n        filters=filters\n    )\n    return self.position\n</code></pre>"},{"location":"api/orchestrator/#clifpy.clif_orchestrator.ClifOrchestrator.load_respiratory_support_data","title":"load_respiratory_support_data","text":"<pre><code>load_respiratory_support_data(\n    sample_size=None, columns=None, filters=None\n)\n</code></pre> <p>Load respiratory support data and create RespiratorySupport table object.</p> <p>Parameters:</p> Name Type Description Default <code>sample_size</code> <code>int</code> <p>Number of rows to load</p> <code>None</code> <code>columns</code> <code>List[str]</code> <p>Specific columns to load</p> <code>None</code> <code>filters</code> <code>Dict</code> <p>Filters to apply when loading</p> <code>None</code> <p>Returns:</p> Name Type Description <code>RespiratorySupport</code> <p>The loaded RespiratorySupport table object</p> Source code in <code>clifpy/clif_orchestrator.py</code> <pre><code>def load_respiratory_support_data(\n    self,\n    sample_size: Optional[int] = None,\n    columns: Optional[List[str]] = None,\n    filters: Optional[Dict[str, Any]] = None\n):\n    \"\"\"\n    Load respiratory support data and create RespiratorySupport table object.\n\n    Parameters:\n        sample_size (int, optional): Number of rows to load\n        columns (List[str], optional): Specific columns to load\n        filters (Dict, optional): Filters to apply when loading\n\n    Returns:\n        RespiratorySupport: The loaded RespiratorySupport table object\n    \"\"\"\n    self.respiratory_support = RespiratorySupport.from_file(\n        data_directory=self.data_directory,\n        filetype=self.filetype,\n        timezone=self.timezone,\n        output_directory=self.output_directory,\n        sample_size=sample_size,\n        columns=columns,\n        filters=filters\n    )\n    return self.respiratory_support\n</code></pre>"},{"location":"api/orchestrator/#clifpy.clif_orchestrator.ClifOrchestrator.load_vitals_data","title":"load_vitals_data","text":"<pre><code>load_vitals_data(\n    sample_size=None, columns=None, filters=None\n)\n</code></pre> <p>Load vitals data and create Vitals table object.</p> <p>Parameters:</p> Name Type Description Default <code>sample_size</code> <code>int</code> <p>Number of rows to load</p> <code>None</code> <code>columns</code> <code>List[str]</code> <p>Specific columns to load</p> <code>None</code> <code>filters</code> <code>Dict</code> <p>Filters to apply when loading</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Vitals</code> <p>The loaded Vitals table object</p> Source code in <code>clifpy/clif_orchestrator.py</code> <pre><code>def load_vitals_data(\n    self,\n    sample_size: Optional[int] = None,\n    columns: Optional[List[str]] = None,\n    filters: Optional[Dict[str, Any]] = None\n):\n    \"\"\"\n    Load vitals data and create Vitals table object.\n\n    Parameters:\n        sample_size (int, optional): Number of rows to load\n        columns (List[str], optional): Specific columns to load\n        filters (Dict, optional): Filters to apply when loading\n\n    Returns:\n        Vitals: The loaded Vitals table object\n    \"\"\"\n    self.vitals = Vitals.from_file(\n        data_directory=self.data_directory,\n        filetype=self.filetype,\n        timezone=self.timezone,\n        output_directory=self.output_directory,\n        sample_size=sample_size,\n        columns=columns,\n        filters=filters\n    )\n    return self.vitals\n</code></pre>"},{"location":"api/orchestrator/#clifpy.clif_orchestrator.ClifOrchestrator.validate_all","title":"validate_all","text":"<pre><code>validate_all()\n</code></pre> <p>Run validation on all loaded tables.</p> <p>This method runs the validate() method on each loaded table and reports the results.</p> Source code in <code>clifpy/clif_orchestrator.py</code> <pre><code>def validate_all(self):\n    \"\"\"\n    Run validation on all loaded tables.\n\n    This method runs the validate() method on each loaded table\n    and reports the results.\n    \"\"\"\n    loaded_tables = self.get_loaded_tables()\n\n    if not loaded_tables:\n        print(\"No tables loaded to validate.\")\n        return\n\n    print(f\"Validating {len(loaded_tables)} table(s)...\")\n\n    for table_name in loaded_tables:\n        table_obj = getattr(self, table_name)\n        print(f\"\\nValidating {table_name}...\")\n        table_obj.validate()\n</code></pre>"},{"location":"api/tables/","title":"Table Classes","text":""},{"location":"api/tables/#patient","title":"Patient","text":""},{"location":"api/tables/#clifpy.tables.patient.Patient","title":"clifpy.tables.patient.Patient","text":"<pre><code>Patient(\n    data_directory=None,\n    filetype=None,\n    timezone=\"UTC\",\n    output_directory=None,\n    data=None,\n)\n</code></pre> <p>               Bases: <code>BaseTable</code></p> <p>Patient table wrapper inheriting from BaseTable.</p> <p>This class handles patient-specific data and validations while leveraging the common functionality provided by BaseTable.</p> <p>Initialize the patient table.</p> <p>Parameters:</p> Name Type Description Default <code>data_directory</code> <code>str</code> <p>Path to the directory containing data files</p> <code>None</code> <code>filetype</code> <code>str</code> <p>Type of data file (csv, parquet, etc.)</p> <code>None</code> <code>timezone</code> <code>str</code> <p>Timezone for datetime columns</p> <code>'UTC'</code> <code>output_directory</code> <code>str</code> <p>Directory for saving output files and logs</p> <code>None</code> <code>data</code> <code>DataFrame</code> <p>Pre-loaded data to use instead of loading from file</p> <code>None</code> Source code in <code>clifpy/tables/patient.py</code> <pre><code>def __init__(\n    self,\n    data_directory: str = None,\n    filetype: str = None,\n    timezone: str = \"UTC\",\n    output_directory: Optional[str] = None,\n    data: Optional[pd.DataFrame] = None\n):\n    \"\"\"\n    Initialize the patient table.\n\n    Parameters:\n        data_directory (str): Path to the directory containing data files\n        filetype (str): Type of data file (csv, parquet, etc.)\n        timezone (str): Timezone for datetime columns\n        output_directory (str, optional): Directory for saving output files and logs\n        data (pd.DataFrame, optional): Pre-loaded data to use instead of loading from file\n    \"\"\"\n\n    super().__init__(\n        data_directory=data_directory,\n        filetype=filetype,\n        timezone=timezone,\n        output_directory=output_directory,\n        data=data\n    )\n</code></pre>"},{"location":"api/tables/#adt-admission-discharge-transfer","title":"ADT (Admission, Discharge, Transfer)","text":""},{"location":"api/tables/#clifpy.tables.adt.Adt","title":"clifpy.tables.adt.Adt","text":"<pre><code>Adt(\n    data_directory=None,\n    filetype=None,\n    timezone=\"UTC\",\n    output_directory=None,\n    data=None,\n)\n</code></pre> <p>               Bases: <code>BaseTable</code></p> <p>ADT (Admission/Discharge/Transfer) table wrapper inheriting from BaseTable.</p> <p>This class handles ADT-specific data and validations while leveraging the common functionality provided by BaseTable.</p> <p>Initialize the ADT table.</p> <p>Parameters:</p> Name Type Description Default <code>data_directory</code> <code>str</code> <p>Path to the directory containing data files</p> <code>None</code> <code>filetype</code> <code>str</code> <p>Type of data file (csv, parquet, etc.)</p> <code>None</code> <code>timezone</code> <code>str</code> <p>Timezone for datetime columns</p> <code>'UTC'</code> <code>output_directory</code> <code>str</code> <p>Directory for saving output files and logs</p> <code>None</code> <code>data</code> <code>DataFrame</code> <p>Pre-loaded data to use instead of loading from file</p> <code>None</code> Source code in <code>clifpy/tables/adt.py</code> <pre><code>def __init__(\n    self,\n    data_directory: str = None,\n    filetype: str = None,\n    timezone: str = \"UTC\",\n    output_directory: Optional[str] = None,\n    data: Optional[pd.DataFrame] = None\n):\n    \"\"\"\n    Initialize the ADT table.\n\n    Parameters:\n        data_directory (str): Path to the directory containing data files\n        filetype (str): Type of data file (csv, parquet, etc.)\n        timezone (str): Timezone for datetime columns\n        output_directory (str, optional): Directory for saving output files and logs\n        data (pd.DataFrame, optional): Pre-loaded data to use instead of loading from file\n    \"\"\"\n    # For backward compatibility, handle the old signature\n    if data_directory is None and filetype is None and data is not None:\n        # Old signature: adt(data)\n        # Use dummy values for required parameters\n        data_directory = \".\"\n        filetype = \"parquet\"\n\n    super().__init__(\n        data_directory=data_directory,\n        filetype=filetype,\n        timezone=timezone,\n        output_directory=output_directory,\n        data=data\n    )\n</code></pre>"},{"location":"api/tables/#clifpy.tables.adt.Adt.filter_by_date_range","title":"filter_by_date_range","text":"<pre><code>filter_by_date_range(\n    start_date, end_date, date_column=\"in_dttm\"\n)\n</code></pre> <p>Return records within a specific date range for a given datetime column.</p> Source code in <code>clifpy/tables/adt.py</code> <pre><code>def filter_by_date_range(self, start_date: datetime, end_date: datetime, \n                       date_column: str = 'in_dttm') -&gt; pd.DataFrame:\n    \"\"\"Return records within a specific date range for a given datetime column.\"\"\"\n    if self.df is None or date_column not in self.df.columns:\n        return pd.DataFrame()\n\n    # Convert datetime column to datetime if it's not already\n    df_copy = self.df.copy()\n    df_copy[date_column] = pd.to_datetime(df_copy[date_column])\n\n    mask = (df_copy[date_column] &gt;= start_date) &amp; (df_copy[date_column] &lt;= end_date)\n    return df_copy[mask]\n</code></pre>"},{"location":"api/tables/#clifpy.tables.adt.Adt.filter_by_hospitalization","title":"filter_by_hospitalization","text":"<pre><code>filter_by_hospitalization(hospitalization_id)\n</code></pre> <p>Return all ADT records for a specific hospitalization.</p> Source code in <code>clifpy/tables/adt.py</code> <pre><code>def filter_by_hospitalization(self, hospitalization_id: str) -&gt; pd.DataFrame:\n    \"\"\"Return all ADT records for a specific hospitalization.\"\"\"\n    if self.df is None:\n        return pd.DataFrame()\n\n    return self.df[self.df['hospitalization_id'] == hospitalization_id].copy()\n</code></pre>"},{"location":"api/tables/#clifpy.tables.adt.Adt.filter_by_location_category","title":"filter_by_location_category","text":"<pre><code>filter_by_location_category(location_category)\n</code></pre> <p>Return all records for a specific location category (e.g., 'icu', 'ward').</p> Source code in <code>clifpy/tables/adt.py</code> <pre><code>def filter_by_location_category(self, location_category: str) -&gt; pd.DataFrame:\n    \"\"\"Return all records for a specific location category (e.g., 'icu', 'ward').\"\"\"\n    if self.df is None or 'location_category' not in self.df.columns:\n        return pd.DataFrame()\n\n    return self.df[self.df['location_category'] == location_category].copy()\n</code></pre>"},{"location":"api/tables/#clifpy.tables.adt.Adt.get_hospital_types","title":"get_hospital_types","text":"<pre><code>get_hospital_types()\n</code></pre> <p>Return unique hospital types in the dataset.</p> Source code in <code>clifpy/tables/adt.py</code> <pre><code>def get_hospital_types(self) -&gt; List[str]:\n    \"\"\"Return unique hospital types in the dataset.\"\"\"\n    if self.df is None or 'hospital_type' not in self.df.columns:\n        return []\n    return self.df['hospital_type'].dropna().unique().tolist()\n</code></pre>"},{"location":"api/tables/#clifpy.tables.adt.Adt.get_location_categories","title":"get_location_categories","text":"<pre><code>get_location_categories()\n</code></pre> <p>Return unique location categories in the dataset.</p> Source code in <code>clifpy/tables/adt.py</code> <pre><code>def get_location_categories(self) -&gt; List[str]:\n    \"\"\"Return unique location categories in the dataset.\"\"\"\n    if self.df is None or 'location_category' not in self.df.columns:\n        return []\n    return self.df['location_category'].dropna().unique().tolist()\n</code></pre>"},{"location":"api/tables/#clifpy.tables.adt.Adt.get_summary_stats","title":"get_summary_stats","text":"<pre><code>get_summary_stats()\n</code></pre> <p>Return summary statistics for the ADT data.</p> Source code in <code>clifpy/tables/adt.py</code> <pre><code>def get_summary_stats(self) -&gt; Dict:\n    \"\"\"Return summary statistics for the ADT data.\"\"\"\n    if self.df is None:\n        return {}\n\n    stats = {\n        'total_records': len(self.df),\n        'unique_hospitalizations': self.df['hospitalization_id'].nunique() if 'hospitalization_id' in self.df.columns else 0,\n        'unique_hospitals': self.df['hospital_id'].nunique() if 'hospital_id' in self.df.columns else 0,\n        'location_category_counts': self.df['location_category'].value_counts().to_dict() if 'location_category' in self.df.columns else {},\n        'hospital_type_counts': self.df['hospital_type'].value_counts().to_dict() if 'hospital_type' in self.df.columns else {},\n        'date_range': {\n            'earliest_in': self.df['in_dttm'].min() if 'in_dttm' in self.df.columns else None,\n            'latest_in': self.df['in_dttm'].max() if 'in_dttm' in self.df.columns else None,\n            'earliest_out': self.df['out_dttm'].min() if 'out_dttm' in self.df.columns else None,\n            'latest_out': self.df['out_dttm'].max() if 'out_dttm' in self.df.columns else None\n        }\n    }\n\n    return stats\n</code></pre>"},{"location":"api/tables/#hospitalization","title":"Hospitalization","text":""},{"location":"api/tables/#clifpy.tables.hospitalization.Hospitalization","title":"clifpy.tables.hospitalization.Hospitalization","text":"<pre><code>Hospitalization(\n    data_directory=None,\n    filetype=None,\n    timezone=\"UTC\",\n    output_directory=None,\n    data=None,\n)\n</code></pre> <p>               Bases: <code>BaseTable</code></p> <p>Hospitalization table wrapper inheriting from BaseTable.</p> <p>This class handles hospitalization-specific data and validations while leveraging the common functionality provided by BaseTable.</p> <p>Initialize the hospitalization table.</p> <p>Parameters:</p> Name Type Description Default <code>data_directory</code> <code>str</code> <p>Path to the directory containing data files</p> <code>None</code> <code>filetype</code> <code>str</code> <p>Type of data file (csv, parquet, etc.)</p> <code>None</code> <code>timezone</code> <code>str</code> <p>Timezone for datetime columns</p> <code>'UTC'</code> <code>output_directory</code> <code>str</code> <p>Directory for saving output files and logs</p> <code>None</code> <code>data</code> <code>DataFrame</code> <p>Pre-loaded data to use instead of loading from file</p> <code>None</code> Source code in <code>clifpy/tables/hospitalization.py</code> <pre><code>def __init__(\n    self,\n    data_directory: str = None,\n    filetype: str = None,\n    timezone: str = \"UTC\",\n    output_directory: Optional[str] = None,\n    data: Optional[pd.DataFrame] = None\n):\n    \"\"\"\n    Initialize the hospitalization table.\n\n    Parameters:\n        data_directory (str): Path to the directory containing data files\n        filetype (str): Type of data file (csv, parquet, etc.)\n        timezone (str): Timezone for datetime columns\n        output_directory (str, optional): Directory for saving output files and logs\n        data (pd.DataFrame, optional): Pre-loaded data to use instead of loading from file\n    \"\"\"\n    # For backward compatibility, handle the old signature\n    if data_directory is None and filetype is None and data is not None:\n        # Old signature: hospitalization(data)\n        # Use dummy values for required parameters\n        data_directory = \".\"\n        filetype = \"parquet\"\n\n    super().__init__(\n        data_directory=data_directory,\n        filetype=filetype,\n        timezone=timezone,\n        output_directory=output_directory,\n        data=data\n    )\n</code></pre>"},{"location":"api/tables/#clifpy.tables.hospitalization.Hospitalization.calculate_length_of_stay","title":"calculate_length_of_stay","text":"<pre><code>calculate_length_of_stay()\n</code></pre> <p>Calculate length of stay for each hospitalization and return DataFrame with LOS column.</p> Source code in <code>clifpy/tables/hospitalization.py</code> <pre><code>def calculate_length_of_stay(self) -&gt; pd.DataFrame:\n    \"\"\"Calculate length of stay for each hospitalization and return DataFrame with LOS column.\"\"\"\n    if self.df is None:\n        return pd.DataFrame()\n\n    required_cols = ['admission_dttm', 'discharge_dttm']\n    if not all(col in self.df.columns for col in required_cols):\n        print(f\"Missing required columns: {[col for col in required_cols if col not in self.df.columns]}\")\n        return pd.DataFrame()\n\n    df_copy = self.df.copy()\n    df_copy['admission_dttm'] = pd.to_datetime(df_copy['admission_dttm'])\n    df_copy['discharge_dttm'] = pd.to_datetime(df_copy['discharge_dttm'])\n\n    # Calculate LOS in days\n    df_copy['length_of_stay_days'] = (df_copy['discharge_dttm'] - df_copy['admission_dttm']).dt.total_seconds() / (24 * 3600)\n\n    return df_copy\n</code></pre>"},{"location":"api/tables/#clifpy.tables.hospitalization.Hospitalization.get_mortality_rate","title":"get_mortality_rate","text":"<pre><code>get_mortality_rate()\n</code></pre> <p>Calculate in-hospital mortality rate.</p> Source code in <code>clifpy/tables/hospitalization.py</code> <pre><code>def get_mortality_rate(self) -&gt; float:\n    \"\"\"Calculate in-hospital mortality rate.\"\"\"\n    if self.df is None or 'discharge_category' not in self.df.columns:\n        return 0.0\n\n    total_hospitalizations = len(self.df)\n    if total_hospitalizations == 0:\n        return 0.0\n\n    expired_count = len(self.df[self.df['discharge_category'] == 'Expired'])\n    return (expired_count / total_hospitalizations) * 100\n</code></pre>"},{"location":"api/tables/#clifpy.tables.hospitalization.Hospitalization.get_patient_hospitalization_counts","title":"get_patient_hospitalization_counts","text":"<pre><code>get_patient_hospitalization_counts()\n</code></pre> <p>Return DataFrame with hospitalization counts per patient.</p> Source code in <code>clifpy/tables/hospitalization.py</code> <pre><code>def get_patient_hospitalization_counts(self) -&gt; pd.DataFrame:\n    \"\"\"Return DataFrame with hospitalization counts per patient.\"\"\"\n    if self.df is None or 'patient_id' not in self.df.columns:\n        return pd.DataFrame()\n\n    patient_counts = (self.df.groupby('patient_id')\n                     .agg({\n                         'hospitalization_id': 'count',\n                         'admission_dttm': ['min', 'max']\n                     })\n                     .reset_index())\n\n    # Flatten column names\n    patient_counts.columns = ['patient_id', 'hospitalization_count', 'first_admission', 'last_admission']\n\n    # Calculate span of care\n    patient_counts['first_admission'] = pd.to_datetime(patient_counts['first_admission'])\n    patient_counts['last_admission'] = pd.to_datetime(patient_counts['last_admission'])\n    patient_counts['care_span_days'] = (patient_counts['last_admission'] - patient_counts['first_admission']).dt.total_seconds() / (24 * 3600)\n\n    return patient_counts.sort_values('hospitalization_count', ascending=False)\n</code></pre>"},{"location":"api/tables/#clifpy.tables.hospitalization.Hospitalization.get_summary_stats","title":"get_summary_stats","text":"<pre><code>get_summary_stats()\n</code></pre> <p>Return comprehensive summary statistics for hospitalization data.</p> Source code in <code>clifpy/tables/hospitalization.py</code> <pre><code>def get_summary_stats(self) -&gt; Dict:\n    \"\"\"Return comprehensive summary statistics for hospitalization data.\"\"\"\n    if self.df is None:\n        return {}\n\n    stats = {\n        'total_hospitalizations': len(self.df),\n        'unique_patients': self.df['patient_id'].nunique() if 'patient_id' in self.df.columns else 0,\n        'discharge_category_counts': self.df['discharge_category'].value_counts().to_dict() if 'discharge_category' in self.df.columns else {},\n        'admission_type_counts': self.df['admission_type_category'].value_counts().to_dict() if 'admission_type_category' in self.df.columns else {},\n        'date_range': {\n            'earliest_admission': self.df['admission_dttm'].min() if 'admission_dttm' in self.df.columns else None,\n            'latest_admission': self.df['admission_dttm'].max() if 'admission_dttm' in self.df.columns else None,\n            'earliest_discharge': self.df['discharge_dttm'].min() if 'discharge_dttm' in self.df.columns else None,\n            'latest_discharge': self.df['discharge_dttm'].max() if 'discharge_dttm' in self.df.columns else None\n        }\n    }\n\n    # Age statistics\n    if 'age_at_admission' in self.df.columns:\n        age_data = self.df['age_at_admission'].dropna()\n        if not age_data.empty:\n            stats['age_stats'] = {\n                'mean': round(age_data.mean(), 1),\n                'median': age_data.median(),\n                'min': age_data.min(),\n                'max': age_data.max(),\n                'std': round(age_data.std(), 1)\n            }\n\n    # Length of stay statistics\n    if all(col in self.df.columns for col in ['admission_dttm', 'discharge_dttm']):\n        los_df = self.calculate_length_of_stay()\n        if 'length_of_stay_days' in los_df.columns:\n            los_data = los_df['length_of_stay_days'].dropna()\n            if not los_data.empty:\n                stats['length_of_stay_stats'] = {\n                    'mean_days': round(los_data.mean(), 1),\n                    'median_days': round(los_data.median(), 1),\n                    'min_days': round(los_data.min(), 1),\n                    'max_days': round(los_data.max(), 1),\n                    'std_days': round(los_data.std(), 1)\n                }\n\n    # Mortality rate\n    stats['mortality_rate_percent'] = round(self.get_mortality_rate(), 2)\n\n    return stats\n</code></pre>"},{"location":"api/tables/#labs","title":"Labs","text":""},{"location":"api/tables/#clifpy.tables.labs.Labs","title":"clifpy.tables.labs.Labs","text":"<pre><code>Labs(\n    data_directory=None,\n    filetype=None,\n    timezone=\"UTC\",\n    output_directory=None,\n    data=None,\n)\n</code></pre> <p>               Bases: <code>BaseTable</code></p> <p>Labs table wrapper inheriting from BaseTable.</p> <p>This class handles laboratory data and validations including reference unit validation while leveraging the common functionality provided by BaseTable.</p> <p>Initialize the labs table.</p> <p>Parameters:</p> Name Type Description Default <code>data_directory</code> <code>str</code> <p>Path to the directory containing data files</p> <code>None</code> <code>filetype</code> <code>str</code> <p>Type of data file (csv, parquet, etc.)</p> <code>None</code> <code>timezone</code> <code>str</code> <p>Timezone for datetime columns</p> <code>'UTC'</code> <code>output_directory</code> <code>str</code> <p>Directory for saving output files and logs</p> <code>None</code> <code>data</code> <code>DataFrame</code> <p>Pre-loaded data to use instead of loading from file</p> <code>None</code> Source code in <code>clifpy/tables/labs.py</code> <pre><code>def __init__(\n    self,\n    data_directory: str = None,\n    filetype: str = None,\n    timezone: str = \"UTC\",\n    output_directory: Optional[str] = None,\n    data: Optional[pd.DataFrame] = None\n):\n    \"\"\"\n    Initialize the labs table.\n\n    Parameters:\n        data_directory (str): Path to the directory containing data files\n        filetype (str): Type of data file (csv, parquet, etc.)\n        timezone (str): Timezone for datetime columns\n        output_directory (str, optional): Directory for saving output files and logs\n        data (pd.DataFrame, optional): Pre-loaded data to use instead of loading from file\n    \"\"\"\n    # For backward compatibility, handle the old signature\n    if data_directory is None and filetype is None and data is not None:\n        # Old signature: labs(data)\n        # Use dummy values for required parameters\n        data_directory = \".\"\n        filetype = \"parquet\"\n\n    # Initialize lab reference units\n    self._lab_reference_units = None\n\n    super().__init__(\n        data_directory=data_directory,\n        filetype=filetype,\n        timezone=timezone,\n        output_directory=output_directory,\n        data=data\n    )\n\n    # Load lab-specific schema data\n    self._load_labs_schema_data()\n</code></pre>"},{"location":"api/tables/#clifpy.tables.labs.Labs.lab_reference_units","title":"lab_reference_units  <code>property</code>","text":"<pre><code>lab_reference_units\n</code></pre> <p>Get the lab reference units mapping from the schema.</p>"},{"location":"api/tables/#clifpy.tables.labs.Labs.get_lab_category_stats","title":"get_lab_category_stats","text":"<pre><code>get_lab_category_stats()\n</code></pre> <p>Return summary statistics for each lab category, including missingness and unique hospitalization_id counts.</p> Source code in <code>clifpy/tables/labs.py</code> <pre><code>def get_lab_category_stats(self) -&gt; pd.DataFrame:\n    \"\"\"Return summary statistics for each lab category, including missingness and unique hospitalization_id counts.\"\"\"\n    if (\n        self.df is None\n        or 'lab_value_numeric' not in self.df.columns\n        or 'hospitalization_id' not in self.df.columns        # remove this line if hosp-id is optional\n    ):\n        return {\"status\": \"Missing columns\"}\n\n    stats = (\n        self.df\n        .groupby('lab_category')\n        .agg(\n            count=('lab_value_numeric', 'count'),\n            unique=('hospitalization_id', 'nunique'),\n            missing_pct=('lab_value_numeric', lambda x: 100 * x.isna().mean()),\n            mean=('lab_value_numeric', 'mean'),\n            std=('lab_value_numeric', 'std'),\n            min=('lab_value_numeric', 'min'),\n            q1=('lab_value_numeric', lambda x: x.quantile(0.25)),\n            median=('lab_value_numeric', 'median'),\n            q3=('lab_value_numeric', lambda x: x.quantile(0.75)),\n            max=('lab_value_numeric', 'max'),\n        )\n        .round(2)\n    )\n\n    return stats\n</code></pre>"},{"location":"api/tables/#clifpy.tables.labs.Labs.get_lab_specimen_stats","title":"get_lab_specimen_stats","text":"<pre><code>get_lab_specimen_stats()\n</code></pre> <p>Return summary statistics for each lab category, including missingness and unique hospitalization_id counts.</p> Source code in <code>clifpy/tables/labs.py</code> <pre><code>def get_lab_specimen_stats(self) -&gt; pd.DataFrame:\n    \"\"\"Return summary statistics for each lab category, including missingness and unique hospitalization_id counts.\"\"\"\n    if (\n        self.df is None\n        or 'lab_value_numeric' not in self.df.columns\n        or 'hospitalization_id' not in self.df.columns \n        or 'lab_speciment_category' not in self.df.columns       # remove this line if hosp-id is optional\n    ):\n        return {\"status\": \"Missing columns\"}\n\n    stats = (\n        self.df\n        .groupby('lab_specimen_category')\n        .agg(\n            count=('lab_value_numeric', 'count'),\n            unique=('hospitalization_id', 'nunique'),\n            missing_pct=('lab_value_numeric', lambda x: 100 * x.isna().mean()),\n            mean=('lab_value_numeric', 'mean'),\n            std=('lab_value_numeric', 'std'),\n            min=('lab_value_numeric', 'min'),\n            q1=('lab_value_numeric', lambda x: x.quantile(0.25)),\n            median=('lab_value_numeric', 'median'),\n            q3=('lab_value_numeric', lambda x: x.quantile(0.75)),\n            max=('lab_value_numeric', 'max'),\n        )\n        .round(2)\n    )\n\n    return stats\n</code></pre>"},{"location":"api/tables/#vitals","title":"Vitals","text":""},{"location":"api/tables/#clifpy.tables.vitals.Vitals","title":"clifpy.tables.vitals.Vitals","text":"<pre><code>Vitals(\n    data_directory=None,\n    filetype=None,\n    timezone=\"UTC\",\n    output_directory=None,\n    data=None,\n)\n</code></pre> <p>               Bases: <code>BaseTable</code></p> <p>Vitals table wrapper inheriting from BaseTable.</p> <p>This class handles vitals-specific data and validations including range validation for vital signs.</p> <p>Initialize the vitals table.</p> <p>Parameters:</p> Name Type Description Default <code>data_directory</code> <code>str</code> <p>Path to the directory containing data files</p> <code>None</code> <code>filetype</code> <code>str</code> <p>Type of data file (csv, parquet, etc.)</p> <code>None</code> <code>timezone</code> <code>str</code> <p>Timezone for datetime columns</p> <code>'UTC'</code> <code>output_directory</code> <code>str</code> <p>Directory for saving output files and logs</p> <code>None</code> <code>data</code> <code>DataFrame</code> <p>Pre-loaded data to use instead of loading from file</p> <code>None</code> Source code in <code>clifpy/tables/vitals.py</code> <pre><code>def __init__(\n    self,\n    data_directory: str = None,\n    filetype: str = None,\n    timezone: str = \"UTC\",\n    output_directory: Optional[str] = None,\n    data: Optional[pd.DataFrame] = None\n):\n    \"\"\"\n    Initialize the vitals table.\n\n    Parameters:\n        data_directory (str): Path to the directory containing data files\n        filetype (str): Type of data file (csv, parquet, etc.)\n        timezone (str): Timezone for datetime columns\n        output_directory (str, optional): Directory for saving output files and logs\n        data (pd.DataFrame, optional): Pre-loaded data to use instead of loading from file\n    \"\"\"\n    # Initialize range validation errors list\n    self.range_validation_errors: List[dict] = []\n\n    # Load vital ranges and units from schema\n    self._vital_units = None\n    self._vital_ranges = None\n\n    super().__init__(\n        data_directory=data_directory,\n        filetype=filetype,\n        timezone=timezone,\n        output_directory=output_directory,\n        data=data\n    )\n\n    # Load vital-specific schema data\n    self._load_vitals_schema_data()\n</code></pre>"},{"location":"api/tables/#clifpy.tables.vitals.Vitals.vital_ranges","title":"vital_ranges  <code>property</code>","text":"<pre><code>vital_ranges\n</code></pre> <p>Get the vital ranges from the schema.</p>"},{"location":"api/tables/#clifpy.tables.vitals.Vitals.vital_units","title":"vital_units  <code>property</code>","text":"<pre><code>vital_units\n</code></pre> <p>Get the vital units mapping from the schema.</p>"},{"location":"api/tables/#clifpy.tables.vitals.Vitals.filter_by_vital_category","title":"filter_by_vital_category","text":"<pre><code>filter_by_vital_category(vital_category)\n</code></pre> <p>Return all records for a specific vital category (e.g., 'heart_rate', 'temp_c').</p> Source code in <code>clifpy/tables/vitals.py</code> <pre><code>def filter_by_vital_category(self, vital_category: str) -&gt; pd.DataFrame:\n    \"\"\"Return all records for a specific vital category (e.g., 'heart_rate', 'temp_c').\"\"\"\n    if self.df is None or 'vital_category' not in self.df.columns:\n        return pd.DataFrame()\n\n    return self.df[self.df['vital_category'] == vital_category].copy()\n</code></pre>"},{"location":"api/tables/#clifpy.tables.vitals.Vitals.get_vital_summary_stats","title":"get_vital_summary_stats","text":"<pre><code>get_vital_summary_stats()\n</code></pre> <p>Return summary statistics for each vital category.</p> Source code in <code>clifpy/tables/vitals.py</code> <pre><code>def get_vital_summary_stats(self) -&gt; pd.DataFrame:\n    \"\"\"Return summary statistics for each vital category.\"\"\"\n    if self.df is None or 'vital_value' not in self.df.columns:\n        return pd.DataFrame()\n\n    # Convert vital_value to numeric\n    df_copy = self.df.copy()\n    df_copy['vital_value'] = pd.to_numeric(df_copy['vital_value'], errors='coerce')\n\n    # Group by vital category and calculate stats\n    stats = df_copy.groupby('vital_category')['vital_value'].agg([\n        'count', 'mean', 'std', 'min', 'max',\n        ('q1', lambda x: x.quantile(0.25)),\n        ('median', lambda x: x.quantile(0.5)),\n        ('q3', lambda x: x.quantile(0.75))\n    ]).round(2)\n\n    return stats\n</code></pre>"},{"location":"api/tables/#clifpy.tables.vitals.Vitals.isvalid","title":"isvalid","text":"<pre><code>isvalid()\n</code></pre> <p>Return <code>True</code> if the last validation finished without errors.</p> Source code in <code>clifpy/tables/vitals.py</code> <pre><code>def isvalid(self) -&gt; bool:\n    \"\"\"Return ``True`` if the last validation finished without errors.\"\"\"\n    return not self.errors and not self.range_validation_errors\n</code></pre>"},{"location":"api/tables/#clifpy.tables.vitals.Vitals.validate_vital_ranges","title":"validate_vital_ranges","text":"<pre><code>validate_vital_ranges()\n</code></pre> <p>Validate vital values against expected ranges using grouped data for efficiency.</p> Source code in <code>clifpy/tables/vitals.py</code> <pre><code>def validate_vital_ranges(self):\n    \"\"\"Validate vital values against expected ranges using grouped data for efficiency.\"\"\"\n    self.range_validation_errors = []\n\n    if self.df is None or not self._vital_ranges:\n        return\n\n    required_columns = ['vital_category', 'vital_value']\n    required_columns_for_df = ['vital_category', 'vital_value']\n    if not all(col in self.df.columns for col in required_columns_for_df):\n        self.range_validation_errors.append({\n            \"error_type\": \"missing_columns_for_range_validation\",\n            \"columns\": [col for col in required_columns_for_df if col not in self.df.columns],\n            \"message\": \"vital_category or vital_value column missing, cannot perform range validation.\"\n        })\n        return\n\n    # Work on a copy to safely convert vital_value to numeric for aggregation\n    df_for_stats = self.df[required_columns_for_df].copy()\n    df_for_stats['vital_value'] = pd.to_numeric(df_for_stats['vital_value'], errors='coerce')\n\n    # Filter out rows where vital_value could not be converted\n    df_for_stats.dropna(subset=['vital_value'], inplace=True)\n\n    if df_for_stats.empty:\n        # No numeric vital_value data to perform range validation on\n        return\n\n    vital_stats = (df_for_stats\n                   .groupby('vital_category')['vital_value']\n                   .agg(['min', 'max', 'mean', 'count'])\n                   .reset_index())\n\n    if vital_stats.empty:\n        return\n\n    # Check each vital category's ranges\n    for _, row in vital_stats.iterrows():\n        vital_category = row['vital_category']\n        min_val = row['min']\n        max_val = row['max']\n        count = row['count']\n        mean_val = row['mean']\n\n        # Check if vital category has defined ranges\n        if vital_category not in self._vital_ranges:\n            self.range_validation_errors.append({\n                'error_type': 'unknown_vital_category',\n                'vital_category': vital_category,\n                'affected_rows': count,\n                'observed_min': min_val,\n                'observed_max': max_val,\n                'message': f\"Unknown vital category '{vital_category}' found in data.\"\n            })\n            continue\n\n        expected_range = self._vital_ranges[vital_category]\n        expected_min = expected_range.get('min')\n        expected_max = expected_range.get('max')\n\n        # Check if any values are outside the expected range\n        if expected_min is not None and min_val &lt; expected_min:\n            self.range_validation_errors.append({\n                'error_type': 'below_range',\n                'vital_category': vital_category,\n                'observed_min': min_val,\n                'expected_min': expected_min,\n                'message': f\"Values below expected minimum for {vital_category}\"\n            })\n\n        if expected_max is not None and max_val &gt; expected_max:\n            self.range_validation_errors.append({\n                'error_type': 'above_range',\n                'vital_category': vital_category,\n                'observed_max': max_val,\n                'expected_max': expected_max,\n                'message': f\"Values above expected maximum for {vital_category}\"\n            })\n\n    # Add range validation errors to main errors list\n    if self.range_validation_errors:\n        self.errors.extend(self.range_validation_errors)\n        self.logger.warning(f\"Found {len(self.range_validation_errors)} range validation errors\")\n</code></pre>"},{"location":"api/tables/#respiratory-support","title":"Respiratory Support","text":""},{"location":"api/tables/#clifpy.tables.respiratory_support.RespiratorySupport","title":"clifpy.tables.respiratory_support.RespiratorySupport","text":"<pre><code>RespiratorySupport(\n    data_directory=None,\n    filetype=None,\n    timezone=\"UTC\",\n    output_directory=None,\n    data=None,\n)\n</code></pre> <p>               Bases: <code>BaseTable</code></p> <p>Respiratory support table wrapper inheriting from BaseTable.</p> <p>This class handles respiratory support data and validations while leveraging the common functionality provided by BaseTable.</p> <p>Initialize the respiratory_support table.</p> <p>Parameters:</p> Name Type Description Default <code>data_directory</code> <code>str</code> <p>Path to the directory containing data files</p> <code>None</code> <code>filetype</code> <code>str</code> <p>Type of data file (csv, parquet, etc.)</p> <code>None</code> <code>timezone</code> <code>str</code> <p>Timezone for datetime columns</p> <code>'UTC'</code> <code>output_directory</code> <code>str</code> <p>Directory for saving output files and logs</p> <code>None</code> <code>data</code> <code>DataFrame</code> <p>Pre-loaded data to use instead of loading from file</p> <code>None</code> Source code in <code>clifpy/tables/respiratory_support.py</code> <pre><code>def __init__(\n    self,\n    data_directory: str = None,\n    filetype: str = None,\n    timezone: str = \"UTC\",\n    output_directory: Optional[str] = None,\n    data: Optional[pd.DataFrame] = None\n):\n    \"\"\"\n    Initialize the respiratory_support table.\n\n    Parameters:\n        data_directory (str): Path to the directory containing data files\n        filetype (str): Type of data file (csv, parquet, etc.)\n        timezone (str): Timezone for datetime columns\n        output_directory (str, optional): Directory for saving output files and logs\n        data (pd.DataFrame, optional): Pre-loaded data to use instead of loading from file\n    \"\"\"\n\n    super().__init__(\n        data_directory=data_directory,\n        filetype=filetype,\n        timezone=timezone,\n        output_directory=output_directory,\n        data=data\n    )\n</code></pre>"},{"location":"api/tables/#medication-administration-continuous","title":"Medication Administration (Continuous)","text":""},{"location":"api/tables/#clifpy.tables.medication_admin_continuous.MedicationAdminContinuous","title":"clifpy.tables.medication_admin_continuous.MedicationAdminContinuous","text":"<pre><code>MedicationAdminContinuous(\n    data_directory=None,\n    filetype=None,\n    timezone=\"UTC\",\n    output_directory=None,\n    data=None,\n)\n</code></pre> <p>               Bases: <code>BaseTable</code></p> <p>Medication administration continuous table wrapper inheriting from BaseTable.</p> <p>This class handles medication administration continuous data and validations while leveraging the common functionality provided by BaseTable.</p> <p>Initialize the medication_admin_continuous table.</p> <p>Parameters:</p> Name Type Description Default <code>data_directory</code> <code>str</code> <p>Path to the directory containing data files</p> <code>None</code> <code>filetype</code> <code>str</code> <p>Type of data file (csv, parquet, etc.)</p> <code>None</code> <code>timezone</code> <code>str</code> <p>Timezone for datetime columns</p> <code>'UTC'</code> <code>output_directory</code> <code>str</code> <p>Directory for saving output files and logs</p> <code>None</code> <code>data</code> <code>DataFrame</code> <p>Pre-loaded data to use instead of loading from file</p> <code>None</code> Source code in <code>clifpy/tables/medication_admin_continuous.py</code> <pre><code>def __init__(\n    self,\n    data_directory: str = None,\n    filetype: str = None,\n    timezone: str = \"UTC\",\n    output_directory: Optional[str] = None,\n    data: Optional[pd.DataFrame] = None\n):\n    \"\"\"\n    Initialize the medication_admin_continuous table.\n\n    Parameters:\n        data_directory (str): Path to the directory containing data files\n        filetype (str): Type of data file (csv, parquet, etc.)\n        timezone (str): Timezone for datetime columns\n        output_directory (str, optional): Directory for saving output files and logs\n        data (pd.DataFrame, optional): Pre-loaded data to use instead of loading from file\n    \"\"\"\n    # For backward compatibility, handle the old signature\n    if data_directory is None and filetype is None and data is not None:\n        # Old signature: medication_admin_continuous(data)\n        # Use dummy values for required parameters\n        data_directory = \".\"\n        filetype = \"parquet\"\n\n    # Load medication mappings\n    self._med_category_to_group = None\n\n    super().__init__(\n        data_directory=data_directory,\n        filetype=filetype,\n        timezone=timezone,\n        output_directory=output_directory,\n        data=data\n    )\n\n    # Load medication-specific schema data\n    self._load_medication_schema_data()\n</code></pre>"},{"location":"api/tables/#clifpy.tables.medication_admin_continuous.MedicationAdminContinuous.med_category_to_group_mapping","title":"med_category_to_group_mapping  <code>property</code>","text":"<pre><code>med_category_to_group_mapping\n</code></pre> <p>Get the medication category to group mapping from the schema.</p>"},{"location":"api/tables/#patient-assessments","title":"Patient Assessments","text":""},{"location":"api/tables/#clifpy.tables.patient_assessments.PatientAssessments","title":"clifpy.tables.patient_assessments.PatientAssessments","text":"<pre><code>PatientAssessments(\n    data_directory=None,\n    filetype=None,\n    timezone=\"UTC\",\n    output_directory=None,\n    data=None,\n)\n</code></pre> <p>               Bases: <code>BaseTable</code></p> <p>Patient assessments table wrapper inheriting from BaseTable.</p> <p>This class handles patient assessment data and validations while leveraging the common functionality provided by BaseTable.</p> <p>Initialize the patient_assessments table.</p> <p>Parameters:</p> Name Type Description Default <code>data_directory</code> <code>str</code> <p>Path to the directory containing data files</p> <code>None</code> <code>filetype</code> <code>str</code> <p>Type of data file (csv, parquet, etc.)</p> <code>None</code> <code>timezone</code> <code>str</code> <p>Timezone for datetime columns</p> <code>'UTC'</code> <code>output_directory</code> <code>str</code> <p>Directory for saving output files and logs</p> <code>None</code> <code>data</code> <code>DataFrame</code> <p>Pre-loaded data to use instead of loading from file</p> <code>None</code> Source code in <code>clifpy/tables/patient_assessments.py</code> <pre><code>def __init__(\n    self,\n    data_directory: str = None,\n    filetype: str = None,\n    timezone: str = \"UTC\",\n    output_directory: Optional[str] = None,\n    data: Optional[pd.DataFrame] = None\n):\n    \"\"\"\n    Initialize the patient_assessments table.\n\n    Parameters:\n        data_directory (str): Path to the directory containing data files\n        filetype (str): Type of data file (csv, parquet, etc.)\n        timezone (str): Timezone for datetime columns\n        output_directory (str, optional): Directory for saving output files and logs\n        data (pd.DataFrame, optional): Pre-loaded data to use instead of loading from file\n    \"\"\"\n    # For backward compatibility, handle the old signature\n    if data_directory is None and filetype is None and data is not None:\n        # Old signature: patient_assessments(data)\n        # Use dummy values for required parameters\n        data_directory = \".\"\n        filetype = \"parquet\"\n\n    # Initialize assessment mappings\n    self._assessment_category_to_group = None\n\n    super().__init__(\n        data_directory=data_directory,\n        filetype=filetype,\n        timezone=timezone,\n        output_directory=output_directory,\n        data=data\n    )\n\n    # Load assessment-specific schema data\n    self._load_assessment_schema_data()\n</code></pre>"},{"location":"api/tables/#clifpy.tables.patient_assessments.PatientAssessments.assessment_category_to_group_mapping","title":"assessment_category_to_group_mapping  <code>property</code>","text":"<pre><code>assessment_category_to_group_mapping\n</code></pre> <p>Get the assessment category to group mapping from the schema.</p>"},{"location":"api/tables/#position","title":"Position","text":""},{"location":"api/tables/#clifpy.tables.position.Position","title":"clifpy.tables.position.Position","text":"<pre><code>Position(\n    data_directory=None,\n    filetype=None,\n    timezone=\"UTC\",\n    output_directory=None,\n    data=None,\n)\n</code></pre> <p>               Bases: <code>BaseTable</code></p> <p>Position table wrapper inheriting from BaseTable.</p> <p>This class handles patient position data and validations while leveraging the common functionality provided by BaseTable.</p> <p>Initialize the position table.</p> <p>Parameters:</p> Name Type Description Default <code>data_directory</code> <code>str</code> <p>Path to the directory containing data files</p> <code>None</code> <code>filetype</code> <code>str</code> <p>Type of data file (csv, parquet, etc.)</p> <code>None</code> <code>timezone</code> <code>str</code> <p>Timezone for datetime columns</p> <code>'UTC'</code> <code>output_directory</code> <code>str</code> <p>Directory for saving output files and logs</p> <code>None</code> <code>data</code> <code>DataFrame</code> <p>Pre-loaded data to use instead of loading from file</p> <code>None</code> Source code in <code>clifpy/tables/position.py</code> <pre><code>def __init__(\n    self,\n    data_directory: str = None,\n    filetype: str = None,\n    timezone: str = \"UTC\",\n    output_directory: Optional[str] = None,\n    data: Optional[pd.DataFrame] = None\n):\n    \"\"\"\n    Initialize the position table.\n\n    Parameters:\n        data_directory (str): Path to the directory containing data files\n        filetype (str): Type of data file (csv, parquet, etc.)\n        timezone (str): Timezone for datetime columns\n        output_directory (str, optional): Directory for saving output files and logs\n        data (pd.DataFrame, optional): Pre-loaded data to use instead of loading from file\n    \"\"\"\n    # For backward compatibility, handle the old signature\n    if data_directory is None and filetype is None and data is not None:\n        # Old signature: position(data)\n        # Use dummy values for required parameters\n        data_directory = \".\"\n        filetype = \"parquet\"\n\n    super().__init__(\n        data_directory=data_directory,\n        filetype=filetype,\n        timezone=timezone,\n        output_directory=output_directory,\n        data=data\n    )\n</code></pre>"},{"location":"api/tables/#clifpy.tables.position.Position.get_position_category_stats","title":"get_position_category_stats","text":"<pre><code>get_position_category_stats()\n</code></pre> <p>Return summary statistics for each position category, including missingness and unique patient counts. Expects columns: 'position_category', 'position_name', and optionally 'hospitalization_id'.</p> Source code in <code>clifpy/tables/position.py</code> <pre><code>def get_position_category_stats(self) -&gt; pd.DataFrame:\n    \"\"\"\n    Return summary statistics for each position category, including missingness and unique patient counts.\n    Expects columns: 'position_category', 'position_name', and optionally 'hospitalization_id'.\n    \"\"\"\n    if self.df is None or 'position_category' not in self.df.columns or 'hospitalization_id' not in self.df.columns:\n        return {\"status\": \"Missing columns\"}\n\n    agg_dict = {\n        'count': ('position_category', 'count'),\n        'unique': ('hospitalization_id', 'nunique'),\n    }\n\n    stats = (\n        self.df\n        .groupby('position_category')\n        .agg(**agg_dict)\n        .round(2)\n    )\n\n    return stats\n</code></pre>"},{"location":"examples/","title":"Examples","text":"<p>This section provides practical examples of using CLIFpy for common ICU data analysis tasks.</p>"},{"location":"examples/#available-examples","title":"Available Examples","text":""},{"location":"examples/#loading-data","title":"Loading Data","text":"<p>Learn different ways to load CLIF data, including: - Loading from CSV and Parquet files - Using filters and column selection - Working with sample data - Handling large datasets efficiently</p>"},{"location":"examples/#analyzing-icu-stays","title":"Analyzing ICU Stays","text":"<p>Common ICU analysis patterns: - Identifying ICU admissions - Calculating length of stay - Tracking patient movement - Analyzing severity of illness</p>"},{"location":"examples/#clinical-calculations","title":"Clinical Calculations","text":"<p>Implement clinical calculations and scores: - Calculating SOFA scores - Tracking vasopressor requirements - Monitoring ventilation parameters - Assessing prone positioning compliance</p>"},{"location":"examples/#quick-examples","title":"Quick Examples","text":""},{"location":"examples/#basic-data-loading","title":"Basic Data Loading","text":"<pre><code>from clifpy.tables import Patient, Labs, Vitals\nfrom clifpy.clif_orchestrator import ClifOrchestrator\n\n# Load individual tables\npatient = Patient.from_file('/data', 'parquet', timezone='US/Central')\nlabs = Labs.from_file('/data', 'parquet', timezone='US/Central')\n\n# Or use orchestrator for multiple tables\norchestrator = ClifOrchestrator('/data', 'parquet', 'US/Central')\norchestrator.initialize(tables=['patient', 'labs', 'vitals', 'adt'])\n</code></pre>"},{"location":"examples/#finding-icu-patients","title":"Finding ICU Patients","text":"<pre><code># Get ICU admissions\nicu_stays = orchestrator.adt.filter_by_location_category('icu')\nicu_patients = icu_stays['patient_id'].unique()\n\n# Get their demographics\nicu_demographics = orchestrator.patient.df[\n    orchestrator.patient.df['patient_id'].isin(icu_patients)\n]\n</code></pre>"},{"location":"examples/#analyzing-lab-trends","title":"Analyzing Lab Trends","text":"<pre><code># Get recent abnormal labs\nrecent_labs = orchestrator.labs.get_recent(hours=24)\nabnormal = recent_labs[\n    (recent_labs['lab_name'] == 'creatinine') &amp; \n    (recent_labs['lab_value'] &gt; 2.0)\n]\n\n# Track patient's lab trend\npatient_labs = orchestrator.labs.df[\n    orchestrator.labs.df['patient_id'] == 'P12345'\n].sort_values('lab_datetime')\n</code></pre>"},{"location":"examples/#medication-analysis","title":"Medication Analysis","text":"<pre><code># Find patients on multiple vasopressors\nvasopressors = orchestrator.medication_admin_continuous.filter_by_med_group('vasopressor')\nconcurrent = orchestrator.medication_admin_continuous.get_concurrent_medications('P12345')\nmulti_pressor = concurrent[concurrent['medication_group'] == 'vasopressor']\n</code></pre>"},{"location":"examples/#example-notebooks","title":"Example Notebooks","text":"<p>The repository includes Jupyter notebooks demonstrating: - <code>labs_demo.ipynb</code> - Laboratory data analysis - <code>respiratory_support_demo.ipynb</code> - Ventilation analysis - <code>position_demo.ipynb</code> - Prone positioning analysis</p>"},{"location":"examples/#next-steps","title":"Next Steps","text":"<ul> <li>Explore specific examples in detail</li> <li>Review the API documentation</li> <li>See the User Guide for comprehensive coverage</li> </ul>"},{"location":"getting-started/basic-usage/","title":"Basic Usage","text":"<p>This guide covers the fundamental patterns for working with CLIFpy.</p>"},{"location":"getting-started/basic-usage/#core-concepts","title":"Core Concepts","text":""},{"location":"getting-started/basic-usage/#table-classes","title":"Table Classes","text":"<p>Each CLIF table is represented by a Python class that inherits from <code>BaseTable</code>:</p> <ul> <li><code>Patient</code> - Demographics and patient identification</li> <li><code>Adt</code> - Admission, discharge, and transfer events</li> <li><code>Hospitalization</code> - Hospital stay information</li> <li><code>Labs</code> - Laboratory test results</li> <li><code>Vitals</code> - Vital signs measurements</li> <li><code>RespiratorySupport</code> - Ventilation and oxygen therapy</li> <li><code>MedicationAdminContinuous</code> - Continuous infusions</li> <li><code>PatientAssessments</code> - Clinical assessment scores</li> <li><code>Position</code> - Patient positioning</li> </ul>"},{"location":"getting-started/basic-usage/#data-loading","title":"Data Loading","text":"<p>All tables support two loading methods:</p> <pre><code># Method 1: From files\ntable = TableClass.from_file(\n    data_directory='/path/to/data',\n    filetype='parquet',  # or 'csv'\n    timezone='US/Central'\n)\n\n# Method 2: From existing DataFrame\ntable = TableClass(\n    data=existing_dataframe,\n    timezone='US/Central'\n)\n</code></pre>"},{"location":"getting-started/basic-usage/#validation","title":"Validation","text":"<p>Every table includes built-in validation:</p> <pre><code># Run validation\ntable.validate()\n\n# Check if valid\nif table.isvalid():\n    print(\"Validation passed!\")\nelse:\n    # Review errors\n    for error in table.errors[:5]:\n        print(f\"{error['type']}: {error['message']}\")\n</code></pre>"},{"location":"getting-started/basic-usage/#working-with-dataframes","title":"Working with DataFrames","text":"<p>All table data is accessible via the <code>df</code> attribute:</p> <pre><code># Access the underlying DataFrame\ndf = table.df\n\n# Use standard pandas operations\nprint(df.shape)\nprint(df.columns.tolist())\nprint(df.dtypes)\n\n# Filter data\nfiltered = df[df['some_column'] &gt; threshold]\n</code></pre>"},{"location":"getting-started/basic-usage/#common-operations","title":"Common Operations","text":""},{"location":"getting-started/basic-usage/#date-range-filtering","title":"Date Range Filtering","text":"<p>Most tables with datetime columns support date range filtering:</p> <pre><code>from datetime import datetime\n\n# Filter by date range\nstart = datetime(2023, 1, 1)\nend = datetime(2023, 12, 31)\n\n# For tables with custom methods\nfiltered = table.filter_by_date_range(start, end)\n\n# Or using pandas\nmask = (df['datetime_column'] &gt;= start) &amp; (df['datetime_column'] &lt;= end)\nfiltered = df[mask]\n</code></pre>"},{"location":"getting-started/basic-usage/#category-filtering","title":"Category Filtering","text":"<p>Tables with standardized categories provide filtering methods:</p> <pre><code># Labs by category\nchemistry = labs.filter_by_category('chemistry')\nhematology = labs.filter_by_category('hematology')\n\n# ADT by location\nicu_stays = adt.filter_by_location_category('icu')\ned_visits = adt.filter_by_location_category('ed')\n\n# Medications by group\nvasopressors = meds.filter_by_med_group('vasopressor')\nsedatives = meds.filter_by_med_group('sedative')\n</code></pre>"},{"location":"getting-started/basic-usage/#patient-specific-data","title":"Patient-specific Data","text":"<pre><code># Single patient\npatient_id = 'P12345'\npatient_labs = labs.df[labs.df['patient_id'] == patient_id]\n\n# Multiple patients\npatient_ids = ['P001', 'P002', 'P003']\ncohort_data = vitals.df[vitals.df['patient_id'].isin(patient_ids)]\n</code></pre>"},{"location":"getting-started/basic-usage/#output-and-reporting","title":"Output and Reporting","text":""},{"location":"getting-started/basic-usage/#summary-statistics","title":"Summary Statistics","text":"<pre><code># Get table summary\nsummary = table.get_summary()\nprint(f\"Rows: {summary['num_rows']}\")\nprint(f\"Columns: {summary['num_columns']}\")\nprint(f\"Memory usage: {summary['memory_usage_mb']:.2f} MB\")\n\n# Save summary to file\ntable.save_summary()\n</code></pre>"},{"location":"getting-started/basic-usage/#validation-reports","title":"Validation Reports","text":"<p>Validation results are automatically saved to the output directory:</p> <pre><code># Set custom output directory\ntable = TableClass.from_file(\n    data_directory='/path/to/data',\n    filetype='parquet',\n    output_directory='/path/to/reports'\n)\n\n# After validation, check output files:\n# - validation_log_[table_name].log\n# - validation_errors_[table_name].csv\n# - missing_data_stats_[table_name].csv\n</code></pre>"},{"location":"getting-started/basic-usage/#timezone-handling","title":"Timezone Handling","text":"<p>CLIFpy ensures consistent timezone handling:</p> <pre><code># Specify timezone when loading\ntable = TableClass.from_file(\n    data_directory='/path/to/data',\n    filetype='parquet',\n    timezone='US/Central'  # All datetime columns converted to this timezone\n)\n\n# Datetime columns are timezone-aware\nprint(table.df['datetime_column'].dt.tz)\n</code></pre>"},{"location":"getting-started/basic-usage/#memory-management","title":"Memory Management","text":"<p>For large datasets:</p> <pre><code># Load only specific columns\ntable = TableClass.from_file(\n    data_directory='/path/to/data',\n    filetype='parquet',\n    columns=['patient_id', 'datetime', 'value']\n)\n\n# Load a sample\ntable = TableClass.from_file(\n    data_directory='/path/to/data',\n    filetype='parquet',\n    sample_size=10000\n)\n\n# Apply filters during loading\ntable = TableClass.from_file(\n    data_directory='/path/to/data',\n    filetype='parquet',\n    filters={'patient_id': patient_list}\n)\n</code></pre>"},{"location":"getting-started/basic-usage/#error-handling","title":"Error Handling","text":"<pre><code>try:\n    table = TableClass.from_file('/path/to/data', 'parquet')\n    table.validate()\n\n    if not table.isvalid():\n        # Handle validation errors\n        error_df = pd.DataFrame(table.errors)\n        error_df.to_csv('validation_errors.csv', index=False)\n\nexcept FileNotFoundError:\n    print(\"Data files not found\")\nexcept Exception as e:\n    print(f\"Error loading data: {e}\")\n</code></pre>"},{"location":"getting-started/basic-usage/#next-steps","title":"Next Steps","text":"<ul> <li>Explore the full User Guide</li> <li>Learn about the Orchestrator</li> <li>See table-specific guides</li> <li>View practical examples</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>This guide will help you install CLIFpy and its dependencies.</p>"},{"location":"getting-started/installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.9 or higher</li> <li>pip (Python package installer)</li> </ul>"},{"location":"getting-started/installation/#basic-installation","title":"Basic Installation","text":""},{"location":"getting-started/installation/#from-pypi-recommended","title":"From PyPI (Recommended)","text":"<pre><code>pip install clifpy\n</code></pre>"},{"location":"getting-started/installation/#from-source","title":"From Source","text":"<p>Clone the repository and install in development mode:</p> <pre><code># Clone the repository\ngit clone https://github.com/Common-Longitudinal-ICU-data-Format/CLIFpy.git\ncd CLIFpy\n\n# Create a virtual environment (recommended)\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n\n# Install in development mode\npip install -e .\n</code></pre>"},{"location":"getting-started/installation/#optional-dependencies","title":"Optional Dependencies","text":""},{"location":"getting-started/installation/#documentation","title":"Documentation","text":"<p>To build the documentation locally:</p> <pre><code>pip install clifpy[docs]\n</code></pre>"},{"location":"getting-started/installation/#verifying-installation","title":"Verifying Installation","text":"<p>After installation, verify that CLIFpy is properly installed:</p> <pre><code>import clifpy\nprint(clifpy.__version__)\n</code></pre> <p>You should see the version number (e.g., <code>0.0.1</code>).</p>"},{"location":"getting-started/installation/#dependencies","title":"Dependencies","text":"<p>CLIFpy automatically installs the following dependencies:</p> <ul> <li>pandas: Data manipulation and analysis</li> <li>duckdb: SQL analytics engine</li> <li>pyarrow: Parquet file support</li> <li>pytz: Timezone handling</li> <li>matplotlib &amp; seaborn: Visualization (for demos)</li> <li>pytest: Testing framework</li> <li>tqdm: Progress bars</li> <li>marimo: Interactive notebooks</li> </ul>"},{"location":"getting-started/installation/#platform-support","title":"Platform Support","text":"<p>CLIFpy is tested on:</p> <ul> <li>Linux (Ubuntu 20.04+)</li> <li>macOS (10.15+)</li> <li>Windows (10+)</li> </ul>"},{"location":"getting-started/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/installation/#import-errors","title":"Import Errors","text":"<p>If you encounter import errors, ensure you're using the correct Python environment:</p> <pre><code>which python\npython --version\n</code></pre>"},{"location":"getting-started/installation/#permission-errors","title":"Permission Errors","text":"<p>On some systems, you may need to use <code>pip install --user</code>:</p> <pre><code>pip install --user clifpy\n</code></pre>"},{"location":"getting-started/installation/#dependency-conflicts","title":"Dependency Conflicts","text":"<p>If you encounter dependency conflicts, consider using a virtual environment:</p> <pre><code>python -m venv clifpy-env\nsource clifpy-env/bin/activate  # On Windows: clifpy-env\\Scripts\\activate\npip install clifpy\n</code></pre>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Follow the Quick Start guide</li> <li>Learn about basic usage</li> <li>Explore the User Guide</li> </ul>"},{"location":"getting-started/quickstart/","title":"Quick Start","text":"<p>This guide will get you up and running with CLIFpy in just a few minutes.</p>"},{"location":"getting-started/quickstart/#loading-demo-data","title":"Loading Demo Data","text":"<p>CLIFpy includes demo data to help you get started:</p> <pre><code>from clifpy.data import load_dataset\n\n# Load all demo tables\ntables = load_dataset()\n\n# Access individual tables\npatient_df = tables['patient']\nlabs_df = tables['labs']\nvitals_df = tables['vitals']\n</code></pre>"},{"location":"getting-started/quickstart/#using-individual-tables","title":"Using Individual Tables","text":""},{"location":"getting-started/quickstart/#loading-a-single-table","title":"Loading a Single Table","text":"<pre><code>from clifpy.tables import Patient\n\n# Load patient data from files\npatient = Patient.from_file(\n    data_directory='/path/to/data',\n    filetype='parquet',\n    timezone='US/Central'\n)\n\n# Validate the data\npatient.validate()\n\n# Check if data is valid\nif patient.isvalid():\n    print(\"Data validation passed!\")\nelse:\n    print(f\"Found {len(patient.errors)} validation errors\")\n</code></pre>"},{"location":"getting-started/quickstart/#working-with-lab-data","title":"Working with Lab Data","text":"<pre><code>from clifpy.tables import Labs\n\n# Load lab data\nlabs = Labs.from_file('/path/to/data', 'parquet')\n\n# Get recent lab results\nrecent_labs = labs.get_recent(hours=24)\n\n# Filter by lab category\nchemistry_labs = labs.filter_by_category('chemistry')\n\n# Get common lab panels\ncbc = labs.get_common_labs('cbc')\nbmp = labs.get_common_labs('bmp')\n</code></pre>"},{"location":"getting-started/quickstart/#analyzing-vital-signs","title":"Analyzing Vital Signs","text":"<pre><code>from clifpy.tables import Vitals\n\n# Load vitals data\nvitals = Vitals.from_file('/path/to/data', 'parquet')\n\n# Get specific vital types\nheart_rates = vitals.filter_by_vital_type('heart_rate')\nblood_pressures = vitals.filter_by_vital_type('sbp')\n\n# Calculate summary statistics\nhr_stats = vitals.get_summary_by_vital_type()\nprint(hr_stats)\n</code></pre>"},{"location":"getting-started/quickstart/#using-the-orchestrator","title":"Using the Orchestrator","text":"<p>For working with multiple tables at once:</p> <pre><code>from clifpy.clif_orchestrator import ClifOrchestrator\n\n# Initialize orchestrator\norchestrator = ClifOrchestrator(\n    data_directory='/path/to/data',\n    filetype='parquet',\n    timezone='US/Central'\n)\n\n# Load multiple tables\norchestrator.initialize(\n    tables=['patient', 'labs', 'vitals', 'adt'],\n    sample_size=1000  # Optional: load sample for testing\n)\n\n# Validate all tables\norchestrator.validate_all()\n\n# Get summary of loaded tables\nloaded = orchestrator.get_loaded_tables()\nprint(f\"Loaded tables: {loaded}\")\n</code></pre>"},{"location":"getting-started/quickstart/#common-patterns","title":"Common Patterns","text":""},{"location":"getting-started/quickstart/#filtering-by-patient","title":"Filtering by Patient","text":"<pre><code># Get data for specific patients\npatient_ids = ['P001', 'P002', 'P003']\n\n# Filter labs\npatient_labs = labs.df[labs.df['patient_id'].isin(patient_ids)]\n\n# Filter vitals\npatient_vitals = vitals.df[vitals.df['patient_id'].isin(patient_ids)]\n</code></pre>"},{"location":"getting-started/quickstart/#time-based-analysis","title":"Time-based Analysis","text":"<pre><code>from datetime import datetime, timedelta\n\n# Get data from the last 7 days\nend_date = datetime.now()\nstart_date = end_date - timedelta(days=7)\n\n# Filter ADT movements\nrecent_movements = adt.filter_by_date_range(start_date, end_date)\n\n# Get ICU admissions\nicu_admissions = adt.filter_by_location_category('icu')\n</code></pre>"},{"location":"getting-started/quickstart/#clinical-calculations","title":"Clinical Calculations","text":"<pre><code># Calculate SOFA scores\nfrom clifpy.tables import PatientAssessments\n\nassessments = PatientAssessments.from_file('/path/to/data', 'parquet')\n\n# Get assessment trends\ngcs_trend = assessments.get_assessment_trend(\n    patient_id='P001',\n    assessment_category='neurological',\n    hours=48\n)\n\n# Check compliance\ncompliance = assessments.get_assessment_compliance(\n    assessment_category='pain',\n    expected_frequency_hours=4\n)\n</code></pre>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about basic usage patterns</li> <li>Explore the full User Guide</li> <li>See more examples</li> <li>Read the API documentation</li> </ul>"},{"location":"user-guide/","title":"User Guide","text":"<p>Welcome to the CLIFpy User Guide. This guide provides comprehensive documentation for working with CLIF data using CLIFpy.</p>"},{"location":"user-guide/#overview","title":"Overview","text":"<p>CLIFpy is designed to make working with CLIF (Common Longitudinal ICU data Format) data straightforward and efficient. Whether you're a researcher analyzing ICU outcomes, a data scientist building predictive models, or a clinician exploring patient data, this guide will help you make the most of CLIFpy.</p>"},{"location":"user-guide/#guide-organization","title":"Guide Organization","text":""},{"location":"user-guide/#clif-orchestrator","title":"CLIF Orchestrator","text":"<p>Learn how to manage multiple CLIF tables simultaneously with consistent configuration and validation.</p>"},{"location":"user-guide/#tables","title":"Tables","text":"<p>Detailed guides for each CLIF table type: </p> <ul> <li>Patient demographics</li> <li>ADT (Admission, Discharge, Transfer) events</li> <li>Hospitalization information</li> <li>Laboratory results</li> <li>Vital signs</li> <li>Respiratory support</li> <li>Medication administration</li> <li>Clinical assessments</li> <li>Patient positioning</li> </ul>"},{"location":"user-guide/#data-validation","title":"Data Validation","text":"<p>Understand how CLIFpy validates your data against CLIF schemas and how to interpret validation results.</p>"},{"location":"user-guide/#working-with-timezones","title":"Working with Timezones","text":"<p>Learn best practices for handling timezone-aware datetime data across different hospital systems.</p>"},{"location":"user-guide/#key-concepts","title":"Key Concepts","text":""},{"location":"user-guide/#table-based-architecture","title":"Table-Based Architecture","text":"<p>CLIFpy organizes ICU data into standardized tables, each representing a specific aspect of patient care:</p> <pre><code>from clifpy.tables import Patient, Labs, Vitals\n\n# Each table is a self-contained unit\npatient = Patient.from_file('/data', 'parquet')\nlabs = Labs.from_file('/data', 'parquet')\nvitals = Vitals.from_file('/data', 'parquet')\n</code></pre>"},{"location":"user-guide/#consistent-interface","title":"Consistent Interface","text":"<p>All tables share common methods inherited from <code>BaseTable</code>: </p> <ul> <li><code>from_file()</code> - Load data from files</li> <li><code>validate()</code> - Run comprehensive validation</li> <li><code>isvalid()</code> - Check validation status</li> <li><code>get_summary()</code> - Get table statistics</li> </ul>"},{"location":"user-guide/#standardized-categories","title":"Standardized Categories","text":"<p>CLIF defines standardized categories for consistent data representation: - Lab categories: chemistry, hematology, coagulation, etc. - Location categories: icu, ward, ed, etc. - Medication groups: vasopressor, sedative, antibiotic, etc.</p>"},{"location":"user-guide/#timezone-awareness","title":"Timezone Awareness","text":"<p>All datetime columns are timezone-aware to handle data from different time zones correctly:</p> <pre><code># Specify timezone when loading\ntable = TableClass.from_file(\n    data_directory='/data',\n    filetype='parquet',\n    timezone='US/Central'\n)\n</code></pre>"},{"location":"user-guide/#common-workflows","title":"Common Workflows","text":""},{"location":"user-guide/#loading-and-validating-data","title":"Loading and Validating Data","text":"<pre><code>from clifpy.clif_orchestrator import ClifOrchestrator\n\n# Load multiple tables\norchestrator = ClifOrchestrator('/data', 'parquet', 'US/Central')\norchestrator.initialize(tables=['patient', 'labs', 'vitals'])\n\n# Validate all tables\norchestrator.validate_all()\n\n# Check validation status\nfor table_name in orchestrator.get_loaded_tables():\n    table = getattr(orchestrator, table_name)\n    print(f\"{table_name}: {'Valid' if table.isvalid() else 'Invalid'}\")\n</code></pre>"},{"location":"user-guide/#filtering-and-analysis","title":"Filtering and Analysis","text":"<pre><code># Category-based filtering\nicu_stays = adt.filter_by_location_category('icu')\n\n# Patient cohort analysis \ncohort_ids = ['P001', 'P002', 'P003']\ncohort_vitals = vitals.df[vitals.df['hospitalization_id'].isin(cohort_ids)]\n</code></pre>"},{"location":"user-guide/#best-practices","title":"Best Practices","text":"<ol> <li>Always validate data after loading to ensure compliance with CLIF standards</li> <li>Use appropriate timezones for your data source</li> <li>Filter early to reduce memory usage with large datasets</li> <li>Review validation errors to understand data quality issues</li> <li>Use the orchestrator when working with multiple related tables</li> </ol>"},{"location":"user-guide/#next-steps","title":"Next Steps","text":"<ul> <li>Explore specific table guides</li> <li>Learn about data validation</li> <li>See practical examples</li> <li>Review the API reference</li> </ul>"},{"location":"user-guide/orchestrator/","title":"CLIF Orchestrator","text":"<p>The <code>ClifOrchestrator</code> class provides a centralized interface for managing multiple CLIF tables with consistent configuration. This guide covers how to use the orchestrator effectively.</p>"},{"location":"user-guide/orchestrator/#overview","title":"Overview","text":"<p>The orchestrator simplifies working with multiple CLIF tables by:</p> <ul> <li>Ensuring consistent configuration across all tables</li> <li>Providing bulk operations (load, validate)</li> <li>Managing shared settings (timezone, file format, output directory)</li> <li>Offering a unified interface for multi-table workflows</li> </ul>"},{"location":"user-guide/orchestrator/#basic-usage","title":"Basic Usage","text":""},{"location":"user-guide/orchestrator/#initialization","title":"Initialization","text":"<pre><code>from clifpy.clif_orchestrator import ClifOrchestrator\n\n# Create orchestrator with your data configuration\norchestrator = ClifOrchestrator(\n    data_directory='/path/to/clif/data',\n    filetype='parquet',  # or 'csv'\n    timezone='US/Central',\n    output_directory='/path/to/outputs'  # Optional\n)\n</code></pre>"},{"location":"user-guide/orchestrator/#loading-tables","title":"Loading Tables","text":"<pre><code># Load specific tables\norchestrator.initialize(tables=['patient', 'labs', 'vitals'])\n\n# Load all available tables\nall_tables = ['patient', 'hospitalization', 'adt', 'labs', 'vitals',\n              'medication_admin_continuous', 'patient_assessments',\n              'respiratory_support', 'position']\norchestrator.initialize(tables=all_tables)\n\n# Load with sampling (useful for testing)\norchestrator.initialize(\n    tables=['patient', 'labs'],\n    sample_size=1000\n)\n</code></pre>"},{"location":"user-guide/orchestrator/#accessing-tables","title":"Accessing Tables","text":"<p>Once loaded, tables are available as attributes:</p> <pre><code># Access individual tables\npatient_data = orchestrator.patient\nlabs_data = orchestrator.labs\nvitals_data = orchestrator.vitals\n\n# Get the underlying DataFrames\npatient_df = orchestrator.patient.df\nlabs_df = orchestrator.labs.df\n</code></pre>"},{"location":"user-guide/orchestrator/#advanced-usage","title":"Advanced Usage","text":""},{"location":"user-guide/orchestrator/#selective-column-loading","title":"Selective Column Loading","text":"<p>Load only specific columns to reduce memory usage:</p> <pre><code>orchestrator.initialize(\n    tables=['labs', 'vitals'],\n    columns={\n        'labs': ['hospitalization_id', 'lab_result_dttm', 'lab_value', 'lab_name'],\n        'vitals': ['hospitalization_id', 'recorded_dttm', 'vital_value']\n    }\n)\n</code></pre>"},{"location":"user-guide/orchestrator/#filtered-loading","title":"Filtered Loading","text":"<p>Apply filters during loading:</p> <pre><code># Filter by patient IDs\nhospitalization_ids = ['P001', 'P002', 'P003']\norchestrator.initialize(\n    tables=['labs', 'vitals'],\n    filters={\n        'labs': {'hospitalization_id': patient_ids},\n        'vitals': {'hospitalization_id': patient_ids}\n    }\n)\n\n# Filter by categories\norchestrator.initialize(\n    tables=['labs', 'adt'],\n    filters={\n        'labs': {'lab_category': 'lactate'},\n        'adt': {'location_category': 'icu'}\n    }\n)\n</code></pre>"},{"location":"user-guide/orchestrator/#validation-workflow","title":"Validation Workflow","text":"<pre><code># Validate all loaded tables\norchestrator.validate_all()\n\n# Check which tables are valid\nfor table_name in orchestrator.get_loaded_tables():\n    table = getattr(orchestrator, table_name)\n    if table.isvalid():\n        print(f\"\u2713 {table_name} passed validation\")\n    else:\n        print(f\"\u2717 {table_name} has {len(table.errors)} errors\")\n</code></pre>"},{"location":"user-guide/orchestrator/#utility-methods","title":"Utility Methods","text":""},{"location":"user-guide/orchestrator/#get-loaded-tables","title":"Get Loaded Tables","text":"<pre><code># List of loaded table names\nloaded = orchestrator.get_loaded_tables()\nprint(f\"Loaded tables: {', '.join(loaded)}\")\n\n# Get table objects\ntable_objects = orchestrator.get_tables_obj_list()\nfor table in table_objects:\n    print(f\"{table.table_name}: {len(table.df)} rows\")\n</code></pre>"},{"location":"user-guide/orchestrator/#individual-table-loading","title":"Individual Table Loading","text":"<p>You can also load tables individually:</p> <pre><code># Load tables one at a time\norchestrator.load_patient_data(sample_size=1000)\norchestrator.load_labs_data(\n    columns=['hospitalization_id', 'lab_result_dttm', 'lab_value']\n)\norchestrator.load_vitals_data(\n    filters={'vital_category': ['heart_rate', 'sbp', 'dbp']}\n)\n</code></pre>"},{"location":"user-guide/orchestrator/#common-patterns","title":"Common Patterns","text":""},{"location":"user-guide/orchestrator/#multi-table-analysis","title":"Multi-table Analysis","text":"<pre><code># Load related tables for ICU analysis\norchestrator.initialize(\n    tables=['patient', 'adt', 'labs', 'vitals', 'respiratory_support']\n)\n\n# Get ICU patients\nicu_stays = orchestrator.adt.filter_by_location_category('icu')\nicu_patient_ids = icu_stays['patient_id'].unique()\n\n# Analyze their labs\nicu_labs = orchestrator.labs.df[\n    orchestrator.labs.df['patient_id'].isin(icu_patient_ids)\n]\n\n# Check ventilation status\nvent_patients = orchestrator.respiratory_support.df[\n    orchestrator.respiratory_support.df['device_category'] == 'IMV'\n]['patient_id'].unique()\n</code></pre>"},{"location":"user-guide/orchestrator/#best-practices","title":"Best Practices","text":"<ol> <li>Load only what you need: Use column and filter parameters to reduce memory usage</li> <li>Validate early: Run validation immediately after loading to catch issues</li> <li>Use consistent timezones: The orchestrator ensures all tables use the same timezone</li> <li>Check output directory: Validation reports and logs are saved to the output directory</li> <li>Handle missing tables gracefully: Check if a table is loaded before accessing it</li> </ol>"},{"location":"user-guide/orchestrator/#error-handling","title":"Error Handling","text":"<pre><code># Check if table is loaded\nif orchestrator.labs is not None:\n    labs_data = orchestrator.labs.df\nelse:\n    print(\"Labs table not loaded\")\n\n# Handle validation errors\norchestrator.validate_all()\nfor table_name in orchestrator.get_loaded_tables():\n    table = getattr(orchestrator, table_name)\n    if not table.isvalid():\n        # Save errors for review\n        error_file = f\"{table_name}_errors.csv\"\n        pd.DataFrame(table.errors).to_csv(error_file, index=False)\n        print(f\"Saved {len(table.errors)} errors to {error_file}\")\n</code></pre>"},{"location":"user-guide/orchestrator/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about individual table types</li> <li>Understand data validation</li> <li>See practical examples</li> </ul>"},{"location":"user-guide/timezones/","title":"Working with Timezones","text":"<p>Proper timezone handling is critical when working with ICU data from multiple sources. This guide explains how CLIFpy manages timezones and best practices for your data.</p>"},{"location":"user-guide/timezones/#overview","title":"Overview","text":"<p>CLIFpy ensures all datetime columns are timezone-aware to: - Prevent ambiguity in timestamp interpretation - Enable accurate time-based calculations - Support data from multiple time zones - Maintain consistency across tables</p>"},{"location":"user-guide/timezones/#timezone-specification","title":"Timezone Specification","text":""},{"location":"user-guide/timezones/#when-loading-data","title":"When Loading Data","text":"<p>Always specify the timezone when loading data:</p> <pre><code># Specify source data timezone\ntable = TableClass.from_file(\n    data_directory='/data',\n    filetype='parquet',\n    timezone='US/Central'  # Source data timezone\n)\n\n# Common US timezones\n# 'US/Eastern', 'US/Central', 'US/Mountain', 'US/Pacific'\n# 'America/New_York', 'America/Chicago', 'America/Denver', 'America/Los_Angeles'\n</code></pre>"},{"location":"user-guide/timezones/#using-orchestrator","title":"Using Orchestrator","text":"<p>The orchestrator ensures consistent timezone across all tables:</p> <pre><code>orchestrator = ClifOrchestrator(\n    data_directory='/data',\n    filetype='parquet',\n    timezone='US/Central'  # Applied to all tables\n)\n</code></pre>"},{"location":"user-guide/timezones/#timezone-conversion","title":"Timezone Conversion","text":""},{"location":"user-guide/timezones/#during-loading","title":"During Loading","text":"<p>CLIFpy automatically converts datetime columns to the specified timezone:</p> <pre><code># Original data in UTC\ntable = TableClass.from_file('/data', 'parquet', timezone='UTC')\n\n# Convert to Central time during loading\ntable = TableClass.from_file('/data', 'parquet', timezone='US/Central')\n</code></pre>"},{"location":"user-guide/timezones/#after-loading","title":"After Loading","text":"<p>Convert between timezones using pandas:</p> <pre><code># Convert to different timezone\ndf = table.df.copy()\ndf['lab_datetime'] = df['lab_datetime'].dt.tz_convert('US/Eastern')\n\n# Localize timezone-naive data (not recommended)\n# df['datetime'] = df['datetime'].dt.tz_localize('US/Central')\n</code></pre>"},{"location":"user-guide/timezones/#common-timezone-issues","title":"Common Timezone Issues","text":""},{"location":"user-guide/timezones/#issue-1-timezone-naive-data","title":"Issue 1: Timezone-Naive Data","text":"<p>Problem: Source data lacks timezone information</p> <pre><code># This will fail validation\ntable.validate()\n# Error: \"Datetime column 'admission_date' is not timezone-aware\"\n</code></pre> <p>Solution: Specify timezone during loading</p> <pre><code># CLIFpy will localize to specified timezone\ntable = TableClass.from_file(\n    '/data', \n    'parquet', \n    timezone='US/Central'  # Assumes data is in Central time\n)\n</code></pre>"},{"location":"user-guide/timezones/#issue-2-mixed-timezones","title":"Issue 2: Mixed Timezones","text":"<p>Problem: Different tables from different timezones</p> <pre><code># Hospital A in Eastern time\nlabs_a = Labs.from_file('/hospital_a/data', 'parquet', timezone='US/Eastern')\n\n# Hospital B in Pacific time  \nlabs_b = Labs.from_file('/hospital_b/data', 'parquet', timezone='US/Pacific')\n</code></pre> <p>Solution: Convert to common timezone</p> <pre><code># Convert both to UTC for analysis\nlabs_a.df['lab_datetime'] = labs_a.df['lab_datetime'].dt.tz_convert('UTC')\nlabs_b.df['lab_datetime'] = labs_b.df['lab_datetime'].dt.tz_convert('UTC')\n\n# Combine datasets\ncombined_labs = pd.concat([labs_a.df, labs_b.df])\n</code></pre>"},{"location":"user-guide/timezones/#issue-3-daylight-saving-time","title":"Issue 3: Daylight Saving Time","text":"<p>Problem: Ambiguous times during DST transitions</p> <pre><code># Fall back: 2:00 AM occurs twice\n# Spring forward: 2:00 AM doesn't exist\n</code></pre> <p>Solution: Use pytz-aware timezone names</p> <pre><code># Good - handles DST automatically\ntable = TableClass.from_file('/data', 'parquet', timezone='US/Central')\n\n# Avoid - doesn't handle DST\n# table = TableClass.from_file('/data', 'parquet', timezone='CST6CDT')\n</code></pre>"},{"location":"user-guide/timezones/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/timezones/#1-know-your-source-timezone","title":"1. Know Your Source Timezone","text":"<pre><code># Document source timezone\n\"\"\"\nData extracted from Hospital EHR\nTimezone: US/Central (America/Chicago)\nIncludes DST adjustments\n\"\"\"\ntable = TableClass.from_file('/data', 'parquet', timezone='US/Central')\n</code></pre>"},{"location":"user-guide/timezones/#2-use-consistent-timezones","title":"2. Use Consistent Timezones","text":"<pre><code># Use orchestrator for consistency\norchestrator = ClifOrchestrator('/data', 'parquet', timezone='US/Central')\norchestrator.initialize(tables=['labs', 'vitals', 'medications'])\n\n# All tables now use same timezone\n</code></pre>"},{"location":"user-guide/timezones/#3-validate-timezone-handling","title":"3. Validate Timezone Handling","text":"<pre><code># Check timezone after loading\nprint(f\"Lab datetime timezone: {table.df['lab_datetime'].dt.tz}\")\n\n# Verify reasonable time ranges\nprint(f\"Earliest: {table.df['lab_datetime'].min()}\")\nprint(f\"Latest: {table.df['lab_datetime'].max()}\")\n</code></pre>"},{"location":"user-guide/timezones/#4-document-timezone-conversions","title":"4. Document Timezone Conversions","text":"<pre><code># Keep audit trail of conversions\nmetadata = {\n    'original_timezone': 'US/Eastern',\n    'converted_timezone': 'UTC',\n    'conversion_date': datetime.now(),\n    'conversion_method': 'pandas dt.tz_convert'\n}\n</code></pre>"},{"location":"user-guide/timezones/#time-based-calculations","title":"Time-based Calculations","text":""},{"location":"user-guide/timezones/#duration-calculations","title":"Duration Calculations","text":"<p>Timezone-aware datetimes ensure accurate duration calculations:</p> <pre><code># Calculate length of stay\nlos = adt.df['out_dttm'] - adt.df['in_dttm']\nlos_hours = los.dt.total_seconds() / 3600\n\n# Time since admission\ncurrent_time = pd.Timestamp.now(tz='US/Central')\ntime_since = current_time - hosp.df['admission_dttm']\n</code></pre>"},{"location":"user-guide/timezones/#filtering-by-time","title":"Filtering by Time","text":"<pre><code># Get data from last 24 hours\ncutoff = pd.Timestamp.now(tz='US/Central') - pd.Timedelta(hours=24)\nrecent = table.df[table.df['datetime_column'] &gt;= cutoff]\n\n# Filter to specific date (timezone-aware)\ndate = pd.Timestamp('2023-01-01', tz='US/Central')\nday_data = table.df[table.df['datetime_column'].dt.date == date.date()]\n</code></pre>"},{"location":"user-guide/timezones/#aggregating-by-time","title":"Aggregating by Time","text":"<pre><code># Hourly aggregation\nhourly = table.df.set_index('datetime_column').resample('H').mean()\n\n# Daily aggregation (timezone affects day boundaries!)\ndaily = table.df.set_index('datetime_column').resample('D').count()\n</code></pre>"},{"location":"user-guide/timezones/#multi-site-considerations","title":"Multi-site Considerations","text":"<p>When combining data from multiple sites:</p> <pre><code># Strategy 1: Convert all to UTC\nsites = ['site_a', 'site_b', 'site_c']\nsite_timezones = {\n    'site_a': 'US/Eastern',\n    'site_b': 'US/Central', \n    'site_c': 'US/Pacific'\n}\n\nall_data = []\nfor site in sites:\n    table = Labs.from_file(f'/data/{site}', 'parquet', \n                          timezone=site_timezones[site])\n    # Convert to UTC\n    table.df['lab_datetime'] = table.df['lab_datetime'].dt.tz_convert('UTC')\n    table.df['site'] = site\n    all_data.append(table.df)\n\ncombined = pd.concat(all_data)\n</code></pre> <pre><code># Strategy 2: Use site's local time with site column\n# Keep original timezone but track source\nfor site in sites:\n    table = Labs.from_file(f'/data/{site}', 'parquet',\n                          timezone=site_timezones[site])\n    table.df['site'] = site\n    table.df['source_timezone'] = site_timezones[site]\n</code></pre>"},{"location":"user-guide/timezones/#timezone-reference","title":"Timezone Reference","text":"<p>Common medical facility timezones:</p> <pre><code>US_TIMEZONES = {\n    'Eastern': 'US/Eastern',     # NYC, Boston, Atlanta\n    'Central': 'US/Central',     # Chicago, Houston, Dallas\n    'Mountain': 'US/Mountain',   # Denver, Phoenix\n    'Pacific': 'US/Pacific',     # LA, Seattle, San Francisco\n    'Alaska': 'US/Alaska',       # Anchorage\n    'Hawaii': 'US/Hawaii'        # Honolulu\n}\n\n# International\nINTL_TIMEZONES = {\n    'London': 'Europe/London',\n    'Paris': 'Europe/Paris',\n    'Tokyo': 'Asia/Tokyo',\n    'Sydney': 'Australia/Sydney',\n    'Toronto': 'America/Toronto'\n}\n</code></pre>"},{"location":"user-guide/timezones/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/timezones/#check-current-timezone","title":"Check Current Timezone","text":"<pre><code># For a datetime column\nprint(table.df['datetime_column'].dt.tz)\n\n# For a single timestamp\nprint(table.df['datetime_column'].iloc[0].tzinfo)\n</code></pre>"},{"location":"user-guide/timezones/#fix-timezone-issues","title":"Fix Timezone Issues","text":"<pre><code># If validation fails due to timezone\nif not table.isvalid():\n    tz_errors = [e for e in table.errors if 'timezone' in str(e)]\n    if tz_errors:\n        # Reload with proper timezone\n        table = TableClass.from_file('/data', 'parquet', \n                                   timezone='US/Central')\n</code></pre>"},{"location":"user-guide/timezones/#next-steps","title":"Next Steps","text":"<ul> <li>Review validation guide for timezone validation</li> <li>See examples of timezone handling</li> <li>Learn about multi-site analysis</li> </ul>"},{"location":"user-guide/validation/","title":"Data Validation","text":"<p>CLIFpy provides comprehensive validation to ensure your data conforms to CLIF standards. This guide explains the validation process and how to interpret results.</p>"},{"location":"user-guide/validation/#overview","title":"Overview","text":"<p>Validation in CLIFpy operates at multiple levels:</p> <ol> <li>Schema Validation - Ensures required columns exist with correct data types</li> <li>Category Validation - Verifies values match standardized categories</li> <li>Range Validation - Checks values fall within clinically reasonable ranges</li> <li>Timezone Validation - Ensures datetime columns are timezone-aware</li> <li>Duplicate Detection - Identifies duplicate records based on composite keys</li> <li>Completeness Checks - Analyzes missing data patterns</li> </ol>"},{"location":"user-guide/validation/#running-validation","title":"Running Validation","text":""},{"location":"user-guide/validation/#basic-validation","title":"Basic Validation","text":"<pre><code># Load and validate a table\ntable = TableClass.from_file('/data', 'parquet')\ntable.validate()\n\n# Check if valid\nif table.isvalid():\n    print(\"Validation passed!\")\nelse:\n    print(f\"Found {len(table.errors)} validation errors\")\n</code></pre>"},{"location":"user-guide/validation/#bulk-validation-with-orchestrator","title":"Bulk Validation with Orchestrator","text":"<pre><code>from clifpy.clif_orchestrator import ClifOrchestrator\n\norchestrator = ClifOrchestrator('/data', 'parquet')\norchestrator.initialize(tables=['patient', 'labs', 'vitals'])\n\n# Validate all tables\norchestrator.validate_all()\n</code></pre>"},{"location":"user-guide/validation/#understanding-validation-results","title":"Understanding Validation Results","text":""},{"location":"user-guide/validation/#error-types","title":"Error Types","text":"<p>Validation errors are stored in the <code>errors</code> attribute:</p> <pre><code># Review errors\nfor error in table.errors[:10]:  # First 10 errors\n    print(f\"Type: {error['type']}\")\n    print(f\"Message: {error['message']}\")\n    print(f\"Details: {error.get('details', 'N/A')}\")\n    print(\"-\" * 50)\n</code></pre> <p>Common error types: - <code>missing_column</code> - Required column not found - <code>invalid_category</code> - Value not in permissible list - <code>out_of_range</code> - Value outside acceptable range - <code>invalid_timezone</code> - Datetime column not timezone-aware - <code>duplicate_rows</code> - Duplicate records found</p>"},{"location":"user-guide/validation/#validation-reports","title":"Validation Reports","text":"<p>Validation results are automatically saved to the output directory:</p> <pre><code># Set custom output directory\ntable = TableClass.from_file(\n    data_directory='/data',\n    filetype='parquet',\n    output_directory='/path/to/reports'\n)\n\n# After validation, these files are created:\n# - validation_log_[table_name].log\n# - validation_errors_[table_name].csv\n# - missing_data_stats_[table_name].csv\n</code></pre>"},{"location":"user-guide/validation/#schema-validation","title":"Schema Validation","text":"<p>Each table has a YAML schema defining its structure:</p> <pre><code># Example from patient_schema.yaml\ncolumns:\n  - name: patient_id\n    data_type: VARCHAR\n    required: true\n    is_category_column: false\n  - name: sex_category\n    data_type: VARCHAR\n    required: true\n    is_category_column: true\n    permissible_values:\n      - Male\n      - Female\n      - Unknown\n</code></pre>"},{"location":"user-guide/validation/#required-columns","title":"Required Columns","text":"<pre><code># Check which required columns are missing\nif not table.isvalid():\n    missing_cols = [e for e in table.errors if e['type'] == 'missing_column']\n    for error in missing_cols:\n        print(f\"Missing required column: {error['column']}\")\n</code></pre>"},{"location":"user-guide/validation/#data-types","title":"Data Types","text":"<p>CLIFpy validates that columns have appropriate data types: - <code>VARCHAR</code> - String/text data - <code>DATETIME</code> - Timezone-aware datetime - <code>NUMERIC</code> - Numeric values (int or float)</p>"},{"location":"user-guide/validation/#category-validation","title":"Category Validation","text":"<p>Standardized categories ensure consistency across institutions:</p> <pre><code># Example: Validating location categories in ADT\nvalid_locations = ['ed', 'ward', 'stepdown', 'icu', 'procedural', \n                   'l&amp;d', 'hospice', 'psych', 'rehab', 'radiology', \n                   'dialysis', 'other']\n\n# Check for invalid categories\ncategory_errors = [e for e in table.errors \n                   if e['type'] == 'invalid_category']\n</code></pre>"},{"location":"user-guide/validation/#range-validation","title":"Range Validation","text":"<p>Clinical values are checked against reasonable ranges:</p> <pre><code># Example: Vital signs ranges\nranges = {\n    'heart_rate': (0, 300),\n    'sbp': (0, 300),\n    'dbp': (0, 200),\n    'temp_c': (25, 44),\n    'spo2': (50, 100)\n}\n\n# Identify out-of-range values\nrange_errors = [e for e in table.errors \n                if e['type'] == 'out_of_range']\n</code></pre>"},{"location":"user-guide/validation/#timezone-validation","title":"Timezone Validation","text":"<p>All datetime columns must be timezone-aware:</p> <pre><code># Check timezone issues\ntz_errors = [e for e in table.errors \n             if 'timezone' in e.get('message', '').lower()]\n\nif tz_errors:\n    print(\"Datetime columns must be timezone-aware\")\n    print(\"Consider reloading with explicit timezone:\")\n    print(\"table = TableClass.from_file('/data', 'parquet', timezone='US/Central')\")\n</code></pre>"},{"location":"user-guide/validation/#duplicate-detection","title":"Duplicate Detection","text":"<p>Duplicates are identified based on composite keys:</p> <pre><code># Check for duplicates\nduplicate_errors = [e for e in table.errors \n                    if e['type'] == 'duplicate_rows']\n\nif duplicate_errors:\n    for error in duplicate_errors:\n        print(f\"Found {error['count']} duplicate rows\")\n        print(f\"Composite keys: {error['keys']}\")\n</code></pre>"},{"location":"user-guide/validation/#missing-data-analysis","title":"Missing Data Analysis","text":"<p>CLIFpy analyzes missing data patterns:</p> <pre><code># Get missing data statistics\nsummary = table.get_summary()\nif 'missing_data' in summary:\n    print(\"Columns with missing data:\")\n    for col, count in summary['missing_data'].items():\n        pct = (count / summary['num_rows']) * 100\n        print(f\"  {col}: {count} ({pct:.1f}%)\")\n</code></pre>"},{"location":"user-guide/validation/#custom-validation","title":"Custom Validation","text":"<p>Tables may include specific validation logic:</p> <pre><code># Example: Labs table validates reference ranges\n# Example: Medications validates dose units match drug\n# Example: Respiratory support validates device/mode combinations\n</code></pre>"},{"location":"user-guide/validation/#best-practices","title":"Best Practices","text":"<ol> <li>Always validate after loading - Catch issues early</li> <li>Review all error types - Don't just check if valid</li> <li>Save validation reports - Keep audit trail</li> <li>Fix data at source - Update extraction/ETL process</li> <li>Document exceptions - Some errors may be acceptable</li> </ol>"},{"location":"user-guide/validation/#handling-validation-errors","title":"Handling Validation Errors","text":""},{"location":"user-guide/validation/#option-1-fix-and-reload","title":"Option 1: Fix and Reload","text":"<pre><code># Identify issues\ntable.validate()\nerrors_df = pd.DataFrame(table.errors)\nerrors_df.to_csv('validation_errors.csv', index=False)\n\n# Fix source data based on errors\n# Then reload\ntable = TableClass.from_file('/fixed_data', 'parquet')\ntable.validate()\n</code></pre>"},{"location":"user-guide/validation/#option-2-filter-invalid-records","title":"Option 2: Filter Invalid Records","text":"<pre><code># Remove records with invalid categories\nvalid_categories = ['Male', 'Female', 'Unknown']\ncleaned_df = table.df[table.df['sex_category'].isin(valid_categories)]\n\n# Create new table instance with cleaned data\ntable = TableClass(data=cleaned_df, timezone='US/Central')\n</code></pre>"},{"location":"user-guide/validation/#option-3-document-and-proceed","title":"Option 3: Document and Proceed","text":"<pre><code># For acceptable validation errors\nif not table.isvalid():\n    # Document why proceeding despite errors\n    with open('validation_notes.txt', 'w') as f:\n        f.write(f\"Proceeding with {len(table.errors)} known issues:\\n\")\n        f.write(\"- Missing optional columns\\n\")\n        f.write(\"- Historical data outside current ranges\\n\")\n</code></pre>"},{"location":"user-guide/validation/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about timezone handling</li> <li>Explore table-specific guides</li> <li>See practical examples</li> </ul>"},{"location":"user-guide/tables/","title":"CLIF Tables Overview","text":"<p>CLIFpy implements all 9 tables defined in the CLIF 2.0.0 specification. Each table represents a specific aspect of ICU patient data, with standardized columns and validation rules. Detailed CLIF Data Dictionary is available here</p>"},{"location":"user-guide/tables/#data-standards","title":"Data Standards","text":"<p>Each table follows CLIF standards for:</p> <ul> <li> <p>\ud83c\udff7\ufe0f Standardized Categories</p> <p>Consistent values across institutions, validated against permissible value lists, and mapped from institution-specific values.</p> </li> <li> <p>\ud83c\udfe5 Source Preservation</p> <p>Original EHR data elements maintained alongside standardized mappings for institutional transparency.</p> </li> <li> <p>\ud83d\udd52 Timezone Handling</p> <p>All datetime columns are timezone-aware with consistent timezone across all tables and automatic conversion during loading.</p> </li> <li> <p>\ud83d\udd11 Composite Keys</p> <p>Unique record identification with duplicate detection and data integrity validation.</p> </li> </ul>"},{"location":"user-guide/tables/#available-tables","title":"Available Tables","text":"<pre><code>graph TD\n    Patient[Patient] --&gt; |patient_id| Hospitalization[Hospitalization]\n    Hospitalization --&gt; |hospitalization_id| ADT[ADT]\n    Hospitalization --&gt; |hospitalization_id| Labs[Labs]\n    Hospitalization --&gt; |hospitalization_id| Vitals[Vitals]\n    Hospitalization --&gt; |hospitalization_id| Meds[Medications]\n    Hospitalization --&gt; |hospitalization_id| Assess[Assessments]\n    Hospitalization --&gt; |hospitalization_id| Resp[Respiratory Support]\n    Hospitalization --&gt; |hospitalization_id| Pos[Position]</code></pre>"},{"location":"user-guide/tables/#patient","title":"Patient","text":"<p>Core demographic information including birth date, sex, race, ethnicity, and language. This is the primary table that links <code>patient_id</code> field to the <code>hospitalization_id</code> field in the Hospitalization table. For detailed API documentation, see Patient API</p>"},{"location":"user-guide/tables/#adt","title":"ADT","text":"<p>Admission, Discharge, and Transfer events tracking patient movement through different hospital locations (ICU, ward, ED, etc.).</p>"},{"location":"user-guide/tables/#hospitalization","title":"Hospitalization","text":"<p>Hospital admission and discharge information, including admission source, discharge disposition, and length of stay.</p>"},{"location":"user-guide/tables/#labs","title":"Labs","text":"<p>Laboratory test results with standardized categories (chemistry, hematology, etc.) and reference ranges.</p>"},{"location":"user-guide/tables/#vitals","title":"Vitals","text":"<p>Vital signs measurements including temperature, heart rate, blood pressure, respiratory rate, and oxygen saturation.</p>"},{"location":"user-guide/tables/#position","title":"Position","text":"<p>Patient positioning data, particularly important for prone positioning in ARDS management.</p>"},{"location":"user-guide/tables/#respiratory-support","title":"Respiratory Support","text":"<p>Ventilation and oxygen therapy data, including device types, settings, and observed values.</p>"},{"location":"user-guide/tables/#medications","title":"Medications","text":"<p>Continuous medication infusions with standardized drug categories and dosing information.</p>"},{"location":"user-guide/tables/#patient-assessments","title":"Patient Assessments","text":"<p>Clinical assessment scores including GCS, RASS, CAM-ICU, pain scores, and other standardized assessments.</p>"},{"location":"user-guide/tables/#common-table-features","title":"Common Table Features","text":"<p>All tables inherit from <code>BaseTable</code> and share these features:</p>"},{"location":"user-guide/tables/#data-loading","title":"Data Loading","text":"<pre><code>table = TableClass.from_file(\n    data_directory='/path/to/data',\n    filetype='parquet',\n    timezone='US/Central'\n)\n</code></pre>"},{"location":"user-guide/tables/#validation","title":"Validation","text":"<pre><code>table.validate()\nif table.isvalid():\n    print(\"Validation passed\")\n</code></pre>"},{"location":"user-guide/tables/#summary-statistics","title":"Summary Statistics","text":"<pre><code>summary = table.get_summary()\nprint(f\"Rows: {summary['num_rows']}\")\nprint(f\"Memory: {summary['memory_usage_mb']} MB\")\n</code></pre>"},{"location":"user-guide/tables/#choosing-tables-for-your-analysis","title":"Choosing Tables for Your Analysis","text":""},{"location":"user-guide/tables/#for-patient-cohort-building","title":"For Patient Cohort Building","text":"<ul> <li>Start with <code>Patient</code> for demographics</li> <li>Add <code>Hospitalization</code> for admission criteria</li> <li>Include <code>ADT</code> for ICU/location-specific cohorts</li> </ul>"},{"location":"user-guide/tables/#for-clinical-outcomes","title":"For Clinical Outcomes","text":"<ul> <li>Use <code>Labs</code> for laboratory markers</li> <li>Add <code>Vitals</code> for physiological parameters</li> <li>Include <code>PatientAssessments</code> for severity scores</li> </ul>"},{"location":"user-guide/tables/#for-treatment-analysis","title":"For Treatment Analysis","text":"<ul> <li>Use <code>RespiratorySupport</code> for ventilation data</li> <li>Add <code>MedicationAdminContinuous</code> for drug therapy</li> <li>Include <code>Position</code> for positioning interventions</li> </ul>"},{"location":"user-guide/tables/#next-steps","title":"Next Steps","text":"<ul> <li>Explore individual table guides for detailed usage</li> <li>Learn about data validation</li> <li>See practical examples</li> <li>Review the API reference</li> </ul>"},{"location":"user-guide/tables/patient/","title":"Patient Table","text":"<p>The Patient table contains core demographic information and serves as the primary reference for all other CLIF tables through the <code>patient_id</code> field.</p>"},{"location":"user-guide/tables/patient/#overview","title":"Overview","text":"<p>The Patient table includes: - Unique patient identifiers - Birth and death dates - Demographics (sex, race, ethnicity) - Primary language</p>"},{"location":"user-guide/tables/patient/#required-columns","title":"Required Columns","text":"Column Type Description patient_id VARCHAR Unique patient identifier birth_date DATETIME Date of birth death_dttm DATETIME Date/time of death (null if alive) race_name VARCHAR Free-text race description race_category VARCHAR Standardized race category ethnicity_name VARCHAR Free-text ethnicity description ethnicity_category VARCHAR Standardized ethnicity category sex_name VARCHAR Free-text sex description sex_category VARCHAR Standardized sex category language_name VARCHAR Primary language language_category VARCHAR Standardized language category"},{"location":"user-guide/tables/patient/#standardized-categories","title":"Standardized Categories","text":""},{"location":"user-guide/tables/patient/#race-categories","title":"Race Categories","text":"<ul> <li>Black or African American</li> <li>White</li> <li>American Indian or Alaska Native</li> <li>Asian</li> <li>Native Hawaiian or Other Pacific Islander</li> <li>Unknown</li> <li>Other</li> </ul>"},{"location":"user-guide/tables/patient/#ethnicity-categories","title":"Ethnicity Categories","text":"<ul> <li>Hispanic</li> <li>Non-Hispanic</li> <li>Unknown</li> </ul>"},{"location":"user-guide/tables/patient/#sex-categories","title":"Sex Categories","text":"<ul> <li>Male</li> <li>Female</li> <li>Unknown</li> </ul>"},{"location":"user-guide/tables/patient/#usage-examples","title":"Usage Examples","text":""},{"location":"user-guide/tables/patient/#loading-patient-data","title":"Loading Patient Data","text":"<pre><code>from clifpy.tables import Patient\n\n# Load from file\npatient = Patient.from_file(\n    data_directory='/path/to/data',\n    filetype='parquet',\n    timezone='US/Central'\n)\n\n# Validate the data\npatient.validate()\n</code></pre>"},{"location":"user-guide/tables/patient/#basic-analysis","title":"Basic Analysis","text":"<pre><code># Get summary statistics\nsummary = patient.get_summary()\nprint(f\"Total patients: {summary['num_rows']}\")\n\n# Demographics distribution\ndemographics = patient.df.groupby(['sex_category', 'race_category']).size()\nprint(demographics)\n\n# Age calculation (if needed)\npatient.df['age'] = (\n    pd.Timestamp.now() - patient.df['birth_date']\n).dt.days / 365.25\n\n# Find elderly patients\nelderly = patient.df[patient.df['age'] &gt;= 65]\n</code></pre>"},{"location":"user-guide/tables/patient/#cohort-building","title":"Cohort Building","text":"<pre><code># Female patients over 65\ncohort = patient.df[\n    (patient.df['sex_category'] == 'Female') &amp; \n    (patient.df['age'] &gt;= 65)\n]\n\n# Living patients\nalive = patient.df[patient.df['death_dttm'].isna()]\n\n# Specific ethnicity\nhispanic = patient.df[patient.df['ethnicity_category'] == 'Hispanic']\n</code></pre>"},{"location":"user-guide/tables/patient/#joining-with-other-tables","title":"Joining with Other Tables","text":"<pre><code># Get patient demographics for lab results\nlabs_with_demographics = labs.df.merge(\n    patient.df[['patient_id', 'age', 'sex_category']],\n    on='patient_id',\n    how='left'\n)\n\n# Analyze by demographic groups\nlab_by_sex = labs_with_demographics.groupby('sex_category')['lab_value'].mean()\n</code></pre>"},{"location":"user-guide/tables/patient/#data-quality-checks","title":"Data Quality Checks","text":"<pre><code># Check for missing demographics\nmissing_sex = patient.df[patient.df['sex_category'].isna()]\nmissing_race = patient.df[patient.df['race_category'].isna()]\n\n# Validate age ranges\npatient.df['age'] = (pd.Timestamp.now() - patient.df['birth_date']).dt.days / 365.25\ninvalid_age = patient.df[(patient.df['age'] &lt; 0) | (patient.df['age'] &gt; 120)]\n\n# Check death date consistency\ninvalid_death = patient.df[\n    patient.df['death_dttm'] &lt; patient.df['birth_date']\n]\n</code></pre>"},{"location":"user-guide/tables/patient/#best-practices","title":"Best Practices","text":"<ol> <li>Always validate demographic categories against standardized values</li> <li>Handle missing data appropriately for demographic fields</li> <li>Calculate age at time of admission, not current date</li> <li>Protect PHI by using only de-identified patient_ids</li> <li>Document any demographic data transformations</li> </ol>"},{"location":"user-guide/tables/patient/#api-reference","title":"API Reference","text":"<p>For detailed API documentation, see Patient API</p>"}]}
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "550fb6f4",
   "metadata": {},
   "source": [
    "## Standard test for wide function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027b7e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from clifpy import ClifOrchestrator\n",
    "\n",
    "# Initialize the ClifOrchestrator\n",
    "# You'll need to adjust the data_directory path to your actual data location\n",
    "co = ClifOrchestrator(\n",
    "    data_directory='../clifpy/data/clif_demo/',  # Adjust this path\n",
    "    filetype='parquet',  # or 'csv' depending on your data format\n",
    "    timezone='UTC',\n",
    "    output_directory=None  # Will create 'output' directory in current working directory\n",
    ")\n",
    "\n",
    "# Create the cohort DataFrame\n",
    "cohort_df = pd.DataFrame({\n",
    "    'hospitalization_id': ['23559586', '20626031'],\n",
    "    'start_time': pd.to_datetime(['2137-01-01 14:29:00-06:00', '2132-12-14 08:00:00-06:00']),\n",
    "    'end_time': pd.to_datetime(['2137-08-25 14:00:00-06:00', '2132-12-20 01:00:00-06:00'])\n",
    "})\n",
    "\n",
    "# Load the required tables\n",
    "co.load_table('vitals')\n",
    "co.load_table('labs')\n",
    "co.load_table('patient_assessments')\n",
    "co.load_table('medication_admin_continuous')\n",
    "\n",
    "# Create the wide dataset\n",
    "wide_df = co.create_wide_dataset(\n",
    "   # tables_to_load=['vitals', 'labs', 'patient_assessments', 'medication_admin_continuous'],\n",
    "   \n",
    "    category_filters={\n",
    "        'labs': ['creatinine','platelet_count','po2_arterial','bilirubin_total'],\n",
    "        'vitals': ['map','spo2', 'weight_kg'],\n",
    "        'patient_assessments': ['gcs_total','sbt_delivery_pass_fail','braden_activity'],\n",
    "        \"medication_admin_continuous\": [\"norepinephrine\",\"epinephrine\",\"phenylephrine\",\"vasopressin\",\n",
    "                \"dopamine\",\"angiotensin\",\"dobutamine\",\"milrinone\"]\n",
    "    },\n",
    "    sample=True,  # Use 20 random hospitalizations\n",
    "    cohort_df=cohort_df\n",
    ")\n",
    "\n",
    "# Optional: Display the resulting DataFrame\n",
    "print(f\"Wide dataset created with shape: {co.wide_df.shape}\")\n",
    "print(f\"Columns: {list(co.wide_df.columns)}\")\n",
    "\n",
    "## expected shape -> Wide dataset created with shape: (924, 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc1e079",
   "metadata": {},
   "outputs": [],
   "source": [
    "co.wide_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44888726",
   "metadata": {},
   "source": [
    "## Wide df test with encounter Stitching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5367fdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: /Users/sudo_sage/Documents/WORK/clifpy/clifpy/data/clif_demo\n",
      "Output directory: /Users/sudo_sage/Documents/WORK/clifpy/examples/output\n",
      "Using directly provided parameters\n",
      "ClifOrchestrator initialized.\n",
      "Using directly provided parameters\n",
      "Loading clif_hospitalization.parquet\n",
      "Data loaded successfully from clif_hospitalization.parquet\n",
      "admission_dttm: null count before conversion= 0\n",
      "admission_dttm: Converted from UTC to your timezone (US/Eastern).\n",
      "admission_dttm: null count after conversion= 0\n",
      "discharge_dttm: null count before conversion= 0\n",
      "discharge_dttm: Converted from UTC to your timezone (US/Eastern).\n",
      "discharge_dttm: null count after conversion= 0\n",
      "Using directly provided parameters\n",
      "Loading clif_adt.parquet\n",
      "Data loaded successfully from clif_adt.parquet\n",
      "in_dttm: null count before conversion= 0\n",
      "in_dttm: Converted from UTC to your timezone (US/Eastern).\n",
      "in_dttm: null count after conversion= 0\n",
      "out_dttm: null count before conversion= 275\n",
      "out_dttm: Converted from UTC to your timezone (US/Eastern).\n",
      "out_dttm: null count after conversion= 275\n",
      "Performing encounter stitching with time interval of 6 hours...\n",
      "Encounter stitching completed successfully.\n",
      "Total hospitalizations: 275\n",
      "Total encounter blocks: 272\n",
      "\n",
      "Encounter mapping shape: (275, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from clifpy import ClifOrchestrator\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def find_project_root(start=None):\n",
    "    p = Path(start or Path.cwd())\n",
    "    for d in [p, *p.parents]:\n",
    "        if (d / \"pyproject.toml\").exists() or (d / \"clifpy\").is_dir():\n",
    "            return d\n",
    "    return p\n",
    "\n",
    "project_root = find_project_root()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "DATA_DIR = (project_root / \"clifpy\" / \"data\" / \"clif_demo\").resolve()\n",
    "OUTPUT_DIR = (project_root / \"examples\" / \"output\").resolve()\n",
    "FILETYPE = \"parquet\"\n",
    "TIMEZONE = \"US/Eastern\"\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "\n",
    "\n",
    "# Initialize orchestrator with encounter stitching enabled\n",
    "clif = ClifOrchestrator(\n",
    "    data_directory=str(DATA_DIR),\n",
    "    filetype=FILETYPE,\n",
    "    timezone=TIMEZONE,\n",
    "    output_directory=str(OUTPUT_DIR),\n",
    "    stitch_encounter=True,  # Enable encounter stitching\n",
    "    stitch_time_interval=6  # 6-hour window (default)\n",
    ")\n",
    "\n",
    "clif.initialize(['hospitalization', 'adt'])\n",
    "\n",
    "# Access the encounter mapping\n",
    "encounter_mapping = clif.get_encounter_mapping()\n",
    "\n",
    "if encounter_mapping is not None:\n",
    "    print(f\"Total hospitalizations: {len(encounter_mapping)}\")\n",
    "    print(f\"Total encounter blocks: {encounter_mapping['encounter_block'].nunique()}\")\n",
    "    print(f\"\\nEncounter mapping shape: {encounter_mapping.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c415ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using directly provided parameters\n",
      "Loading clif_vitals.parquet\n",
      "Data loaded successfully from clif_vitals.parquet\n",
      "recorded_dttm: null count before conversion= 0\n",
      "recorded_dttm: Converted from UTC to your timezone (US/Eastern).\n",
      "recorded_dttm: null count after conversion= 0\n",
      "Using directly provided parameters\n",
      "Loading clif_labs.parquet\n",
      "Data loaded successfully from clif_labs.parquet\n",
      "lab_order_dttm: null count before conversion= 43419\n",
      "lab_order_dttm: Converted from UTC to your timezone (US/Eastern).\n",
      "lab_order_dttm: null count after conversion= 43419\n",
      "lab_collect_dttm: null count before conversion= 0\n",
      "lab_collect_dttm: Converted from UTC to your timezone (US/Eastern).\n",
      "lab_collect_dttm: null count after conversion= 0\n",
      "lab_result_dttm: null count before conversion= 0\n",
      "lab_result_dttm: Converted from UTC to your timezone (US/Eastern).\n",
      "lab_result_dttm: null count after conversion= 0\n",
      "Using directly provided parameters\n",
      "Loading clif_patient_assessments.parquet\n",
      "Data loaded successfully from clif_patient_assessments.parquet\n",
      "recorded_dttm: null count before conversion= 0\n",
      "recorded_dttm: Converted from UTC to your timezone (US/Eastern).\n",
      "recorded_dttm: null count after conversion= 0\n",
      "Using directly provided parameters\n",
      "Loading clif_medication_admin_continuous.parquet\n",
      "Data loaded successfully from clif_medication_admin_continuous.parquet\n",
      "admin_dttm: null count before conversion= 0\n",
      "admin_dttm: Converted from UTC to your timezone (US/Eastern).\n",
      "admin_dttm: null count after conversion= 0\n",
      "==================================================\n",
      "=== WIDE DATASET CREATION STARTED ===\n",
      "==================================================\n",
      "\n",
      "Phase 1: Initialization\n",
      "  1.1: Validating parameters\n",
      "  1.2: Configuring encounter stitching (enabled)\n",
      "\n",
      "Phase 2: Encounter Processing\n",
      "  2.1: === SPECIAL: ENCOUNTER STITCHING ===\n",
      "Info: Encounter stitching has been performed. Your cohort_df uses hospitalization_id. Consider using 'encounter_block' column instead for cleaner encounter-level filtering.\n",
      "\n",
      "Phase 3: Table Loading\n",
      "  3.1: Auto-loading base tables\n",
      "       - Loading patient table...\n",
      "Using directly provided parameters\n",
      "Loading clif_patient.parquet\n",
      "Data loaded successfully from clif_patient.parquet\n",
      "death_dttm: null count before conversion= 85\n",
      "death_dttm: Converted from UTC to your timezone (US/Eastern).\n",
      "death_dttm: null count after conversion= 85\n",
      "  3.2: Loading optional tables: None\n",
      "  === SPECIAL: PATIENT ASSESSMENTS PROCESSING ===\n",
      "       - Merging numerical_value and categorical_value columns\n",
      "       - Using Polars for performance optimization\n",
      "       - WARNING: Found 9951 rows with both values!\n",
      "       -          Numerical values will take precedence\n",
      "       - Created assessment_value column:\n",
      "       -   27454 numerical values (takes precedence)\n",
      "       -   13222 categorical values (used when numerical is null)\n",
      "       -   Total non-null assessment values: 30725\n",
      "       -   Stored as string type for processing compatibility\n",
      "\n",
      "Phase 4: Calling Wide Dataset Utility\n",
      "  4.1: Passing to wide_dataset.create_wide_dataset()\n",
      "       - Tables: None\n",
      "       - Category filters: ['labs', 'vitals', 'patient_assessments', 'medication_admin_continuous']\n",
      "       - Batch size: 1000\n",
      "       - Memory limit: None\n",
      "       - Show progress: True\n",
      "\n",
      "Phase 4: Wide Dataset Processing (utility function)\n",
      "  4.1: Starting wide dataset creation...\n",
      "  === SPECIAL: COHORT TIME WINDOW FILTERING ===\n",
      "       - Processing 2 hospitalizations with time windows\n",
      "       - Ensuring datetime types for start_time, end_time\n",
      "\n",
      "Using 2 hospitalization IDs from cohort_df\n",
      "\n",
      "Loading and filtering base tables...\n",
      "  ADT time filtering: 11 → 8 records\n",
      "       - Base tables filtered - Hospitalization: 2, Patient: 100, ADT: 8\n",
      "\n",
      "  4.2: Determining processing mode\n",
      "       - Single mode: Processing all 2 hospitalizations at once\n",
      "  4.S: === SINGLE PROCESSING MODE ===\n",
      "    4.S.1: Loading and filtering base tables\n",
      "           - Base cohort created with 2 records\n",
      "    4.S.3: Processing tables\n",
      "           - Processing labs...\n",
      "Loaded 931 records from labs\n",
      "           === SPECIAL: TIME FILTERING ===\n",
      "           - Applying cohort time windows to labs\n",
      "           - labs: 931 → 728 records after filtering\n",
      "           === PIVOTING LABS ===\n",
      "           - Categories to pivot: ['creatinine', 'platelet_count', 'po2_arterial', 'bilirubin_total']\n",
      "Filtering labs categories to: ['creatinine', 'platelet_count', 'po2_arterial', 'bilirubin_total']\n",
      "Pivoted labs: 98 combo_ids with 4 category columns\n",
      "           - Processing vitals...\n",
      "Loaded 3437 records from vitals\n",
      "           === SPECIAL: TIME FILTERING ===\n",
      "           - Applying cohort time windows to vitals\n",
      "           - vitals: 3437 → 2199 records after filtering\n",
      "           === PIVOTING VITALS ===\n",
      "           - Categories to pivot: ['map', 'spo2', 'weight_kg']\n",
      "Filtering vitals categories to: ['map', 'spo2', 'weight_kg']\n",
      "Pivoted vitals: 512 combo_ids with 3 category columns\n",
      "           - Processing patient_assessments...\n",
      "Loaded 1202 records from patient_assessments\n",
      "           === SPECIAL: TIME FILTERING ===\n",
      "           - Applying cohort time windows to patient_assessments\n",
      "           - patient_assessments: 1202 → 753 records after filtering\n",
      "           === PIVOTING PATIENT_ASSESSMENTS ===\n",
      "           - Categories to pivot: ['gcs_total']\n",
      "Filtering patient_assessments categories to: ['gcs_total']\n",
      "Pivoted patient_assessments: 70 combo_ids with 1 category columns\n",
      "           - Processing medication_admin_continuous...\n",
      "           - No converted data found, using original medication data\n",
      "Loaded 256 records from medication_admin_continuous\n",
      "           === SPECIAL: TIME FILTERING ===\n",
      "           - Applying cohort time windows to medication_admin_continuous\n",
      "           - medication_admin_continuous: 256 → 255 records after filtering\n",
      "           === PIVOTING MEDICATION_ADMIN_CONTINUOUS ===\n",
      "           - Categories to pivot: ['norepinephrine', 'epinephrine', 'phenylephrine', 'vasopressin', 'dopamine', 'angiotensin', 'dobutamine', 'milrinone']\n",
      "           - Using original medication column: med_dose\n",
      "Filtering medication_admin_continuous categories to: ['norepinephrine', 'epinephrine', 'phenylephrine', 'vasopressin', 'dopamine', 'angiotensin', 'dobutamine', 'milrinone']\n",
      "Pivoted medication_admin_continuous: 88 combo_ids with 3 category columns\n",
      "    4.S.4: Creating wide dataset\n",
      "           - Building event time union from 5 tables\n",
      "           - Creating combo_id keys\n",
      "           - Executing main join query\n",
      "Executing join query...\n",
      "Applying cohort time window filtering to final dataset...\n",
      "  Final time filtering: 924 → 924 records\n",
      "    === SPECIAL: MISSING COLUMNS ===\n",
      "           - Added missing column: epinephrine\n",
      "           - Added missing column: dopamine\n",
      "           - Added missing column: angiotensin\n",
      "           - Added missing column: dobutamine\n",
      "           - Added missing column: milrinone\n",
      "\n",
      "    4.S.6: Final cleanup\n",
      "           - Removing duplicate columns\n",
      "           - Dropping temporary columns (combo_id, date)\n",
      "           - Wide dataset created: 924 records with 28 columns\n",
      "\n",
      "Phase 5: Post-Processing\n",
      "  5.1: === SPECIAL: ADDING ENCOUNTER BLOCKS ===\n",
      "       - Encounter_block column already present - 2 unique encounter blocks\n",
      "  5.2: === SPECIAL: ASSESSMENT TYPE OPTIMIZATION ===\n",
      "       - Using Polars for performance optimization\n",
      "       - Analyzing 1 assessment columns\n",
      "       - Converted to numeric (1 columns):\n",
      "       -   gcs_total\n",
      "\n",
      "Phase 6: Completion\n",
      "  6.1: Wide dataset stored in self.wide_df\n",
      "  6.2: Dataset shape: 924 rows x 28 columns\n",
      "\n",
      "==================================================\n",
      "=== WIDE DATASET CREATION COMPLETED ===\n",
      "==================================================\n",
      "\n",
      "Wide dataset created with shape: (924, 28)\n",
      "Columns: ['hospitalization_id', 'patient_id', 'age_at_admission', 'event_time', 'norepinephrine', 'phenylephrine', 'vasopressin', 'map', 'spo2', 'weight_kg', 'bilirubin_total', 'creatinine', 'platelet_count', 'po2_arterial', 'hospital_id', 'in_dttm', 'out_dttm', 'location_category', 'location_type', 'encounter_block', 'day_number', 'hosp_id_day_key', 'epinephrine', 'dopamine', 'angiotensin', 'dobutamine', 'milrinone', 'gcs_total']\n"
     ]
    }
   ],
   "source": [
    "# Create the cohort DataFrame\n",
    "cohort_df = pd.DataFrame({\n",
    "    'hospitalization_id': ['23559586', '20626031'],\n",
    "    'start_time': pd.to_datetime(['2137-01-01 14:29:00-06:00', '2132-12-14 08:00:00-06:00']),\n",
    "    'end_time': pd.to_datetime(['2137-08-25 14:00:00-06:00', '2132-12-20 01:00:00-06:00'])\n",
    "})\n",
    "\n",
    "# Load the required tables\n",
    "clif.load_table('vitals')\n",
    "clif.load_table('labs')\n",
    "clif.load_table('patient_assessments')\n",
    "clif.load_table('medication_admin_continuous')\n",
    "\n",
    "# Create the wide dataset\n",
    "clif.create_wide_dataset(\n",
    "   # tables_to_load=['vitals', 'labs', 'patient_assessments', 'medication_admin_continuous'],\n",
    "   \n",
    "    category_filters={\n",
    "        'labs': ['creatinine','platelet_count','po2_arterial','bilirubin_total'],\n",
    "        'vitals': ['map','spo2', 'weight_kg'],\n",
    "        'patient_assessments': ['gcs_total'],\n",
    "        \"medication_admin_continuous\": [\"norepinephrine\",\"epinephrine\",\"phenylephrine\",\"vasopressin\",\n",
    "                \"dopamine\",\"angiotensin\",\"dobutamine\",\"milrinone\"]\n",
    "    },\n",
    "    sample=True,  # Use 20 random hospitalizations\n",
    "    cohort_df=cohort_df\n",
    ")\n",
    "\n",
    "# Optional: Display the resulting DataFrame\n",
    "print(f\"Wide dataset created with shape: {clif.wide_df.shape}\")\n",
    "print(f\"Columns: {list(clif.wide_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ecee26",
   "metadata": {},
   "source": [
    "## test with meds conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77c9fcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: /Users/sudo_sage/Documents/WORK/clifpy/clifpy/data/clif_demo\n",
      "Output directory: /Users/sudo_sage/Documents/WORK/clifpy/examples/output\n",
      "Using directly provided parameters\n",
      "ClifOrchestrator initialized.\n",
      "Using directly provided parameters\n",
      "Loading clif_hospitalization.parquet\n",
      "Data loaded successfully from clif_hospitalization.parquet\n",
      "admission_dttm: null count before conversion= 0\n",
      "admission_dttm: Converted from UTC to your timezone (US/Eastern).\n",
      "admission_dttm: null count after conversion= 0\n",
      "discharge_dttm: null count before conversion= 0\n",
      "discharge_dttm: Converted from UTC to your timezone (US/Eastern).\n",
      "discharge_dttm: null count after conversion= 0\n",
      "Using directly provided parameters\n",
      "Loading clif_adt.parquet\n",
      "Data loaded successfully from clif_adt.parquet\n",
      "in_dttm: null count before conversion= 0\n",
      "in_dttm: Converted from UTC to your timezone (US/Eastern).\n",
      "in_dttm: null count after conversion= 0\n",
      "out_dttm: null count before conversion= 275\n",
      "out_dttm: Converted from UTC to your timezone (US/Eastern).\n",
      "out_dttm: null count after conversion= 275\n",
      "Performing encounter stitching with time interval of 6 hours...\n",
      "Encounter stitching completed successfully.\n",
      "Total hospitalizations: 275\n",
      "Total encounter blocks: 272\n",
      "\n",
      "Encounter mapping shape: (275, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from clifpy import ClifOrchestrator\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def find_project_root(start=None):\n",
    "    p = Path(start or Path.cwd())\n",
    "    for d in [p, *p.parents]:\n",
    "        if (d / \"pyproject.toml\").exists() or (d / \"clifpy\").is_dir():\n",
    "            return d\n",
    "    return p\n",
    "\n",
    "project_root = find_project_root()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "DATA_DIR = (project_root / \"clifpy\" / \"data\" / \"clif_demo\").resolve()\n",
    "OUTPUT_DIR = (project_root / \"examples\" / \"output\").resolve()\n",
    "FILETYPE = \"parquet\"\n",
    "TIMEZONE = \"US/Eastern\"\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "\n",
    "\n",
    "# Initialize orchestrator with encounter stitching enabled\n",
    "clif = ClifOrchestrator(\n",
    "    data_directory=str(DATA_DIR),\n",
    "    filetype=FILETYPE,\n",
    "    timezone=TIMEZONE,\n",
    "    output_directory=str(OUTPUT_DIR),\n",
    "    stitch_encounter=True,  # Enable encounter stitching\n",
    "    stitch_time_interval=6  # 6-hour window (default)\n",
    ")\n",
    "\n",
    "clif.initialize(['hospitalization', 'adt'])\n",
    "\n",
    "# Access the encounter mapping\n",
    "encounter_mapping = clif.get_encounter_mapping()\n",
    "\n",
    "if encounter_mapping is not None:\n",
    "    print(f\"Total hospitalizations: {len(encounter_mapping)}\")\n",
    "    print(f\"Total encounter blocks: {encounter_mapping['encounter_block'].nunique()}\")\n",
    "    print(f\"\\nEncounter mapping shape: {encounter_mapping.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc9fd01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using directly provided parameters\n",
      "Loading clif_vitals.parquet\n",
      "Data loaded successfully from clif_vitals.parquet\n",
      "recorded_dttm: null count before conversion= 0\n",
      "recorded_dttm: Converted from UTC to your timezone (US/Eastern).\n",
      "recorded_dttm: null count after conversion= 0\n",
      "Using directly provided parameters\n",
      "Loading clif_labs.parquet\n",
      "Data loaded successfully from clif_labs.parquet\n",
      "lab_order_dttm: null count before conversion= 43419\n",
      "lab_order_dttm: Converted from UTC to your timezone (US/Eastern).\n",
      "lab_order_dttm: null count after conversion= 43419\n",
      "lab_collect_dttm: null count before conversion= 0\n",
      "lab_collect_dttm: Converted from UTC to your timezone (US/Eastern).\n",
      "lab_collect_dttm: null count after conversion= 0\n",
      "lab_result_dttm: null count before conversion= 0\n",
      "lab_result_dttm: Converted from UTC to your timezone (US/Eastern).\n",
      "lab_result_dttm: null count after conversion= 0\n",
      "Using directly provided parameters\n",
      "Loading clif_patient_assessments.parquet\n",
      "Data loaded successfully from clif_patient_assessments.parquet\n",
      "recorded_dttm: null count before conversion= 0\n",
      "recorded_dttm: Converted from UTC to your timezone (US/Eastern).\n",
      "recorded_dttm: null count after conversion= 0\n",
      "Using directly provided parameters\n",
      "Loading clif_medication_admin_continuous.parquet\n",
      "Data loaded successfully from clif_medication_admin_continuous.parquet\n",
      "admin_dttm: null count before conversion= 0\n",
      "admin_dttm: Converted from UTC to your timezone (US/Eastern).\n",
      "admin_dttm: null count after conversion= 0\n",
      "No weight_kg column found, adding the most recent from vitals\n",
      "==================================================\n",
      "=== WIDE DATASET CREATION STARTED ===\n",
      "==================================================\n",
      "\n",
      "Phase 1: Initialization\n",
      "  1.1: Validating parameters\n",
      "  1.2: Configuring encounter stitching (enabled)\n",
      "\n",
      "Phase 2: Encounter Processing\n",
      "  2.1: === SPECIAL: ENCOUNTER STITCHING ===\n",
      "       - No encounter_blocks provided - processing all encounter blocks\n",
      "\n",
      "Phase 3: Table Loading\n",
      "  3.1: Auto-loading base tables\n",
      "       - Loading patient table...\n",
      "Using directly provided parameters\n",
      "Loading clif_patient.parquet\n",
      "Data loaded successfully from clif_patient.parquet\n",
      "death_dttm: null count before conversion= 85\n",
      "death_dttm: Converted from UTC to your timezone (US/Eastern).\n",
      "death_dttm: null count after conversion= 85\n",
      "  3.2: Loading optional tables: None\n",
      "  === SPECIAL: PATIENT ASSESSMENTS PROCESSING ===\n",
      "       - Merging numerical_value and categorical_value columns\n",
      "       - Using Polars for performance optimization\n",
      "       - WARNING: Found 9951 rows with both values!\n",
      "       -          Numerical values will take precedence\n",
      "       - Created assessment_value column:\n",
      "       -   27454 numerical values (takes precedence)\n",
      "       -   13222 categorical values (used when numerical is null)\n",
      "       -   Total non-null assessment values: 30725\n",
      "       -   Stored as string type for processing compatibility\n",
      "\n",
      "Phase 4: Calling Wide Dataset Utility\n",
      "  4.1: Passing to wide_dataset.create_wide_dataset()\n",
      "       - Tables: None\n",
      "       - Category filters: ['labs', 'vitals', 'patient_assessments', 'medication_admin_continuous']\n",
      "       - Batch size: 1000\n",
      "       - Memory limit: None\n",
      "       - Show progress: True\n",
      "\n",
      "Phase 4: Wide Dataset Processing (utility function)\n",
      "  4.1: Starting wide dataset creation...\n",
      "Processing all 275 hospitalizations\n",
      "\n",
      "Loading and filtering base tables...\n",
      "       - Base tables filtered - Hospitalization: 275, Patient: 100, ADT: 1136\n",
      "\n",
      "  4.2: Determining processing mode\n",
      "       - Single mode: Processing all 275 hospitalizations at once\n",
      "  4.S: === SINGLE PROCESSING MODE ===\n",
      "    4.S.1: Loading and filtering base tables\n",
      "           - Base cohort created with 275 records\n",
      "    4.S.3: Processing tables\n",
      "           - Processing labs...\n",
      "Loaded 43419 records from labs\n",
      "           === PIVOTING LABS ===\n",
      "           - Categories to pivot: ['creatinine', 'platelet_count', 'po2_arterial', 'bilirubin_total']\n",
      "Filtering labs categories to: ['creatinine', 'platelet_count', 'po2_arterial', 'bilirubin_total']\n",
      "Pivoted labs: 5524 combo_ids with 4 category columns\n",
      "           - Processing vitals...\n",
      "Loaded 89085 records from vitals\n",
      "           === PIVOTING VITALS ===\n",
      "           - Categories to pivot: ['map', 'spo2', 'weight_kg']\n",
      "Filtering vitals categories to: ['map', 'spo2', 'weight_kg']\n",
      "Pivoted vitals: 19231 combo_ids with 3 category columns\n",
      "           - Processing patient_assessments...\n",
      "Loaded 30803 records from patient_assessments\n",
      "           === PIVOTING PATIENT_ASSESSMENTS ===\n",
      "           - Categories to pivot: ['gcs_total']\n",
      "Filtering patient_assessments categories to: ['gcs_total']\n",
      "Pivoted patient_assessments: 3279 combo_ids with 1 category columns\n",
      "           - Processing medication_admin_continuous...\n",
      "           === SPECIAL: USING CONVERTED MEDICATION DATA ===\n",
      "           - Including all 6,791 rows: 6,667 successful conversions, 124 (1.8%) fallback to original units\n",
      "Loaded 6791 records from medication_admin_continuous\n",
      "           === PIVOTING MEDICATION_ADMIN_CONTINUOUS ===\n",
      "           - Categories to pivot: ['norepinephrine', 'epinephrine', 'phenylephrine', 'vasopressin', 'dopamine', 'angiotensin', 'dobutamine', 'milrinone']\n",
      "           - Using converted medication columns: med_dose_converted, med_dose_unit_converted\n",
      "Filtering medication_admin_continuous categories to: ['norepinephrine', 'epinephrine', 'phenylephrine', 'vasopressin', 'dopamine', 'angiotensin', 'dobutamine', 'milrinone']\n",
      "           - Creating unit-aware pivot with columns: category_unit format\n",
      "           - Including both successful conversions and original units for failed conversions\n",
      "Pivoted medication_admin_continuous: 1924 combo_ids with 7 medication_unit columns\n",
      "    4.S.4: Creating wide dataset\n",
      "           - Building event time union from 5 tables\n",
      "           - Creating combo_id keys\n",
      "           - Executing main join query\n",
      "Executing join query...\n",
      "    === SPECIAL: MISSING COLUMNS ===\n",
      "           - Found unit-aware columns for norepinephrine: ['norepinephrine_mcg_min']\n",
      "           - Found unit-aware columns for epinephrine: ['epinephrine_mcg_min']\n",
      "           - Found unit-aware columns for phenylephrine: ['phenylephrine_mcg_min']\n",
      "           - Found unit-aware columns for vasopressin: ['vasopressin_u_min']\n",
      "           - Found unit-aware columns for dopamine: ['dopamine_mcg_min']\n",
      "           - Added missing column: angiotensin\n",
      "           - Found unit-aware columns for dobutamine: ['dobutamine_mcg_min']\n",
      "           - Found unit-aware columns for milrinone: ['milrinone_mcg_min']\n",
      "\n",
      "    4.S.6: Final cleanup\n",
      "           - Removing duplicate columns\n",
      "           - Dropping temporary columns (combo_id, date)\n",
      "           - Wide dataset created: 36749 records with 28 columns\n",
      "\n",
      "Phase 5: Post-Processing\n",
      "  5.1: === SPECIAL: ADDING ENCOUNTER BLOCKS ===\n",
      "       - Encounter_block column already present - 272 unique encounter blocks\n",
      "  5.2: === SPECIAL: ASSESSMENT TYPE OPTIMIZATION ===\n",
      "       - Using Polars for performance optimization\n",
      "       - Analyzing 1 assessment columns\n",
      "       - Converted to numeric (1 columns):\n",
      "       -   gcs_total\n",
      "\n",
      "Phase 6: Completion\n",
      "  6.1: Wide dataset stored in self.wide_df\n",
      "  6.2: Dataset shape: 36749 rows x 28 columns\n",
      "\n",
      "==================================================\n",
      "=== WIDE DATASET CREATION COMPLETED ===\n",
      "==================================================\n",
      "\n",
      "Wide dataset created with shape: (36749, 28)\n",
      "Columns: ['hospitalization_id', 'patient_id', 'age_at_admission', 'event_time', 'dobutamine_mcg_min', 'dopamine_mcg_min', 'epinephrine_mcg_min', 'milrinone_mcg_min', 'norepinephrine_mcg_min', 'phenylephrine_mcg_min', 'vasopressin_u_min', 'map', 'spo2', 'weight_kg', 'bilirubin_total', 'creatinine', 'platelet_count', 'po2_arterial', 'hospital_id', 'in_dttm', 'out_dttm', 'location_category', 'location_type', 'encounter_block', 'day_number', 'hosp_id_day_key', 'angiotensin', 'gcs_total']\n"
     ]
    }
   ],
   "source": [
    "# # Create the cohort DataFrame\n",
    "# cohort_df = pd.DataFrame({\n",
    "#     'hospitalization_id': ['23559586', '20626031'],\n",
    "#     'start_time': pd.to_datetime(['2137-01-01 14:29:00-06:00', '2132-12-14 08:00:00-06:00']),\n",
    "#     'end_time': pd.to_datetime(['2137-08-25 14:00:00-06:00', '2132-12-20 01:00:00-06:00'])\n",
    "# })\n",
    "\n",
    "# Load the required tables\n",
    "clif.load_table('vitals')\n",
    "clif.load_table('labs')\n",
    "clif.load_table('patient_assessments')\n",
    "clif.load_table('medication_admin_continuous')\n",
    "preferred_units_cont = {\n",
    "    \"propofol\": \"mcg/min\",\n",
    "    \"fentanyl\": \"mcg/hr\",\n",
    "    \"insulin\": \"u/hr\",\n",
    "    \"midazolam\": \"mg/hr\",\n",
    "    \"heparin\": \"u/min\"\n",
    "}\n",
    "\n",
    "clif.convert_dose_units_for_continuous_meds(preferred_units_cont)\n",
    "# Create the wide dataset\n",
    "clif.create_wide_dataset(\n",
    "   # tables_to_load=['vitals', 'labs', 'patient_assessments', 'medication_admin_continuous'],\n",
    "   \n",
    "    category_filters={\n",
    "        'labs': ['creatinine','platelet_count','po2_arterial','bilirubin_total'],\n",
    "        'vitals': ['map','spo2', 'weight_kg'],\n",
    "        'patient_assessments': ['gcs_total'],\n",
    "        \"medication_admin_continuous\": [\"norepinephrine\",\"epinephrine\",\"phenylephrine\",\"vasopressin\",\n",
    "                \"dopamine\",\"angiotensin\",\"dobutamine\",\"milrinone\"]\n",
    "    }\n",
    "    #,\n",
    "    #sample=True,  # Use 20 random hospitalizations\n",
    "   # cohort_df=cohort_df\n",
    ")\n",
    "\n",
    "# Optional: Display the resulting DataFrame\n",
    "print(f\"Wide dataset created with shape: {clif.wide_df.shape}\")\n",
    "print(f\"Columns: {list(clif.wide_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "725cafda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hospitalization_id', 'patient_id', 'age_at_admission', 'event_time',\n",
       "       'dobutamine_mcg_min', 'dopamine_mcg_min', 'epinephrine_mcg_min',\n",
       "       'milrinone_mcg_min', 'norepinephrine_mcg_min', 'phenylephrine_mcg_min',\n",
       "       'vasopressin_u_min', 'map', 'spo2', 'weight_kg', 'bilirubin_total',\n",
       "       'creatinine', 'platelet_count', 'po2_arterial', 'hospital_id',\n",
       "       'in_dttm', 'out_dttm', 'location_category', 'location_type',\n",
       "       'encounter_block', 'day_number', 'hosp_id_day_key', 'angiotensin',\n",
       "       'gcs_total'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clif.wide_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29608fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dextrose', 'propofol', 'insulin', 'magnesium', 'heparin',\n",
       "       'esmolol', 'diltiazem', 'phenylephrine', 'norepinephrine',\n",
       "       'vasopressin', 'fentanyl', 'amiodarone', 'labetalol',\n",
       "       'dexmedetomidine', 'sodium bicarbonate', 'pantoprazole', 'tpn',\n",
       "       'nicardipine', 'dobutamine', 'dopamine', 'midazolam', 'furosemide',\n",
       "       'morphine', 'octreotide', 'aminocaproic', 'epinephrine',\n",
       "       'bumetanide', 'milrinone', 'rocuronium', 'hydromorphone'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clif.medication_admin_continuous.df.med_category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3876e0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hospitalization_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>age_at_admission</th>\n",
       "      <th>event_time</th>\n",
       "      <th>norepinephrine_mcg_min</th>\n",
       "      <th>phenylephrine_mcg_min</th>\n",
       "      <th>vasopressin_u_min</th>\n",
       "      <th>map</th>\n",
       "      <th>spo2</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>...</th>\n",
       "      <th>location_type</th>\n",
       "      <th>encounter_block</th>\n",
       "      <th>day_number</th>\n",
       "      <th>hosp_id_day_key</th>\n",
       "      <th>epinephrine</th>\n",
       "      <th>dopamine</th>\n",
       "      <th>angiotensin</th>\n",
       "      <th>dobutamine</th>\n",
       "      <th>milrinone</th>\n",
       "      <th>gcs_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20626031</td>\n",
       "      <td>10005817</td>\n",
       "      <td>66</td>\n",
       "      <td>2132-12-14 08:05:00-06:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>20626031_day_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20626031</td>\n",
       "      <td>10005817</td>\n",
       "      <td>66</td>\n",
       "      <td>2132-12-14 11:02:00-06:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>20626031_day_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20626031</td>\n",
       "      <td>10005817</td>\n",
       "      <td>66</td>\n",
       "      <td>2132-12-14 13:03:00-06:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>20626031_day_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20626031</td>\n",
       "      <td>10005817</td>\n",
       "      <td>66</td>\n",
       "      <td>2132-12-14 13:04:00-06:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>20626031_day_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20626031</td>\n",
       "      <td>10005817</td>\n",
       "      <td>66</td>\n",
       "      <td>2132-12-14 16:40:00-06:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>20626031_day_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>23559586</td>\n",
       "      <td>10003400</td>\n",
       "      <td>75</td>\n",
       "      <td>2137-08-25 12:00:00-06:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>23559586_day_22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>23559586</td>\n",
       "      <td>10003400</td>\n",
       "      <td>75</td>\n",
       "      <td>2137-08-25 12:01:00-06:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>23559586_day_22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>23559586</td>\n",
       "      <td>10003400</td>\n",
       "      <td>75</td>\n",
       "      <td>2137-08-25 13:00:00-06:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>23559586_day_22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>23559586</td>\n",
       "      <td>10003400</td>\n",
       "      <td>75</td>\n",
       "      <td>2137-08-25 13:01:00-06:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>23559586_day_22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>23559586</td>\n",
       "      <td>10003400</td>\n",
       "      <td>75</td>\n",
       "      <td>2137-08-25 14:00:00-06:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>23559586_day_22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>924 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    hospitalization_id patient_id  age_at_admission                event_time  \\\n",
       "0             20626031   10005817                66 2132-12-14 08:05:00-06:00   \n",
       "1             20626031   10005817                66 2132-12-14 11:02:00-06:00   \n",
       "2             20626031   10005817                66 2132-12-14 13:03:00-06:00   \n",
       "3             20626031   10005817                66 2132-12-14 13:04:00-06:00   \n",
       "4             20626031   10005817                66 2132-12-14 16:40:00-06:00   \n",
       "..                 ...        ...               ...                       ...   \n",
       "919           23559586   10003400                75 2137-08-25 12:00:00-06:00   \n",
       "920           23559586   10003400                75 2137-08-25 12:01:00-06:00   \n",
       "921           23559586   10003400                75 2137-08-25 13:00:00-06:00   \n",
       "922           23559586   10003400                75 2137-08-25 13:01:00-06:00   \n",
       "923           23559586   10003400                75 2137-08-25 14:00:00-06:00   \n",
       "\n",
       "     norepinephrine_mcg_min  phenylephrine_mcg_min  vasopressin_u_min   map  \\\n",
       "0                       NaN                    NaN                NaN   NaN   \n",
       "1                       NaN                    NaN                NaN   NaN   \n",
       "2                       NaN                    NaN                NaN   NaN   \n",
       "3                       NaN                    NaN                NaN   NaN   \n",
       "4                       NaN                    NaN                NaN   NaN   \n",
       "..                      ...                    ...                ...   ...   \n",
       "919                     NaN                    NaN                NaN   NaN   \n",
       "920                     NaN                    NaN                NaN  71.0   \n",
       "921                     NaN                    NaN                NaN   NaN   \n",
       "922                     NaN                    NaN                NaN  61.0   \n",
       "923                     NaN                    NaN                NaN   NaN   \n",
       "\n",
       "     spo2  weight_kg  ...  location_type  encounter_block  day_number  \\\n",
       "0     NaN        NaN  ...           None              NaN           1   \n",
       "1     NaN        NaN  ...           None              NaN           1   \n",
       "2     NaN        NaN  ...           None              NaN           1   \n",
       "3     NaN        NaN  ...           None              NaN           1   \n",
       "4     NaN        NaN  ...           None              NaN           1   \n",
       "..    ...        ...  ...            ...              ...         ...   \n",
       "919  99.0        NaN  ...           None              NaN          22   \n",
       "920   NaN        NaN  ...           None              NaN          22   \n",
       "921  99.0        NaN  ...           None              NaN          22   \n",
       "922   NaN        NaN  ...           None              NaN          22   \n",
       "923   NaN        NaN  ...           None              NaN          22   \n",
       "\n",
       "     hosp_id_day_key epinephrine dopamine angiotensin dobutamine milrinone  \\\n",
       "0     20626031_day_1         NaN      NaN         NaN        NaN       NaN   \n",
       "1     20626031_day_1         NaN      NaN         NaN        NaN       NaN   \n",
       "2     20626031_day_1         NaN      NaN         NaN        NaN       NaN   \n",
       "3     20626031_day_1         NaN      NaN         NaN        NaN       NaN   \n",
       "4     20626031_day_1         NaN      NaN         NaN        NaN       NaN   \n",
       "..               ...         ...      ...         ...        ...       ...   \n",
       "919  23559586_day_22         NaN      NaN         NaN        NaN       NaN   \n",
       "920  23559586_day_22         NaN      NaN         NaN        NaN       NaN   \n",
       "921  23559586_day_22         NaN      NaN         NaN        NaN       NaN   \n",
       "922  23559586_day_22         NaN      NaN         NaN        NaN       NaN   \n",
       "923  23559586_day_22         NaN      NaN         NaN        NaN       NaN   \n",
       "\n",
       "     gcs_total  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "..         ...  \n",
       "919        NaN  \n",
       "920        NaN  \n",
       "921        NaN  \n",
       "922        NaN  \n",
       "923        NaN  \n",
       "\n",
       "[924 rows x 28 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clif.wide_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a44292",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

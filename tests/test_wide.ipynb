{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "550fb6f4",
   "metadata": {},
   "source": [
    "## Standard test for wide function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027b7e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using directly provided parameters\n",
      "ClifOrchestrator initialized.\n",
      "Using directly provided parameters\n",
      "Loading clif_vitals.parquet\n",
      "Data loaded successfully from clif_vitals.parquet\n",
      "recorded_dttm: Already in your timezone (UTC), no conversion needed.\n",
      "Using directly provided parameters\n",
      "Loading clif_labs.parquet\n",
      "Data loaded successfully from clif_labs.parquet\n",
      "lab_order_dttm: Already in your timezone (UTC), no conversion needed.\n",
      "lab_collect_dttm: Already in your timezone (UTC), no conversion needed.\n",
      "lab_result_dttm: Already in your timezone (UTC), no conversion needed.\n",
      "Using directly provided parameters\n",
      "Loading clif_patient_assessments.parquet\n",
      "Data loaded successfully from clif_patient_assessments.parquet\n",
      "recorded_dttm: Already in your timezone (UTC), no conversion needed.\n",
      "Using directly provided parameters\n",
      "Loading clif_medication_admin_continuous.parquet\n",
      "Data loaded successfully from clif_medication_admin_continuous.parquet\n",
      "admin_dttm: Already in your timezone (UTC), no conversion needed.\n",
      "Loading patient table...\n",
      "Using directly provided parameters\n",
      "Loading clif_patient.parquet\n",
      "Data loaded successfully from clif_patient.parquet\n",
      "death_dttm: Already in your timezone (UTC), no conversion needed.\n",
      "Loading hospitalization table...\n",
      "Using directly provided parameters\n",
      "Loading clif_hospitalization.parquet\n",
      "Data loaded successfully from clif_hospitalization.parquet\n",
      "admission_dttm: Already in your timezone (UTC), no conversion needed.\n",
      "discharge_dttm: Already in your timezone (UTC), no conversion needed.\n",
      "Loading adt table...\n",
      "Using directly provided parameters\n",
      "Loading clif_adt.parquet\n",
      "Data loaded successfully from clif_adt.parquet\n",
      "in_dttm: Already in your timezone (UTC), no conversion needed.\n",
      "out_dttm: Already in your timezone (UTC), no conversion needed.\n",
      "WARNING: Found 9951 rows with both numerical and categorical values!\n",
      "         Numerical values will take precedence in the merged column\n",
      "Created assessment_value column for patient_assessments (using Polars):\n",
      "  - 27454 numerical values (takes precedence)\n",
      "  - 13222 categorical values (used when numerical is null)\n",
      "  - Total non-null assessment values: 30725\n",
      "  - Stored as string type for processing compatibility\n",
      "Starting wide dataset creation...\n",
      "Using cohort_df with time windows for 2 hospitalizations\n",
      "Using 2 hospitalization IDs from cohort_df\n",
      "\n",
      "Loading and filtering base tables...\n",
      "  ADT time filtering: 11 → 8 records\n",
      "Base tables filtered - Hospitalization: 2, Patient: 100, ADT: 8\n",
      "\n",
      "=== Processing Tables ===\n",
      "Base cohort created with 2 records\n",
      "\n",
      "Processing labs...\n",
      "Loaded 931 records from labs\n",
      "  Time filtering: 931 → 728 records\n",
      "Filtering labs categories to: ['creatinine', 'platelet_count', 'po2_arterial', 'bilirubin_total']\n",
      "Pivoted labs: 98 combo_ids with 4 category columns\n",
      "\n",
      "Processing vitals...\n",
      "Loaded 3437 records from vitals\n",
      "  Time filtering: 3437 → 2199 records\n",
      "Filtering vitals categories to: ['map', 'spo2', 'weight_kg']\n",
      "Pivoted vitals: 512 combo_ids with 3 category columns\n",
      "\n",
      "Processing patient_assessments...\n",
      "Loaded 1202 records from patient_assessments\n",
      "  Time filtering: 1202 → 753 records\n",
      "Filtering patient_assessments categories to: ['gcs_total', 'sbt_delivery_pass_fail', 'braden_activity']\n",
      "Pivoted patient_assessments: 85 combo_ids with 3 category columns\n",
      "\n",
      "Processing medication_admin_continuous...\n",
      "Loaded 256 records from medication_admin_continuous\n",
      "  Time filtering: 256 → 255 records\n",
      "Filtering medication_admin_continuous categories to: ['norepinephrine', 'epinephrine', 'phenylephrine', 'vasopressin', 'dopamine', 'angiotensin', 'dobutamine', 'milrinone']\n",
      "Pivoted medication_admin_continuous: 88 combo_ids with 3 category columns\n",
      "\n",
      "=== Creating wide dataset ===\n",
      "Executing join query...\n",
      "Applying cohort time window filtering to final dataset...\n",
      "  Final time filtering: 924 → 924 records\n",
      "Added missing column: epinephrine\n",
      "Added missing column: dopamine\n",
      "Added missing column: angiotensin\n",
      "Added missing column: dobutamine\n",
      "Added missing column: milrinone\n",
      "Wide dataset created: 924 records with 29 columns\n",
      "\n",
      "Optimizing data types for 3 assessment columns using Polars...\n",
      "  Converted to numeric (2 columns):\n",
      "    - gcs_total\n",
      "    - braden_activity\n",
      "  Kept as string (1 columns with mixed/text values):\n",
      "    - sbt_delivery_pass_fail\n",
      "Wide dataset created with shape: (924, 29)\n",
      "Columns: ['hospitalization_id', 'patient_id', 'age_at_admission', 'event_time', 'norepinephrine', 'phenylephrine', 'vasopressin', 'sbt_delivery_pass_fail', 'map', 'spo2', 'weight_kg', 'bilirubin_total', 'creatinine', 'platelet_count', 'po2_arterial', 'hospital_id', 'in_dttm', 'out_dttm', 'location_category', 'location_type', 'day_number', 'hosp_id_day_key', 'epinephrine', 'dopamine', 'angiotensin', 'dobutamine', 'milrinone', 'gcs_total', 'braden_activity']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from clifpy import ClifOrchestrator\n",
    "\n",
    "# Initialize the ClifOrchestrator\n",
    "# You'll need to adjust the data_directory path to your actual data location\n",
    "co = ClifOrchestrator(\n",
    "    data_directory='../clifpy/data/clif_demo/',  # Adjust this path\n",
    "    filetype='parquet',  # or 'csv' depending on your data format\n",
    "    timezone='UTC',\n",
    "    output_directory=None  # Will create 'output' directory in current working directory\n",
    ")\n",
    "\n",
    "# Create the cohort DataFrame\n",
    "cohort_df = pd.DataFrame({\n",
    "    'hospitalization_id': ['23559586', '20626031'],\n",
    "    'start_time': pd.to_datetime(['2137-01-01 14:29:00-06:00', '2132-12-14 08:00:00-06:00']),\n",
    "    'end_time': pd.to_datetime(['2137-08-25 14:00:00-06:00', '2132-12-20 01:00:00-06:00'])\n",
    "})\n",
    "\n",
    "# Load the required tables\n",
    "co.load_table('vitals')\n",
    "co.load_table('labs')\n",
    "co.load_table('patient_assessments')\n",
    "co.load_table('medication_admin_continuous')\n",
    "\n",
    "# Create the wide dataset\n",
    "wide_df = co.create_wide_dataset(\n",
    "   # tables_to_load=['vitals', 'labs', 'patient_assessments', 'medication_admin_continuous'],\n",
    "   \n",
    "    category_filters={\n",
    "        'labs': ['creatinine','platelet_count','po2_arterial','bilirubin_total'],\n",
    "        'vitals': ['map','spo2', 'weight_kg'],\n",
    "        'patient_assessments': ['gcs_total','sbt_delivery_pass_fail','braden_activity'],\n",
    "        \"medication_admin_continuous\": [\"norepinephrine\",\"epinephrine\",\"phenylephrine\",\"vasopressin\",\n",
    "                \"dopamine\",\"angiotensin\",\"dobutamine\",\"milrinone\"]\n",
    "    },\n",
    "    sample=True,  # Use 20 random hospitalizations\n",
    "    cohort_df=cohort_df\n",
    ")\n",
    "\n",
    "# Optional: Display the resulting DataFrame\n",
    "print(f\"Wide dataset created with shape: {co.wide_df.shape}\")\n",
    "print(f\"Columns: {list(co.wide_df.columns)}\")\n",
    "\n",
    "## expected shape -> Wide dataset created with shape: (924, 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fc1e079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hospitalization_id                                 object\n",
       "patient_id                                         object\n",
       "age_at_admission                                    int64\n",
       "event_time                datetime64[us, America/Chicago]\n",
       "norepinephrine                                    float64\n",
       "phenylephrine                                     float64\n",
       "vasopressin                                       float64\n",
       "sbt_delivery_pass_fail                             object\n",
       "map                                               float64\n",
       "spo2                                              float64\n",
       "weight_kg                                         float64\n",
       "bilirubin_total                                   float64\n",
       "creatinine                                        float64\n",
       "platelet_count                                    float64\n",
       "po2_arterial                                      float64\n",
       "hospital_id                                        object\n",
       "in_dttm                   datetime64[us, America/Chicago]\n",
       "out_dttm                  datetime64[us, America/Chicago]\n",
       "location_category                                  object\n",
       "location_type                                      object\n",
       "day_number                                          int64\n",
       "hosp_id_day_key                                    object\n",
       "epinephrine                                       float64\n",
       "dopamine                                          float64\n",
       "angiotensin                                       float64\n",
       "dobutamine                                        float64\n",
       "milrinone                                         float64\n",
       "gcs_total                                         float64\n",
       "braden_activity                                   float64\n",
       "dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co.wide_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44888726",
   "metadata": {},
   "source": [
    "## Wide df test with encounter Stitching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5367fdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: /Users/sudo_sage/Documents/WORK/clifpy/clifpy/data/clif_demo\n",
      "Output directory: /Users/sudo_sage/Documents/WORK/clifpy/examples/output\n",
      "Using directly provided parameters\n",
      "ClifOrchestrator initialized.\n",
      "Using directly provided parameters\n",
      "Loading clif_hospitalization.parquet\n",
      "Data loaded successfully from clif_hospitalization.parquet\n",
      "admission_dttm: null count before conversion= 0\n",
      "admission_dttm: Converted from UTC to your timezone (US/Eastern).\n",
      "admission_dttm: null count after conversion= 0\n",
      "discharge_dttm: null count before conversion= 0\n",
      "discharge_dttm: Converted from UTC to your timezone (US/Eastern).\n",
      "discharge_dttm: null count after conversion= 0\n",
      "Using directly provided parameters\n",
      "Loading clif_adt.parquet\n",
      "Data loaded successfully from clif_adt.parquet\n",
      "in_dttm: null count before conversion= 0\n",
      "in_dttm: Converted from UTC to your timezone (US/Eastern).\n",
      "in_dttm: null count after conversion= 0\n",
      "out_dttm: null count before conversion= 275\n",
      "out_dttm: Converted from UTC to your timezone (US/Eastern).\n",
      "out_dttm: null count after conversion= 275\n",
      "Performing encounter stitching with time interval of 6 hours...\n",
      "Encounter stitching completed successfully.\n",
      "Total hospitalizations: 275\n",
      "Total encounter blocks: 272\n",
      "\n",
      "Encounter mapping shape: (275, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from clifpy import ClifOrchestrator\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def find_project_root(start=None):\n",
    "    p = Path(start or Path.cwd())\n",
    "    for d in [p, *p.parents]:\n",
    "        if (d / \"pyproject.toml\").exists() or (d / \"clifpy\").is_dir():\n",
    "            return d\n",
    "    return p\n",
    "\n",
    "project_root = find_project_root()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "DATA_DIR = (project_root / \"clifpy\" / \"data\" / \"clif_demo\").resolve()\n",
    "OUTPUT_DIR = (project_root / \"examples\" / \"output\").resolve()\n",
    "FILETYPE = \"parquet\"\n",
    "TIMEZONE = \"US/Eastern\"\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "\n",
    "\n",
    "# Initialize orchestrator with encounter stitching enabled\n",
    "clif = ClifOrchestrator(\n",
    "    data_directory=str(DATA_DIR),\n",
    "    filetype=FILETYPE,\n",
    "    timezone=TIMEZONE,\n",
    "    output_directory=str(OUTPUT_DIR),\n",
    "    stitch_encounter=True,  # Enable encounter stitching\n",
    "    stitch_time_interval=6  # 6-hour window (default)\n",
    ")\n",
    "\n",
    "clif.initialize(['hospitalization', 'adt'])\n",
    "\n",
    "# Access the encounter mapping\n",
    "encounter_mapping = clif.get_encounter_mapping()\n",
    "\n",
    "if encounter_mapping is not None:\n",
    "    print(f\"Total hospitalizations: {len(encounter_mapping)}\")\n",
    "    print(f\"Total encounter blocks: {encounter_mapping['encounter_block'].nunique()}\")\n",
    "    print(f\"\\nEncounter mapping shape: {encounter_mapping.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c415ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using directly provided parameters\n",
      "Loading clif_vitals.parquet\n",
      "Data loaded successfully from clif_vitals.parquet\n",
      "recorded_dttm: null count before conversion= 0\n",
      "recorded_dttm: Converted from UTC to your timezone (US/Eastern).\n",
      "recorded_dttm: null count after conversion= 0\n",
      "Using directly provided parameters\n",
      "Loading clif_labs.parquet\n",
      "Data loaded successfully from clif_labs.parquet\n",
      "lab_order_dttm: null count before conversion= 43419\n",
      "lab_order_dttm: Converted from UTC to your timezone (US/Eastern).\n",
      "lab_order_dttm: null count after conversion= 43419\n",
      "lab_collect_dttm: null count before conversion= 0\n",
      "lab_collect_dttm: Converted from UTC to your timezone (US/Eastern).\n",
      "lab_collect_dttm: null count after conversion= 0\n",
      "lab_result_dttm: null count before conversion= 0\n",
      "lab_result_dttm: Converted from UTC to your timezone (US/Eastern).\n",
      "lab_result_dttm: null count after conversion= 0\n",
      "Using directly provided parameters\n",
      "Loading clif_patient_assessments.parquet\n",
      "Data loaded successfully from clif_patient_assessments.parquet\n",
      "recorded_dttm: null count before conversion= 0\n",
      "recorded_dttm: Converted from UTC to your timezone (US/Eastern).\n",
      "recorded_dttm: null count after conversion= 0\n",
      "Using directly provided parameters\n",
      "Loading clif_medication_admin_continuous.parquet\n",
      "Data loaded successfully from clif_medication_admin_continuous.parquet\n",
      "admin_dttm: null count before conversion= 0\n",
      "admin_dttm: Converted from UTC to your timezone (US/Eastern).\n",
      "admin_dttm: null count after conversion= 0\n",
      "==================================================\n",
      "=== WIDE DATASET CREATION STARTED ===\n",
      "==================================================\n",
      "\n",
      "Phase 1: Initialization\n",
      "  1.1: Validating parameters\n",
      "  1.2: Configuring encounter stitching (enabled)\n",
      "\n",
      "Phase 2: Encounter Processing\n",
      "  2.1: === SPECIAL: ENCOUNTER STITCHING ===\n",
      "Info: Encounter stitching has been performed. Your cohort_df uses hospitalization_id. Consider using 'encounter_block' column instead for cleaner encounter-level filtering.\n",
      "\n",
      "Phase 3: Table Loading\n",
      "  3.1: Auto-loading base tables\n",
      "       - Loading patient table...\n",
      "Using directly provided parameters\n",
      "Loading clif_patient.parquet\n",
      "Data loaded successfully from clif_patient.parquet\n",
      "death_dttm: null count before conversion= 85\n",
      "death_dttm: Converted from UTC to your timezone (US/Eastern).\n",
      "death_dttm: null count after conversion= 85\n",
      "  3.2: Loading optional tables: None\n",
      "  === SPECIAL: PATIENT ASSESSMENTS PROCESSING ===\n",
      "       - Merging numerical_value and categorical_value columns\n",
      "       - Using Polars for performance optimization\n",
      "       - WARNING: Found 9951 rows with both values!\n",
      "       -          Numerical values will take precedence\n",
      "       - Created assessment_value column:\n",
      "       -   27454 numerical values (takes precedence)\n",
      "       -   13222 categorical values (used when numerical is null)\n",
      "       -   Total non-null assessment values: 30725\n",
      "       -   Stored as string type for processing compatibility\n",
      "\n",
      "Phase 4: Calling Wide Dataset Utility\n",
      "  4.1: Passing to wide_dataset.create_wide_dataset()\n",
      "       - Tables: None\n",
      "       - Category filters: ['labs', 'vitals', 'patient_assessments', 'medication_admin_continuous']\n",
      "       - Batch size: 1000\n",
      "       - Memory limit: None\n",
      "       - Show progress: True\n",
      "\n",
      "Phase 4: Wide Dataset Processing (utility function)\n",
      "  4.1: Starting wide dataset creation...\n",
      "  === SPECIAL: COHORT TIME WINDOW FILTERING ===\n",
      "       - Processing 2 hospitalizations with time windows\n",
      "       - Ensuring datetime types for start_time, end_time\n",
      "\n",
      "Using 2 hospitalization IDs from cohort_df\n",
      "\n",
      "Loading and filtering base tables...\n",
      "  ADT time filtering: 11 → 8 records\n",
      "       - Base tables filtered - Hospitalization: 2, Patient: 100, ADT: 8\n",
      "\n",
      "  4.2: Determining processing mode\n",
      "       - Single mode: Processing all 2 hospitalizations at once\n",
      "  4.S: === SINGLE PROCESSING MODE ===\n",
      "    4.S.1: Loading and filtering base tables\n",
      "           - Base cohort created with 2 records\n",
      "    4.S.3: Processing tables\n",
      "           - Processing labs...\n",
      "Loaded 931 records from labs\n",
      "           === SPECIAL: TIME FILTERING ===\n",
      "           - Applying cohort time windows to labs\n",
      "           - labs: 931 → 728 records after filtering\n",
      "           === PIVOTING LABS ===\n",
      "           - Categories to pivot: ['creatinine', 'platelet_count', 'po2_arterial', 'bilirubin_total']\n",
      "Filtering labs categories to: ['creatinine', 'platelet_count', 'po2_arterial', 'bilirubin_total']\n",
      "Pivoted labs: 98 combo_ids with 4 category columns\n",
      "           - Processing vitals...\n",
      "Loaded 3437 records from vitals\n",
      "           === SPECIAL: TIME FILTERING ===\n",
      "           - Applying cohort time windows to vitals\n",
      "           - vitals: 3437 → 2199 records after filtering\n",
      "           === PIVOTING VITALS ===\n",
      "           - Categories to pivot: ['map', 'spo2', 'weight_kg']\n",
      "Filtering vitals categories to: ['map', 'spo2', 'weight_kg']\n",
      "Pivoted vitals: 512 combo_ids with 3 category columns\n",
      "           - Processing patient_assessments...\n",
      "Loaded 1202 records from patient_assessments\n",
      "           === SPECIAL: TIME FILTERING ===\n",
      "           - Applying cohort time windows to patient_assessments\n",
      "           - patient_assessments: 1202 → 753 records after filtering\n",
      "           === PIVOTING PATIENT_ASSESSMENTS ===\n",
      "           - Categories to pivot: ['gcs_total']\n",
      "Filtering patient_assessments categories to: ['gcs_total']\n",
      "Pivoted patient_assessments: 70 combo_ids with 1 category columns\n",
      "           - Processing medication_admin_continuous...\n",
      "Loaded 256 records from medication_admin_continuous\n",
      "           === SPECIAL: TIME FILTERING ===\n",
      "           - Applying cohort time windows to medication_admin_continuous\n",
      "           - medication_admin_continuous: 256 → 255 records after filtering\n",
      "           === PIVOTING MEDICATION_ADMIN_CONTINUOUS ===\n",
      "           - Categories to pivot: ['norepinephrine', 'epinephrine', 'phenylephrine', 'vasopressin', 'dopamine', 'angiotensin', 'dobutamine', 'milrinone']\n",
      "Filtering medication_admin_continuous categories to: ['norepinephrine', 'epinephrine', 'phenylephrine', 'vasopressin', 'dopamine', 'angiotensin', 'dobutamine', 'milrinone']\n",
      "Pivoted medication_admin_continuous: 88 combo_ids with 3 category columns\n",
      "    4.S.4: Creating wide dataset\n",
      "           - Building event time union from 5 tables\n",
      "           - Creating combo_id keys\n",
      "           - Executing main join query\n",
      "Executing join query...\n",
      "Applying cohort time window filtering to final dataset...\n",
      "  Final time filtering: 924 → 924 records\n",
      "    === SPECIAL: MISSING COLUMNS ===\n",
      "           - Added missing column: epinephrine\n",
      "           - Added missing column: dopamine\n",
      "           - Added missing column: angiotensin\n",
      "           - Added missing column: dobutamine\n",
      "           - Added missing column: milrinone\n",
      "\n",
      "    4.S.6: Final cleanup\n",
      "           - Removing duplicate columns\n",
      "           - Dropping temporary columns (combo_id, date)\n",
      "           - Wide dataset created: 924 records with 28 columns\n",
      "\n",
      "Phase 5: Post-Processing\n",
      "  5.1: === SPECIAL: ADDING ENCOUNTER BLOCKS ===\n",
      "       - Encounter_block column already present - 2 unique encounter blocks\n",
      "  5.2: === SPECIAL: ASSESSMENT TYPE OPTIMIZATION ===\n",
      "       - Using Polars for performance optimization\n",
      "       - Analyzing 1 assessment columns\n",
      "       - Converted to numeric (1 columns):\n",
      "       -   gcs_total\n",
      "\n",
      "Phase 6: Completion\n",
      "  6.1: Wide dataset stored in self.wide_df\n",
      "  6.2: Dataset shape: 924 rows x 28 columns\n",
      "\n",
      "==================================================\n",
      "=== WIDE DATASET CREATION COMPLETED ===\n",
      "==================================================\n",
      "\n",
      "Wide dataset created with shape: (924, 28)\n",
      "Columns: ['hospitalization_id', 'patient_id', 'age_at_admission', 'event_time', 'norepinephrine', 'phenylephrine', 'vasopressin', 'map', 'spo2', 'weight_kg', 'bilirubin_total', 'creatinine', 'platelet_count', 'po2_arterial', 'hospital_id', 'in_dttm', 'out_dttm', 'location_category', 'location_type', 'encounter_block', 'day_number', 'hosp_id_day_key', 'epinephrine', 'dopamine', 'angiotensin', 'dobutamine', 'milrinone', 'gcs_total']\n"
     ]
    }
   ],
   "source": [
    "# Create the cohort DataFrame\n",
    "cohort_df = pd.DataFrame({\n",
    "    'hospitalization_id': ['23559586', '20626031'],\n",
    "    'start_time': pd.to_datetime(['2137-01-01 14:29:00-06:00', '2132-12-14 08:00:00-06:00']),\n",
    "    'end_time': pd.to_datetime(['2137-08-25 14:00:00-06:00', '2132-12-20 01:00:00-06:00'])\n",
    "})\n",
    "\n",
    "# Load the required tables\n",
    "clif.load_table('vitals')\n",
    "clif.load_table('labs')\n",
    "clif.load_table('patient_assessments')\n",
    "clif.load_table('medication_admin_continuous')\n",
    "\n",
    "# Create the wide dataset\n",
    "clif.create_wide_dataset(\n",
    "   # tables_to_load=['vitals', 'labs', 'patient_assessments', 'medication_admin_continuous'],\n",
    "   \n",
    "    category_filters={\n",
    "        'labs': ['creatinine','platelet_count','po2_arterial','bilirubin_total'],\n",
    "        'vitals': ['map','spo2', 'weight_kg'],\n",
    "        'patient_assessments': ['gcs_total'],\n",
    "        \"medication_admin_continuous\": [\"norepinephrine\",\"epinephrine\",\"phenylephrine\",\"vasopressin\",\n",
    "                \"dopamine\",\"angiotensin\",\"dobutamine\",\"milrinone\"]\n",
    "    },\n",
    "    sample=True,  # Use 20 random hospitalizations\n",
    "    cohort_df=cohort_df\n",
    ")\n",
    "\n",
    "# Optional: Display the resulting DataFrame\n",
    "print(f\"Wide dataset created with shape: {clif.wide_df.shape}\")\n",
    "print(f\"Columns: {list(clif.wide_df.columns)}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test ASE (Adult Sepsis Event) Implementation\n",
        "\n",
        "This notebook tests the `compute_ase()` function using CLIFpy's demo data or your specified data directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup: Import required packages\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add the project root to path to ensure we're using the local clifpy\n",
        "project_root = Path().absolute().parent\n",
        "if str(project_root) not in sys.path:\n",
        "    sys.path.insert(0, str(project_root))\n",
        "\n",
        "print(f\"Project root: {project_root}\")\n",
        "print(f\"Using clifpy from: {project_root / 'clifpy'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import ASE functions\n",
        "from clifpy.utils.ase import compute_ase\n",
        "from clifpy.data.loader import _get_demo_data_path\n",
        "\n",
        "print(\"ASE module imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configure Data Source\n",
        "\n",
        "You can either use the demo data or specify your own data directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option 1: Use demo data (default)\n",
        "use_demo_data = False\n",
        "\n",
        "if use_demo_data:\n",
        "    data_directory = _get_demo_data_path()\n",
        "    print(f\"Using demo data from: {data_directory}\")\n",
        "    # Configuration\n",
        "    filetype = 'parquet'  # or 'csv' if your data is in CSV format\n",
        "    timezone = 'US/Eastern'      # Adjust based on your data's timezone\n",
        "else:\n",
        "    # Option 2: Specify your own data directory\n",
        "    # Update this path to your CLIF data directory\n",
        "    data_directory = \"path/to/2.1.0\"  \n",
        "    print(f\"Using custom data from: {data_directory}\")\n",
        "    # Configuration\n",
        "    filetype = 'parquet'  # or 'csv' if your data is in CSV format\n",
        "    timezone = 'US/Central'      # Adjust based on your data's timezone\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List available data files\n",
        "import os\n",
        "\n",
        "if os.path.exists(data_directory):\n",
        "    data_files = sorted([f for f in os.listdir(data_directory) if f.endswith('.parquet') or f.endswith('.csv')])\n",
        "    print(f\"Available data files ({len(data_files)}):\")\n",
        "    for f in data_files[:10]:  # Show first 10 files\n",
        "        file_path = os.path.join(data_directory, f)\n",
        "        size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
        "        print(f\"  - {f} ({size_mb:.2f} MB)\")\n",
        "    if len(data_files) > 10:\n",
        "        print(f\"  ... and {len(data_files) - 10} more files\")\n",
        "else:\n",
        "    print(f\"Error: Data directory not found: {data_directory}\")\n",
        "    print(\"Please update the data_directory path above.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Get Hospitalization IDs for Cohort\n",
        "\n",
        "Let's load the hospitalization data to get some IDs for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load hospitalization data to get IDs\n",
        "hosp_file = os.path.join(data_directory, f\"clif_hospitalization.{filetype}\")\n",
        "\n",
        "if os.path.exists(hosp_file):\n",
        "    if filetype == 'parquet':\n",
        "        hosp_df = pd.read_parquet(hosp_file)\n",
        "    else:\n",
        "        hosp_df = pd.read_csv(hosp_file)\n",
        "    \n",
        "    print(f\"Hospitalization data shape: {hosp_df.shape}\")\n",
        "    print(f\"Columns: {list(hosp_df.columns)}\")\n",
        "    \n",
        "    # Get unique hospitalization IDs\n",
        "    hospitalization_ids = hosp_df['hospitalization_id'].unique().tolist()\n",
        "    print(f\"\\nTotal hospitalizations available: {len(hospitalization_ids)}\")\n",
        "    \n",
        "    # Select a subset for testing (adjust as needed)\n",
        "    test_hosp_ids = hospitalization_ids[:10]  # Test with first 10 hospitalizations\n",
        "    print(f\"Selected {len(test_hosp_ids)} hospitalizations for testing\")\n",
        "    print(f\"Sample IDs: {test_hosp_ids[:5]}\")\n",
        "else:\n",
        "    print(f\"Hospitalization file not found: {hosp_file}\")\n",
        "    # Manual specification if file not found\n",
        "    test_hosp_ids = ['hosp1', 'hosp2']  # Update with actual IDs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Run ASE Computation\n",
        "\n",
        "Now let's compute ASE for the selected hospitalizations. This will identify Adult Sepsis Events based on CDC criteria."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "# Run ASE computation\n",
        "print(\"Starting ASE computation...\")\n",
        "print(f\"Processing {len(hospitalization_ids)} hospitalizations\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "ase_results = compute_ase(\n",
        "    hospitalization_ids=hospitalization_ids,\n",
        "    data_directory=data_directory,\n",
        "    filetype=filetype,\n",
        "    timezone=timezone,\n",
        "    apply_rit=True,           # Apply 14-day Repeat Infection Timeframe\n",
        "    include_lactate=False,    # Include lactate criterion\n",
        "    verbose=True              # Show detailed progress\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"‚úÖ ASE computation complete!\")\n",
        "print(f\"Result shape: {ase_results.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Examine Results\n",
        "\n",
        "Let's explore the ASE results in detail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display columns in the result\n",
        "print(\"Result columns:\")\n",
        "for i, col in enumerate(ase_results.columns, 1):\n",
        "    print(f\"  {i:2}. {col}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Count unique hospitalization IDs with sepsis- \n",
        "unique_hosp_sepsis = ase_results.loc[ase_results['sepsis'] == 1, 'hospitalization_id'].nunique()\n",
        "\n",
        "# Count total unique hospitalization IDs\n",
        "total_hosp = ase_results['hospitalization_id'].nunique()\n",
        "\n",
        "# Calculate percentage\n",
        "sepsis_percentage = (unique_hosp_sepsis / total_hosp) * 100\n",
        "\n",
        "# Display results\n",
        "print(f\"Unique hospitalizations with sepsis: {unique_hosp_sepsis:,}\")\n",
        "print(f\"Total unique hospitalizations: {total_hosp:,}\")\n",
        "print(f\"Percentage with sepsis: {sepsis_percentage:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Overall statistics\n",
        "total_hosps = ase_results['hospitalization_id'].nunique()\n",
        "total_blood_cultures = ase_results[ase_results['bc_id'].notna()]['bc_id'].count()\n",
        "total_sepsis_events = ase_results['sepsis'].sum()\n",
        "total_sepsis_wo_lactate = ase_results['sepsis_wo_lactate'].sum()\n",
        "\n",
        "print(\"=== ASE Summary Statistics ===\")\n",
        "print(f\"Total hospitalizations processed: {total_hosps}\")\n",
        "print(f\"Total blood cultures evaluated: {total_blood_cultures}\")\n",
        "print(f\"Total ASE events (with lactate): {total_sepsis_events}\")\n",
        "print(f\"Total ASE events (without lactate): {total_sepsis_wo_lactate}\")\n",
        "\n",
        "if total_blood_cultures > 0:\n",
        "    print(f\"\\nASE rate per blood culture: {total_sepsis_events/total_blood_cultures:.1%}\")\n",
        "    print(f\"ASE rate per hospitalization: {total_sepsis_events/total_hosps:.1%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show ASE events\n",
        "ase_events = ase_results[ase_results['sepsis'] == 1]\n",
        "\n",
        "if len(ase_events) > 0:\n",
        "    print(f\"\\n=== ASE Events ({len(ase_events)} total) ===\")\n",
        "    display_cols = ['hospitalization_id', 'bc_id', 'episode_id', 'type', \n",
        "                   'ase_onset_w_lactate_dttm', 'ase_first_criteria_w_lactate']\n",
        "    print(ase_events[display_cols].head(10))\n",
        "else:\n",
        "    print(\"No ASE events detected in this cohort.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze reasons for no sepsis\n",
        "no_sepsis_reasons = ase_results['no_sepsis_reason'].value_counts()\n",
        "\n",
        "print(\"\\n=== Reasons for No Sepsis ===\")\n",
        "for reason, count in no_sepsis_reasons.items():\n",
        "    if pd.notna(reason):\n",
        "        print(f\"  {reason}: {count} ({count/len(ase_results):.1%})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Look at presumed infection (Component A)\n",
        "presumed_infection_count = ase_results['presumed_infection'].sum()\n",
        "\n",
        "print(\"\\n=== Component A: Presumed Infection ===\")\n",
        "print(f\"Blood cultures with presumed infection: {presumed_infection_count}\")\n",
        "if total_blood_cultures > 0:\n",
        "    print(f\"Presumed infection rate: {presumed_infection_count/total_blood_cultures:.1%}\")\n",
        "\n",
        "# Show some presumed infections\n",
        "presumed = ase_results[ase_results['presumed_infection'] == 1]\n",
        "if len(presumed) > 0:\n",
        "    print(\"\\nSample presumed infections:\")\n",
        "    display_cols = ['hospitalization_id', 'bc_id', 'blood_culture_dttm', \n",
        "                   'total_qad', 'qad_start_date', 'qad_end_date']\n",
        "    available_cols = [c for c in display_cols if c in presumed.columns]\n",
        "    print(presumed[available_cols].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Look at organ dysfunction criteria\n",
        "print(\"\\n=== Component B: Organ Dysfunction Criteria ===\")\n",
        "\n",
        "organ_cols = [\n",
        "    'vasopressor_dttm', 'imv_dttm', 'aki_dttm', \n",
        "    'hyperbilirubinemia_dttm', 'thrombocytopenia_dttm', 'lactate_dttm'\n",
        "]\n",
        "\n",
        "for col in organ_cols:\n",
        "    if col in ase_results.columns:\n",
        "        count = ase_results[col].notna().sum()\n",
        "        organ_name = col.replace('_dttm', '').replace('_', ' ').title()\n",
        "        print(f\"  {organ_name}: {count} events\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Test Different Configurations\n",
        "\n",
        "Let's test ASE with different configuration options."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with lactate criterion included\n",
        "print(\"Testing with lactate criterion included...\")\n",
        "\n",
        "ase_with_lactate = compute_ase(\n",
        "    hospitalization_ids=hospitalization_ids,  # Use fewer IDs for quick test\n",
        "    data_directory=data_directory,\n",
        "    filetype=filetype,\n",
        "    timezone=timezone,\n",
        "    apply_rit=True,\n",
        "    include_lactate=True,  # Include lactate\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "sepsis_with_lactate = ase_with_lactate['sepsis'].sum()\n",
        "sepsis_without_lactate = ase_with_lactate['sepsis_wo_lactate'].sum()\n",
        "\n",
        "print(f\"\\nResults with lactate criterion:\")\n",
        "print(f\"  ASE events (with lactate): {sepsis_with_lactate}\")\n",
        "print(f\"  ASE events (without lactate): {sepsis_without_lactate}\")\n",
        "print(f\"  Additional events from lactate: {sepsis_with_lactate - sepsis_without_lactate}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test without RIT (Repeat Infection Timeframe)\n",
        "print(\"Testing without RIT filtering...\")\n",
        "\n",
        "ase_no_rit = compute_ase(\n",
        "    hospitalization_ids=hospitalization_ids,\n",
        "    data_directory=data_directory,\n",
        "    filetype=filetype,\n",
        "    timezone=timezone,\n",
        "    apply_rit=False,  # No RIT filtering\n",
        "    include_lactate=False,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "sepsis_no_rit = ase_no_rit['sepsis'].sum()\n",
        "\n",
        "print(f\"\\nResults without RIT:\")\n",
        "print(f\"  ASE events (no RIT): {sepsis_no_rit}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Validation\n",
        "\n",
        "Let's validate that the ASE results are consistent and correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validation checks\n",
        "print(\"=== Validation Checks ===\")\n",
        "print()\n",
        "\n",
        "# Check 1: All hospitalizations are present\n",
        "result_hosps = set(ase_results['hospitalization_id'].unique())\n",
        "input_hosps = set(test_hosp_ids)\n",
        "missing = input_hosps - result_hosps\n",
        "status = \"‚úÖ\" if len(missing) == 0 else \"‚ùå\"\n",
        "print(f\"{status} All hospitalizations processed: {len(missing) == 0}\")\n",
        "if missing:\n",
        "    print(f\"   Missing: {missing}\")\n",
        "\n",
        "# Check 2: Sepsis requires presumed infection\n",
        "invalid_sepsis = ase_results[(ase_results['sepsis'] == 1) & (ase_results['presumed_infection'] != 1)]\n",
        "status = \"‚úÖ\" if len(invalid_sepsis) == 0 else \"‚ùå\"\n",
        "print(f\"{status} All sepsis events have presumed infection: {len(invalid_sepsis) == 0}\")\n",
        "\n",
        "# Check 3: Episode IDs are sequential within hospitalization\n",
        "episodes = ase_results[ase_results['episode_id'].notna()]\n",
        "if len(episodes) > 0:\n",
        "    valid_episodes = True\n",
        "    for hosp_id in episodes['hospitalization_id'].unique():\n",
        "        hosp_episodes = episodes[episodes['hospitalization_id'] == hosp_id]['episode_id'].sort_values()\n",
        "        expected = list(range(1, len(hosp_episodes) + 1))\n",
        "        if list(hosp_episodes) != expected:\n",
        "            valid_episodes = False\n",
        "            break\n",
        "    status = \"‚úÖ\" if valid_episodes else \"‚ùå\"\n",
        "    print(f\"{status} Episode IDs are sequential: {valid_episodes}\")\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è No episodes to validate\")\n",
        "\n",
        "# Check 4: Type is either community, hospital, or NA\n",
        "valid_types = {'community', 'hospital', pd.NA, None, np.nan}\n",
        "invalid_types = set(ase_results['type'].unique()) - valid_types\n",
        "status = \"‚úÖ\" if len(invalid_types) == 0 else \"‚ùå\"\n",
        "print(f\"{status} All onset types are valid: {len(invalid_types) == 0}\")\n",
        "if invalid_types:\n",
        "    print(f\"   Invalid types: {invalid_types}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéâ ASE testing complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Export Results (Optional)\n",
        "\n",
        "Save the results for further analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to save results\n",
        "# output_file = 'ase_results.csv'\n",
        "# ase_results.to_csv(output_file, index=False)\n",
        "# print(f\"Results saved to {output_file}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}

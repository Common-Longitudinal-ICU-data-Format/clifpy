{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timezone Handling in pyCLIF\n",
    "\n",
    "This notebook demonstrates comprehensive timezone handling capabilities in pyCLIF, including automatic conversion, timezone awareness, and best practices for working with datetime data.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Healthcare data often comes from different sources with various timezone configurations. pyCLIF provides robust timezone handling to ensure:\n",
    "- Consistent datetime interpretation\n",
    "- Automatic conversion to site timezones\n",
    "- Preservation of original timezone information\n",
    "- Support for multiple timezone formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytz\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "# Import pyCLIF components\n",
    "from pyclif import CLIF\n",
    "from pyclif.tables.vitals import vitals\n",
    "from pyclif.utils.io import load_data, convert_datetime_columns_to_site_tz\n",
    "\n",
    "print(f\"Timezone handling setup complete!\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Pytz version: {pytz.__version__}\")\n",
    "\n",
    "# Display current system timezone\n",
    "print(f\"\\nSystem timezone info:\")\n",
    "print(f\"Local time: {datetime.now()}\")\n",
    "print(f\"UTC time: {datetime.utcnow()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data directory\n",
    "DATA_DIR = \"/Users/vaishvik/downloads/CLIF_MIMIC\"\n",
    "print(f\"Data directory: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Timezone Formats\n",
    "\n",
    "pyCLIF supports various timezone formats commonly used in healthcare settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common timezone formats in healthcare\n",
    "common_timezones = {\n",
    "    'US/Eastern': 'Eastern Time (US)',\n",
    "    'US/Central': 'Central Time (US)',\n",
    "    'US/Mountain': 'Mountain Time (US)',\n",
    "    'US/Pacific': 'Pacific Time (US)',\n",
    "    'America/New_York': 'New York (Eastern)',\n",
    "    'America/Chicago': 'Chicago (Central)',\n",
    "    'America/Denver': 'Denver (Mountain)',\n",
    "    'America/Los_Angeles': 'Los Angeles (Pacific)',\n",
    "    'UTC': 'Coordinated Universal Time',\n",
    "    'GMT': 'Greenwich Mean Time'\n",
    "}\n",
    "\n",
    "print(\"=== SUPPORTED TIMEZONE FORMATS ===\")\n",
    "current_time = datetime.now()\n",
    "\n",
    "for tz_name, description in common_timezones.items():\n",
    "    try:\n",
    "        tz = pytz.timezone(tz_name)\n",
    "        local_time = tz.normalize(tz.localize(current_time.replace(tzinfo=None)))\n",
    "        print(f\"{tz_name:<20}: {description:<25} | {local_time.strftime('%Y-%m-%d %H:%M:%S %Z')}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{tz_name:<20}: {description:<25} | Error: {e}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Your site timezone (US/Eastern): {pytz.timezone('US/Eastern')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data with Timezone Conversion\n",
    "\n",
    "Demonstrate different methods of loading data with timezone handling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Using CLIF Class with Timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data using main CLIF class with timezone specification\n",
    "clif_eastern = CLIF(\n",
    "    data_dir=DATA_DIR,\n",
    "    filetype='parquet',\n",
    "    timezone='US/Eastern'  # Your site timezone\n",
    ")\n",
    "\n",
    "print(f\"CLIF object initialized with timezone: {clif_eastern.timezone}\")\n",
    "\n",
    "# Load vitals data\n",
    "clif_eastern.initialize(tables=['vitals'])\n",
    "\n",
    "if clif_eastern.vitals and clif_eastern.vitals.df is not None:\n",
    "    print(f\"\\nVitals data loaded: {clif_eastern.vitals.df.shape}\")\n",
    "    \n",
    "    # Check datetime columns and their timezone info\n",
    "    datetime_cols = [col for col in clif_eastern.vitals.df.columns if 'dttm' in col]\n",
    "    print(f\"DateTime columns found: {datetime_cols}\")\n",
    "    \n",
    "    for col in datetime_cols:\n",
    "        if col in clif_eastern.vitals.df.columns:\n",
    "            sample_dt = clif_eastern.vitals.df[col].dropna().iloc[0] if not clif_eastern.vitals.df[col].dropna().empty else None\n",
    "            if sample_dt is not None:\n",
    "                tz_info = getattr(sample_dt, 'tz', 'No timezone info')\n",
    "                print(f\"  {col}: {sample_dt} (TZ: {tz_info})\")\nelse:\n    print(\"No vitals data available for timezone demonstration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Manual Timezone Conversion with load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data with explicit timezone conversion\n",
    "vitals_eastern = load_data(\n",
    "    table_name=\"vitals\",\n",
    "    table_path=DATA_DIR,\n",
    "    table_format_type=\"parquet\",\n",
    "    sample_size=1000,  # Smaller sample for demonstration\n",
    "    site_tz=\"US/Eastern\"  # Explicit timezone conversion\n",
    ")\n",
    "\n",
    "print(f\"Vitals data loaded with timezone conversion: {vitals_eastern.shape}\")\n",
    "\n",
    "# Check the timezone of datetime columns\n",
    "datetime_cols = [col for col in vitals_eastern.columns if 'dttm' in col]\n",
    "print(f\"\\nDateTime columns after conversion:\")\n",
    "\n",
    "for col in datetime_cols:\n",
    "    if col in vitals_eastern.columns and not vitals_eastern[col].dropna().empty:\n",
    "        sample_dt = vitals_eastern[col].dropna().iloc[0]\n",
    "        tz_info = getattr(sample_dt, 'tz', 'No timezone info')\n",
    "        print(f\"  {col}: {sample_dt} (TZ: {tz_info})\")\n",
    "        \n",
    "        # Show timezone distribution\n",
    "        if hasattr(sample_dt, 'tz') and sample_dt.tz is not None:\n",
    "            print(f\"    ‚úÖ Timezone-aware data in {sample_dt.tz}\")\n",
    "        else:\n",
    "            print(f\"    ‚ö†Ô∏è  Naive datetime (no timezone info)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3: Comparing Different Timezones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the same data with different timezone conversions\n",
    "timezone_comparison = {}\n",
    "\n",
    "timezones_to_test = ['UTC', 'US/Eastern', 'US/Central', 'US/Pacific']\n",
    "\n",
    "for tz in timezones_to_test:\n",
    "    try:\n",
    "        tz_data = load_data(\n",
    "            table_name=\"vitals\",\n",
    "            table_path=DATA_DIR,\n",
    "            table_format_type=\"parquet\",\n",
    "            sample_size=100,  # Small sample for quick comparison\n",
    "            site_tz=tz\n",
    "        )\n",
    "        \n",
    "        # Get a sample datetime\n",
    "        datetime_col = [col for col in tz_data.columns if 'dttm' in col][0]\n",
    "        sample_datetime = tz_data[datetime_col].dropna().iloc[0] if not tz_data[datetime_col].dropna().empty else None\n",
    "        \n",
    "        timezone_comparison[tz] = {\n",
    "            'sample_datetime': sample_datetime,\n",
    "            'timezone_info': getattr(sample_datetime, 'tz', None) if sample_datetime else None,\n",
    "            'records': len(tz_data)\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        timezone_comparison[tz] = {'error': str(e)}\n",
    "\n",
    "print(\"=== TIMEZONE COMPARISON ===\")\n",
    "print(f\"Sample datetime values across different timezones:\")\n",
    "print()\n",
    "\n",
    "for tz, info in timezone_comparison.items():\n",
    "    if 'error' in info:\n",
    "        print(f\"{tz:<12}: Error - {info['error']}\")\n",
    "    else:\n",
    "        sample_dt = info['sample_datetime']\n",
    "        tz_info = info['timezone_info']\n",
    "        print(f\"{tz:<12}: {sample_dt} (TZ: {tz_info})\")\n",
    "\n",
    "# Show time differences\n",
    "if len([tz for tz in timezone_comparison.keys() if 'error' not in timezone_comparison[tz]]) >= 2:\n",
    "    print(\"\\n=== TIME DIFFERENCES ===\")\n",
    "    reference_tz = 'UTC'\n",
    "    if reference_tz in timezone_comparison and 'error' not in timezone_comparison[reference_tz]:\n",
    "        ref_time = timezone_comparison[reference_tz]['sample_datetime']\n",
    "        \n",
    "        for tz, info in timezone_comparison.items():\n",
    "            if 'error' not in info and tz != reference_tz:\n",
    "                tz_time = info['sample_datetime']\n",
    "                if ref_time and tz_time:\n",
    "                    try:\n",
    "                        # Convert both to naive for comparison\n",
    "                        ref_naive = ref_time.replace(tzinfo=None) if hasattr(ref_time, 'tz') else ref_time\n",
    "                        tz_naive = tz_time.replace(tzinfo=None) if hasattr(tz_time, 'tz') else tz_time\n",
    "                        diff = tz_naive - ref_naive\n",
    "                        print(f\"{tz} vs {reference_tz}: {diff} ({diff.total_seconds()/3600:.1f} hours)\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"{tz} vs {reference_tz}: Comparison error - {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Timezone Conversion Functions\n",
    "\n",
    "Demonstrate the manual timezone conversion utility function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test data with datetime columns\n",
    "test_datetime_data = pd.DataFrame({\n",
    "    'patient_id': ['P001', 'P002', 'P003', 'P004', 'P005'],\n",
    "    'event_dttm': [\n",
    "        '2023-06-15 08:30:00',\n",
    "        '2023-06-15 14:45:00',\n",
    "        '2023-06-15 20:15:00',\n",
    "        '2023-06-16 02:30:00',\n",
    "        '2023-06-16 11:00:00'\n",
    "    ],\n",
    "    'recorded_dttm': [\n",
    "        '2023-06-15 08:32:00',\n",
    "        '2023-06-15 14:47:00',\n",
    "        '2023-06-15 20:17:00',\n",
    "        '2023-06-16 02:32:00',\n",
    "        '2023-06-16 11:02:00'\n",
    "    ],\n",
    "    'value': [98.6, 99.1, 98.4, 97.8, 98.9]\n",
    "})\n",
    "\n",
    "print(\"=== ORIGINAL TEST DATA ===\")\n",
    "print(\"Original datetime data (assumed to be in UTC):\")\n",
    "print(test_datetime_data)\n",
    "\n",
    "# Convert datetime columns to pandas datetime\n",
    "for col in ['event_dttm', 'recorded_dttm']:\n",
    "    test_datetime_data[col] = pd.to_datetime(test_datetime_data[col])\n",
    "\n",
    "print(f\"\\nDatetime column types:\")\n",
    "for col in ['event_dttm', 'recorded_dttm']:\n",
    "    print(f\"  {col}: {test_datetime_data[col].dtype}\")\n",
    "    sample_val = test_datetime_data[col].iloc[0]\n",
    "    print(f\"    Sample: {sample_val} (TZ: {getattr(sample_val, 'tz', 'naive')})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply timezone conversion using the utility function\n",
    "print(\"=== TIMEZONE CONVERSION DEMONSTRATION ===\")\n",
    "\n",
    "# Convert to US/Eastern\n",
    "eastern_data = test_datetime_data.copy()\n",
    "eastern_converted = convert_datetime_columns_to_site_tz(\n",
    "    eastern_data, \n",
    "    site_tz_str='US/Eastern',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\nData after conversion to US/Eastern:\")\n",
    "print(eastern_converted[['patient_id', 'event_dttm', 'recorded_dttm']].head())\n",
    "\n",
    "# Check timezone info after conversion\n",
    "print(f\"\\nTimezone info after conversion:\")\n",
    "for col in ['event_dttm', 'recorded_dttm']:\n",
    "    sample_val = eastern_converted[col].iloc[0]\n",
    "    print(f\"  {col}: {sample_val} (TZ: {getattr(sample_val, 'tz', 'naive')})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different timezone conversions\n",
    "timezone_conversions = {}\n",
    "target_timezones = ['US/Eastern', 'US/Central', 'US/Pacific', 'UTC']\n",
    "\n",
    "for tz in target_timezones:\n",
    "    tz_data = test_datetime_data.copy()\n",
    "    try:\n",
    "        converted_data = convert_datetime_columns_to_site_tz(\n",
    "            tz_data, \n",
    "            site_tz_str=tz,\n",
    "            verbose=False  # Suppress output for cleaner display\n",
    "        )\n",
    "        timezone_conversions[tz] = converted_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting to {tz}: {e}\")\n",
    "\n",
    "# Display comparison\n",
    "print(\"=== TIMEZONE CONVERSION COMPARISON ===\")\n",
    "print(\"Same event in different timezones:\")\n",
    "print()\n",
    "\n",
    "# Show first event across all timezones\n",
    "event_index = 0\n",
    "print(f\"Patient: {test_datetime_data.iloc[event_index]['patient_id']}\")\n",
    "print(f\"Original event_dttm: {test_datetime_data.iloc[event_index]['event_dttm']} (naive)\")\n",
    "print()\n",
    "\n",
    "for tz, data in timezone_conversions.items():\n",
    "    event_time = data.iloc[event_index]['event_dttm']\n",
    "    print(f\"{tz:<12}: {event_time}\")\n",
    "\n",
    "print(f\"\\nüí° Note: All times represent the same moment, just displayed in different timezones.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Data Timezone Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze timezone patterns in real data\n",
    "if clif_eastern.vitals and clif_eastern.vitals.df is not None:\n",
    "    vitals_df = clif_eastern.vitals.df\n",
    "    \n",
    "    # Focus on datetime columns\n",
    "    datetime_cols = [col for col in vitals_df.columns if 'dttm' in col]\n",
    "    \n",
    "    print(\"=== REAL DATA TIMEZONE ANALYSIS ===\")\n",
    "    print(f\"Dataset: {len(vitals_df):,} records\")\n",
    "    print(f\"DateTime columns: {datetime_cols}\")\n",
    "    \n",
    "    for col in datetime_cols:\n",
    "        if col in vitals_df.columns:\n",
    "            print(f\"\\nAnalyzing column: {col}\")\n",
    "            \n",
    "            # Basic statistics\n",
    "            non_null_count = vitals_df[col].notna().sum()\n",
    "            print(f\"  Non-null values: {non_null_count:,} ({non_null_count/len(vitals_df)*100:.1f}%)\")\n",
    "            \n",
    "            if non_null_count > 0:\n",
    "                # Date range\n",
    "                min_date = vitals_df[col].min()\n",
    "                max_date = vitals_df[col].max()\n",
    "                date_range = max_date - min_date\n",
    "                \n",
    "                print(f\"  Date range: {min_date} to {max_date}\")\n",
    "                print(f\"  Span: {date_range.days} days\")\n",
    "                \n",
    "                # Timezone info\n",
    "                sample_datetime = vitals_df[col].dropna().iloc[0]\n",
    "                if hasattr(sample_datetime, 'tz') and sample_datetime.tz is not None:\n",
    "                    print(f\"  Timezone: {sample_datetime.tz}\")\n",
    "                    print(f\"  ‚úÖ Timezone-aware data\")\n",
    "                else:\n",
    "                    print(f\"  ‚ö†Ô∏è  Naive datetime (no timezone)\")\n",
    "                \n",
    "                # Hourly distribution\n",
    "                vitals_df_copy = vitals_df.copy()\n",
    "                vitals_df_copy['hour'] = vitals_df_copy[col].dt.hour\n",
    "                hourly_dist = vitals_df_copy['hour'].value_counts().sort_index()\n",
    "                \n",
    "                print(f\"  Peak hour: {hourly_dist.idxmax()}:00 ({hourly_dist.max():,} records)\")\n",
    "                print(f\"  Quiet hour: {hourly_dist.idxmin()}:00 ({hourly_dist.min():,} records)\")\nelse:\n    print(\"No vitals data available for timezone analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Timezone Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization of timezone effects\n",
    "if clif_eastern.vitals and clif_eastern.vitals.df is not None:\n",
    "    vitals_sample = clif_eastern.vitals.df.head(1000).copy()  # Sample for performance\n",
    "    datetime_col = [col for col in vitals_sample.columns if 'dttm' in col][0]\n",
    "    \n",
    "    if datetime_col in vitals_sample.columns:\n",
    "        # Extract hour information\n",
    "        vitals_sample['hour'] = vitals_sample[datetime_col].dt.hour\n",
    "        vitals_sample['day_of_week'] = vitals_sample[datetime_col].dt.day_name()\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        \n",
    "        # Hourly distribution\n",
    "        hourly_counts = vitals_sample['hour'].value_counts().sort_index()\n",
    "        axes[0, 0].bar(hourly_counts.index, hourly_counts.values)\n",
    "        axes[0, 0].set_title('Vital Signs Measurements by Hour of Day\\n(US/Eastern Time)')\n",
    "        axes[0, 0].set_xlabel('Hour of Day')\n",
    "        axes[0, 0].set_ylabel('Number of Measurements')\n",
    "        axes[0, 0].set_xticks(range(0, 24, 2))\n",
    "        \n",
    "        # Day of week distribution\n",
    "        day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "        day_counts = vitals_sample['day_of_week'].value_counts().reindex(day_order)\n",
    "        axes[0, 1].bar(range(len(day_counts)), day_counts.values)\n",
    "        axes[0, 1].set_title('Vital Signs Measurements by Day of Week')\n",
    "        axes[0, 1].set_xlabel('Day of Week')\n",
    "        axes[0, 1].set_ylabel('Number of Measurements')\n",
    "        axes[0, 1].set_xticks(range(len(day_counts)))\n",
    "        axes[0, 1].set_xticklabels([day[:3] for day in day_counts.index], rotation=45)\n",
    "        \n",
    "        # Timeline view\n",
    "        timeline_data = vitals_sample.set_index(datetime_col).resample('6H').size()\n",
    "        axes[1, 0].plot(timeline_data.index, timeline_data.values, marker='o', markersize=3)\n",
    "        axes[1, 0].set_title('Measurement Frequency Over Time\\n(6-hour intervals)')\n",
    "        axes[1, 0].set_xlabel('Date/Time')\n",
    "        axes[1, 0].set_ylabel('Number of Measurements')\n",
    "        axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Heatmap: hour vs day of week\n",
    "        heatmap_data = vitals_sample.groupby(['day_of_week', 'hour']).size().unstack(fill_value=0)\n",
    "        heatmap_data = heatmap_data.reindex(day_order)\n",
    "        \n",
    "        im = axes[1, 1].imshow(heatmap_data.values, cmap='YlOrRd', aspect='auto')\n",
    "        axes[1, 1].set_title('Measurement Heatmap\\n(Day of Week vs Hour)')\n",
    "        axes[1, 1].set_xlabel('Hour of Day')\n",
    "        axes[1, 1].set_ylabel('Day of Week')\n",
    "        axes[1, 1].set_xticks(range(0, 24, 4))\n",
    "        axes[1, 1].set_xticklabels(range(0, 24, 4))\n",
    "        axes[1, 1].set_yticks(range(len(day_order)))\n",
    "        axes[1, 1].set_yticklabels([day[:3] for day in day_order])\n",
    "        \n",
    "        # Add colorbar\n",
    "        plt.colorbar(im, ax=axes[1, 1], label='Number of Measurements')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print insights\n",
    "        print(\"=== TIMEZONE-BASED INSIGHTS ===\")\n",
    "        peak_hour = hourly_counts.idxmax()\n",
    "        quiet_hour = hourly_counts.idxmin()\n",
    "        peak_day = day_counts.idxmax()\n",
    "        quiet_day = day_counts.idxmin()\n",
    "        \n",
    "        print(f\"Peak measurement hour: {peak_hour}:00 ({hourly_counts[peak_hour]:,} measurements)\")\n",
    "        print(f\"Quietest hour: {quiet_hour}:00 ({hourly_counts[quiet_hour]:,} measurements)\")\n",
    "        print(f\"Busiest day: {peak_day} ({day_counts[peak_day]:,} measurements)\")\n",
    "        print(f\"Quietest day: {quiet_day} ({day_counts[quiet_day]:,} measurements)\")\n",
    "        \n",
    "        # Clinical insights\n",
    "        if 6 <= peak_hour <= 10:\n",
    "            print(f\"üìä Clinical insight: Peak at {peak_hour}:00 suggests morning rounds activity\")\n",
    "        elif 18 <= peak_hour <= 22:\n",
    "            print(f\"üìä Clinical insight: Peak at {peak_hour}:00 suggests evening shift activity\")\n",
    "            \n",
    "        if 2 <= quiet_hour <= 5:\n",
    "            print(f\"üò¥ Clinical insight: Quiet at {quiet_hour}:00 is typical for night hours\")\nelse:\n    print(\"No suitable data available for timezone visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timezone Best Practices and Troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate timezone best practices\n",
    "def timezone_best_practices_demo():\n",
    "    print(\"=== TIMEZONE BEST PRACTICES ===\")\n",
    "    print()\n",
    "    \n",
    "    # 1. Always specify timezone when loading data\n",
    "    print(\"1. ‚úÖ ALWAYS SPECIFY TIMEZONE WHEN LOADING DATA\")\n",
    "    print(\"   Good: load_data(..., site_tz='US/Eastern')\")\n",
    "    print(\"   Good: CLIF(..., timezone='US/Eastern')\")\n",
    "    print(\"   Bad:  load_data(...) # No timezone specified\")\n",
    "    print()\n",
    "    \n",
    "    # 2. Check timezone awareness\n",
    "    print(\"2. ‚úÖ CHECK TIMEZONE AWARENESS OF DATETIME COLUMNS\")\n",
    "    sample_naive = pd.Timestamp('2023-06-15 10:30:00')\n",
    "    sample_aware = pd.Timestamp('2023-06-15 10:30:00', tz='US/Eastern')\n",
    "    \n",
    "    print(f\"   Naive datetime: {sample_naive} (tz: {sample_naive.tz})\")\n",
    "    print(f\"   Aware datetime: {sample_aware} (tz: {sample_aware.tz})\")\n",
    "    print(f\"   Check with: hasattr(datetime_value, 'tz') and datetime_value.tz is not None\")\n",
    "    print()\n",
    "    \n",
    "    # 3. Handle timezone conversion errors\n",
    "    print(\"3. ‚úÖ HANDLE TIMEZONE CONVERSION ERRORS GRACEFULLY\")\n",
    "    print(\"   try:\")\n",
    "    print(\"       convert_datetime_columns_to_site_tz(df, 'US/Eastern')\")\n",
    "    print(\"   except Exception as e:\")\n",
    "    print(\"       print(f'Timezone conversion failed: {e}')\")\n",
    "    print()\n",
    "    \n",
    "    # 4. Document timezone assumptions\n",
    "    print(\"4. ‚úÖ DOCUMENT TIMEZONE ASSUMPTIONS\")\n",
    "    print(\"   - Clearly document the source timezone of your data\")\n",
    "    print(\"   - Specify your site/analysis timezone\")\n",
    "    print(\"   - Note any timezone changes during data collection\")\n",
    "    print()\n",
    "    \n",
    "    # 5. Validate timezone conversions\n",
    "    print(\"5. ‚úÖ VALIDATE TIMEZONE CONVERSIONS\")\n",
    "    print(\"   - Compare timestamps before/after conversion\")\n",
    "    print(\"   - Check for reasonable time differences\")\n",
    "    print(\"   - Look for timezone-related outliers\")\n",
    "    print()\n",
    "\ntimezone_best_practices_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common timezone troubleshooting scenarios\n",
    "def timezone_troubleshooting():\n",
    "    print(\"=== COMMON TIMEZONE ISSUES & SOLUTIONS ===\")\n",
    "    print()\n",
    "    \n",
    "    # Issue 1: Mixed timezone data\n",
    "    print(\"‚ùå ISSUE 1: Mixed timezone data\")\n",
    "    print(\"   Problem: Data contains timestamps from different timezones\")\n",
    "    print(\"   Solution: Standardize to UTC first, then convert to site timezone\")\n",
    "    print(\"   Code: df['datetime'] = pd.to_datetime(df['datetime'], utc=True)\")\n",
    "    print()\n",
    "    \n",
    "    # Issue 2: Daylight saving time transitions\n",
    "    print(\"‚ùå ISSUE 2: Daylight saving time transitions\")\n",
    "    print(\"   Problem: Ambiguous times during DST transitions\")\n",
    "    print(\"   Solution: Use pytz timezone handling with ambiguous parameter\")\n",
    "    print(\"   Code: tz.localize(datetime, ambiguous='infer')\")\n",
    "    print()\n",
    "    \n",
    "    # Issue 3: Naive datetime assumptions\n",
    "    print(\"‚ùå ISSUE 3: Naive datetime assumptions\")\n",
    "    print(\"   Problem: Assuming naive datetimes are in local timezone\")\n",
    "    print(\"   Solution: Always explicitly specify timezone when localizing\")\n",
    "    print(\"   Code: df['datetime'].dt.tz_localize('US/Eastern')\")\n",
    "    print()\n",
    "    \n",
    "    # Issue 4: Inconsistent timezone formats\n",
    "    print(\"‚ùå ISSUE 4: Inconsistent timezone formats\")\n",
    "    print(\"   Problem: Mixing 'EST', 'US/Eastern', 'America/New_York'\")\n",
    "    print(\"   Solution: Standardize to IANA timezone names\")\n",
    "    print(\"   Preferred: 'America/New_York' over 'US/Eastern' over 'EST'\")\n",
    "    print()\n",
    "    \n",
    "    # Issue 5: Performance with large datasets\n",
    "    print(\"‚ùå ISSUE 5: Performance issues with large datasets\")\n",
    "    print(\"   Problem: Timezone conversion is slow on large datasets\")\n",
    "    print(\"   Solution: Convert during data loading, not during analysis\")\n",
    "    print(\"   Code: Use site_tz parameter in load_data()\")\n",
    "    print()\n",
    "\ntimezone_troubleshooting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timezone Validation and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a timezone validation function\n",
    "def validate_timezone_conversion(original_df, converted_df, datetime_col, expected_tz_str):\n",
    "    \"\"\"Validate that timezone conversion was successful.\"\"\"\n",
    "    print(f\"=== TIMEZONE CONVERSION VALIDATION ===\")\n",
    "    print(f\"Column: {datetime_col}\")\n",
    "    print(f\"Expected timezone: {expected_tz_str}\")\n",
    "    print()\n",
    "    \n",
    "    validation_results = {\n",
    "        'column_exists': datetime_col in converted_df.columns,\n",
    "        'data_preserved': len(original_df) == len(converted_df),\n",
    "        'timezone_applied': False,\n",
    "        'reasonable_conversion': False\n",
    "    }\n",
    "    \n",
    "    if validation_results['column_exists']:\n",
    "        # Check if timezone was applied\n",
    "        sample_dt = converted_df[datetime_col].dropna().iloc[0] if not converted_df[datetime_col].dropna().empty else None\n",
    "        if sample_dt and hasattr(sample_dt, 'tz') and sample_dt.tz is not None:\n",
    "            validation_results['timezone_applied'] = True\n",
    "            print(f\"‚úÖ Timezone applied: {sample_dt.tz}\")\n",
    "            \n",
    "            # Check if it's the expected timezone\n",
    "            expected_tz = pytz.timezone(expected_tz_str)\n",
    "            if str(sample_dt.tz) == str(expected_tz):\n",
    "                print(f\"‚úÖ Correct timezone: {expected_tz}\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è  Unexpected timezone: got {sample_dt.tz}, expected {expected_tz}\")\n",
    "        else:\n",
    "            print(f\"‚ùå No timezone information found\")\n",
    "    \n",
    "    # Check for reasonable time differences (if we have original data)\n",
    "    if (datetime_col in original_df.columns and \n",
    "        datetime_col in converted_df.columns and \n",
    "        not original_df[datetime_col].dropna().empty and \n",
    "        not converted_df[datetime_col].dropna().empty):\n",
    "        \n",
    "        orig_sample = original_df[datetime_col].dropna().iloc[0]\n",
    "        conv_sample = converted_df[datetime_col].dropna().iloc[0]\n",
    "        \n",
    "        try:\n",
    "            # Convert to naive for comparison\n",
    "            orig_naive = orig_sample.replace(tzinfo=None) if hasattr(orig_sample, 'tz') else orig_sample\n",
    "            conv_naive = conv_sample.replace(tzinfo=None) if hasattr(conv_sample, 'tz') else conv_sample\n",
    "            \n",
    "            time_diff = abs((conv_naive - orig_naive).total_seconds() / 3600)  # Hours\n",
    "            \n",
    "            if time_diff <= 24:  # Reasonable for timezone conversion\n",
    "                validation_results['reasonable_conversion'] = True\n",
    "                print(f\"‚úÖ Reasonable time difference: {time_diff:.1f} hours\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è  Large time difference: {time_diff:.1f} hours\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Could not compare times: {e}\")\n",
    "    \n",
    "    print(f\"\\nData preservation: {validation_results['data_preserved']}\")\n",
    "    \n",
    "    # Overall validation result\n",
    "    all_good = all(validation_results.values())\n",
    "    print(f\"\\n{'‚úÖ VALIDATION PASSED' if all_good else '‚ö†Ô∏è  VALIDATION ISSUES FOUND'}\")\n",
    "    \n",
    "    return validation_results\n",
    "\n",
    "# Test the validation function\n",
    "if 'eastern_converted' in locals():\n",
    "    validation_result = validate_timezone_conversion(\n",
    "        test_datetime_data, \n",
    "        eastern_converted, \n",
    "        'event_dttm', \n",
    "        'US/Eastern'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Recommendations\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **Always Specify Timezone**: Use the `site_tz` parameter when loading data or the `timezone` parameter in CLIF class initialization\n",
    "\n",
    "2. **Validate Conversions**: Always check that timezone conversions worked as expected\n",
    "\n",
    "3. **Use Standard Formats**: Prefer IANA timezone names like 'America/New_York' over abbreviations like 'EST'\n",
    "\n",
    "4. **Document Assumptions**: Clearly document the source and target timezones for your data\n",
    "\n",
    "5. **Handle Edge Cases**: Be prepared for daylight saving time transitions and ambiguous times\n",
    "\n",
    "### Your Site Configuration:\n",
    "- **Site Timezone**: US/Eastern\n",
    "- **Data Format**: Parquet\n",
    "- **Recommended Usage**: `CLIF(data_dir, filetype='parquet', timezone='US/Eastern')`\n",
    "\n",
    "### Clinical Implications:\n",
    "- Proper timezone handling ensures accurate temporal analysis\n",
    "- Critical for multi-site studies or collaborations\n",
    "- Essential for regulatory compliance and audit trails\n",
    "- Enables meaningful time-based clinical insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary of timezone capabilities\n",
    "print(\"=== PYCLIF TIMEZONE CAPABILITIES SUMMARY ===\")\n",
    "print()\n",
    "print(\"üîß AVAILABLE FUNCTIONS:\")\n",
    "print(\"  ‚Ä¢ CLIF(timezone='US/Eastern') - Set timezone for entire CLIF object\")\n",
    "print(\"  ‚Ä¢ load_data(site_tz='US/Eastern') - Convert during data loading\")\n",
    "print(\"  ‚Ä¢ convert_datetime_columns_to_site_tz() - Manual conversion utility\")\n",
    "print()\n",
    "print(\"üìä SUPPORTED FORMATS:\")\n",
    "print(\"  ‚Ä¢ IANA timezone names (America/New_York, America/Chicago, etc.)\")\n",
    "print(\"  ‚Ä¢ US timezone shortcuts (US/Eastern, US/Central, etc.)\")\n",
    "print(\"  ‚Ä¢ UTC and GMT for universal time\")\n",
    "print()\n",
    "print(\"‚úÖ FEATURES:\")\n",
    "print(\"  ‚Ä¢ Automatic detection of datetime columns (contains 'dttm')\")\n",
    "print(\"  ‚Ä¢ Preservation of original data integrity\")\n",
    "print(\"  ‚Ä¢ Verbose output for debugging\")\n",
    "print(\"  ‚Ä¢ Error handling for invalid timezones\")\n",
    "print(\"  ‚Ä¢ Support for daylight saving time transitions\")\n",
    "print()\n",
    "print(\"üéØ YOUR SETUP:\")\n",
    "print(f\"  ‚Ä¢ Data directory: {DATA_DIR}\")\n",
    "print(f\"  ‚Ä¢ File format: parquet\")\n",
    "print(f\"  ‚Ä¢ Site timezone: US/Eastern\")\n",
    "print(f\"  ‚Ä¢ Recommended: CLIF('{DATA_DIR}', filetype='parquet', timezone='US/Eastern')\")\n",
    "print()\n",
    "print(\"üìö Next Steps: Explore other example notebooks for advanced analysis techniques!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "This notebook covered:\n",
    "- Comprehensive timezone format support\n",
    "- Multiple methods for timezone conversion\n",
    "- Validation and troubleshooting techniques\n",
    "- Best practices for healthcare data\n",
    "- Visual analysis of timezone effects\n",
    "- Real-world examples and edge cases\n",
    "\n",
    "### Explore Other Notebooks:\n",
    "- `01_basic_usage.ipynb` - Basic pyCLIF usage\n",
    "- `02_individual_tables.ipynb` - Individual table classes\n",
    "- `03_data_validation.ipynb` - Data validation techniques\n",
    "- `04_vitals_analysis.ipynb` - Advanced vitals analysis\n",
    "- `06_data_filtering.ipynb` - Advanced filtering techniques"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
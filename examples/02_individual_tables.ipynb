{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Individual Table Classes\n",
    "\n",
    "This notebook demonstrates how to work with individual CLIF table classes, providing more flexibility and control over data loading and processing.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Instead of using the main CLIF class, you can work directly with individual table classes:\n",
    "- More granular control over data loading\n",
    "- Independent validation and processing\n",
    "- Flexibility to load specific columns or apply filters\n",
    "- Better for memory management with large datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Import individual table classes\n",
    "from pyclif.tables.patient import patient\n",
    "from pyclif.tables.vitals import vitals\n",
    "from pyclif.tables.hospitalization import hospitalization\n",
    "from pyclif.tables.labs import labs\n",
    "from pyclif.tables.adt import adt\n",
    "from pyclif.tables.respiratory_support import respiratory_support\n",
    "\n",
    "print(f\"Individual table classes imported successfully!\")\n",
    "print(f\"Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Loading from Files\n",
    "\n",
    "Each table class has a `from_file()` class method for loading data directly from files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your data directory path\n",
    "DATA_DIR = \"/Users/vaishvik/downloads/CLIF_MIMIC\"\n",
    "\n",
    "print(f\"Loading data from: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Patient Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load patient table using from_file class method\n",
    "patient_table = patient.from_file(\n",
    "    table_path=DATA_DIR,\n",
    "    table_format_type=\"parquet\"\n",
    ")\n",
    "\n",
    "print(f\"Patient table loaded successfully!\")\n",
    "print(f\"Shape: {patient_table.df.shape}\")\n",
    "print(f\"Columns: {list(patient_table.df.columns)}\")\n",
    "print(f\"Is valid: {patient_table.isvalid()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample patient data\n",
    "print(\"Sample patient data:\")\n",
    "patient_table.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Vitals Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vitals table\n",
    "vitals_table = vitals.from_file(\n",
    "    table_path=DATA_DIR,\n",
    "    table_format_type=\"parquet\"\n",
    ")\n",
    "\n",
    "print(f\"Vitals table loaded successfully!\")\n",
    "print(f\"Shape: {vitals_table.df.shape}\")\n",
    "print(f\"Is valid: {vitals_table.isvalid()}\")\n",
    "\n",
    "# Show unique vital categories\n",
    "vital_categories = vitals_table.get_vital_categories()\n",
    "print(f\"Vital categories: {vital_categories}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Hospitalization Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load hospitalization table\n",
    "hosp_table = hospitalization.from_file(\n",
    "    table_path=DATA_DIR,\n",
    "    table_format_type=\"parquet\"\n",
    ")\n",
    "\n",
    "print(f\"Hospitalization table loaded successfully!\")\n",
    "print(f\"Shape: {hosp_table.df.shape}\")\n",
    "print(f\"Is valid: {hosp_table.isvalid()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Loading with Custom Data\n",
    "\n",
    "You can also initialize table classes with existing DataFrames for more control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data manually with custom parameters using the load_data function\n",
    "from pyclif.utils.io import load_data\n",
    "\n",
    "# Load vitals data with specific filters and timezone conversion\n",
    "vitals_df = load_data(\n",
    "    table_name=\"vitals\",\n",
    "    table_path=DATA_DIR,\n",
    "    table_format_type=\"parquet\",\n",
    "    sample_size=1000,  # Load only first 1000 rows for demo\n",
    "    site_tz=\"US/Eastern\"  # Apply timezone conversion\n",
    ")\n",
    "\n",
    "print(f\"Custom vitals data loaded: {vitals_df.shape}\")\n",
    "print(f\"Columns: {list(vitals_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vitals table object from the custom DataFrame\n",
    "custom_vitals = vitals(data=vitals_df)\n",
    "\n",
    "print(f\"Custom vitals table created!\")\n",
    "print(f\"Is valid: {custom_vitals.isvalid()}\")\n",
    "print(f\"Validation errors: {len(custom_vitals.errors)}\")\n",
    "print(f\"Range validation errors: {len(custom_vitals.range_validation_errors)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table-Specific Features\n",
    "\n",
    "Each table class has specialized methods and properties for working with that type of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vitals Table Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get vital units mapping\n",
    "vital_units = vitals_table.vital_units\n",
    "print(\"Vital units mapping:\")\n",
    "for vital, unit in list(vital_units.items())[:5]:  # Show first 5\n",
    "    print(f\"  {vital}: {unit}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get vital ranges for validation\n",
    "vital_ranges = vitals_table.vital_ranges\n",
    "print(\"\\nVital ranges for validation:\")\n",
    "for vital, ranges in list(vital_ranges.items())[:3]:  # Show first 3\n",
    "    print(f\"  {vital}: {ranges}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter vitals by category\n",
    "heart_rate_data = vitals_table.filter_by_vital_category('heart_rate')\n",
    "print(f\"Heart rate measurements: {len(heart_rate_data)}\")\n",
    "\n",
    "if not heart_rate_data.empty:\n",
    "    print(\"\\nHeart rate statistics:\")\n",
    "    print(heart_rate_data['vital_value'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by date range\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Get recent data (last 30 days from the latest timestamp)\n",
    "if 'recorded_dttm' in vitals_table.df.columns:\n",
    "    latest_date = pd.to_datetime(vitals_table.df['recorded_dttm']).max()\n",
    "    start_date = latest_date - timedelta(days=30)\n",
    "    \n",
    "    recent_vitals = vitals_table.filter_by_date_range(start_date, latest_date)\n",
    "    print(f\"Recent vitals (last 30 days): {len(recent_vitals)} records\")\n",
    "    print(f\"Date range: {start_date.date()} to {latest_date.date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get comprehensive summary statistics\n",
    "summary = vitals_table.get_summary_stats()\n",
    "print(\"=== VITALS SUMMARY STATISTICS ===\")\n",
    "print(f\"Total records: {summary.get('total_records', 'N/A')}\")\n",
    "print(f\"Unique hospitalizations: {summary.get('unique_hospitalizations', 'N/A')}\")\n",
    "\n",
    "print(\"\\nVital category counts:\")\n",
    "for category, count in list(summary.get('vital_category_counts', {}).items())[:5]:\n",
    "    print(f\"  {category}: {count}\")\n",
    "\n",
    "date_range = summary.get('date_range', {})\n",
    "print(f\"\\nDate range: {date_range.get('earliest')} to {date_range.get('latest')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Range Validation Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get detailed range validation report\n",
    "range_report = vitals_table.get_range_validation_report()\n",
    "print(\"Range validation report:\")\n",
    "print(range_report)\n",
    "\n",
    "if not range_report.empty:\n",
    "    print(\"\\nRange validation issues found:\")\n",
    "    for _, row in range_report.head(3).iterrows():\n",
    "        print(f\"  - {row['message']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Usage: Custom Filtering and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data with custom filters using load_data\n",
    "from pyclif.utils.io import load_data\n",
    "\n",
    "# Example: Load only specific vital categories\n",
    "filtered_vitals_df = load_data(\n",
    "    table_name=\"vitals\",\n",
    "    table_path=DATA_DIR,\n",
    "    table_format_type=\"parquet\",\n",
    "    columns=['patient_id', 'hospitalization_id', 'vital_category', 'vital_value', 'recorded_dttm'],\n",
    "    filters={'vital_category': ['heart_rate', 'sbp', 'dbp']},  # Only BP and HR\n",
    "    sample_size=500,\n",
    "    site_tz=\"US/Eastern\"\n",
    ")\n",
    "\n",
    "print(f\"Filtered vitals data: {filtered_vitals_df.shape}\")\n",
    "print(f\"Unique vital categories: {filtered_vitals_df['vital_category'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table object from filtered data\n",
    "filtered_vitals_table = vitals(data=filtered_vitals_df)\n",
    "\n",
    "print(f\"Filtered vitals table created!\")\n",
    "print(f\"Is valid: {filtered_vitals_table.isvalid()}\")\n",
    "\n",
    "# Get statistics for filtered data\n",
    "filtered_summary = filtered_vitals_table.get_summary_stats()\n",
    "print(f\"\\nFiltered data summary:\")\n",
    "print(f\"Total records: {filtered_summary.get('total_records')}\")\n",
    "print(f\"Vital categories: {list(filtered_summary.get('vital_category_counts', {}).keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Multiple Individual Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load multiple tables independently for comparison\n",
    "tables_info = {}\n",
    "\n",
    "# Load different tables\n",
    "table_classes = {\n",
    "    'patient': patient,\n",
    "    'vitals': vitals,\n",
    "    'hospitalization': hospitalization\n",
    "}\n",
    "\n",
    "for table_name, table_class in table_classes.items():\n",
    "    try:\n",
    "        table_obj = table_class.from_file(DATA_DIR, \"parquet\")\n",
    "        tables_info[table_name] = {\n",
    "            'shape': table_obj.df.shape,\n",
    "            'is_valid': table_obj.isvalid(),\n",
    "            'columns': len(table_obj.df.columns),\n",
    "            'memory_usage': f\"{table_obj.df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        tables_info[table_name] = {'error': str(e)}\n",
    "\n",
    "# Display summary\n",
    "print(\"=== TABLE COMPARISON ===\")\n",
    "for table_name, info in tables_info.items():\n",
    "    print(f\"\\n{table_name.upper()}:\")\n",
    "    if 'error' in info:\n",
    "        print(f\"  Error: {info['error']}\")\n",
    "    else:\n",
    "        print(f\"  Shape: {info['shape']}\")\n",
    "        print(f\"  Valid: {info['is_valid']}\")\n",
    "        print(f\"  Columns: {info['columns']}\")\n",
    "        print(f\"  Memory: {info['memory_usage']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benefits of Individual Table Approach\n",
    "\n",
    "### Advantages:\n",
    "1. **Memory Efficiency**: Load only the tables you need\n",
    "2. **Custom Processing**: Apply specific filters, column selection, and transformations\n",
    "3. **Independent Validation**: Each table validates independently\n",
    "4. **Flexible Loading**: Different parameters for different tables\n",
    "5. **Specialized Methods**: Each table class has domain-specific functionality\n",
    "\n",
    "### When to Use:\n",
    "- Working with large datasets where memory is a concern\n",
    "- Need custom filtering or column selection\n",
    "- Performing analysis on specific table types\n",
    "- Building specialized data processing pipelines\n",
    "- Need fine-grained control over validation and error handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "This notebook demonstrated:\n",
    "- Loading individual table classes\n",
    "- Using `from_file()` class methods\n",
    "- Creating tables from custom DataFrames\n",
    "- Table-specific features and methods\n",
    "- Custom filtering and processing\n",
    "- Memory and performance considerations\n",
    "\n",
    "### Explore Other Notebooks:\n",
    "- `01_basic_usage.ipynb` - Main CLIF class approach\n",
    "- `03_data_validation.ipynb` - Advanced validation techniques\n",
    "- `04_vitals_analysis.ipynb` - Deep dive into vitals analysis\n",
    "- `05_timezone_handling.ipynb` - Timezone conversion details\n",
    "- `06_data_filtering.ipynb` - Advanced filtering techniques"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
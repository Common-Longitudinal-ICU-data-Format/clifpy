{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hourly Wide Dataset Creation with pyCLIF\n",
    "\n",
    "This notebook demonstrates how to create hourly aggregated wide datasets using the pyCLIF library. The hourly aggregation functionality allows you to collapse time-series data into hourly buckets with user-defined aggregation methods.\n",
    "\n",
    "**Author:** pyCLIF Team  \n",
    "**Date:** 2024\n",
    "\n",
    "## Overview\n",
    "\n",
    "The hourly wide dataset functionality allows you to:\n",
    "- **Convert wide datasets** to hourly aggregation\n",
    "- **Apply different aggregation methods** (max, min, mean, median, first, last, boolean, one-hot encode)\n",
    "- **Track time progression** with `nth_hour` column (incremental hours from admission)\n",
    "- **Maintain patient context** with demographics and hospitalization details\n",
    "- **Create analysis-ready datasets** for time-series modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyclif import CLIF\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=== pyCLIF Hourly Wide Dataset Example ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Data Directory\n",
    "\n",
    "Update the `data_dir` variable to point to your CLIF data location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CLIF with MIMIC data\n",
    "data_dir = \"/Users/vaishvik/Downloads/CLIF_MIMIC\"\n",
    "\n",
    "# Check if data directory exists\n",
    "if not os.path.exists(data_dir):\n",
    "    print(f\"‚ö†Ô∏è  Warning: Data directory {data_dir} does not exist.\")\n",
    "    print(\"Please update the data_dir variable to point to your CLIF data location.\")\n",
    "else:\n",
    "    print(f\"‚úÖ Data directory found: {data_dir}\")\n",
    "    \n",
    "# Initialize CLIF\n",
    "print(f\"\\nInitializing CLIF with data from: {data_dir}\")\n",
    "clif = CLIF(\n",
    "    data_dir=data_dir,\n",
    "    filetype='parquet',\n",
    "    timezone=\"US/Eastern\"\n",
    ")\n",
    "print(\"üöÄ CLIF object initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create a Wide Dataset\n",
    "\n",
    "First, we need to create a wide dataset that we'll then convert to hourly aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Creating Wide Dataset ===\")\n",
    "\n",
    "# Create a wide dataset with vitals, labs, and medications\n",
    "wide_df = clif.create_wide_dataset(\n",
    "    optional_tables=['vitals', 'labs', 'medication_admin_continuous', 'patient_assessments'],\n",
    "    category_filters={\n",
    "        'vitals': ['map', 'heart_rate', 'spo2', 'respiratory_rate', 'temp_c', 'sbp', 'dbp'],\n",
    "        'labs': ['hemoglobin', 'wbc', 'sodium', 'potassium', 'creatinine', 'glucose'],\n",
    "        'medication_admin_continuous': ['norepinephrine', 'propofol', 'fentanyl', 'epinephrine'],\n",
    "        'patient_assessments': ['gcs_total', 'rass', 'sbt_delivery_pass_fail']\n",
    "    },\n",
    "    sample=True,  # Sample 20 hospitalizations for demo\n",
    "    save_to_data_location=False\n",
    ")\n",
    "\n",
    "if wide_df is not None:\n",
    "    print(f\"\\n‚úÖ Wide dataset created successfully!\")\n",
    "    print(f\"   - Records: {len(wide_df):,}\")\n",
    "    print(f\"   - Columns: {len(wide_df.columns)}\")\n",
    "    print(f\"   - Hospitalizations: {wide_df['hospitalization_id'].nunique()}\")\n",
    "    print(f\"   - Date range: {wide_df['event_time'].min()} to {wide_df['event_time'].max()}\")\n",
    "    \n",
    "    # Check that the dataset was stored in clif.wide_df\n",
    "    print(f\"\\nüìã Wide dataset stored in clif.wide_df: {clif.wide_df is not None}\")\n",
    "else:\n",
    "    print(\"‚ùå Failed to create wide dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Wide Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clif.wide_df is not None:\n",
    "    print(\"üìä Wide Dataset Structure:\")\n",
    "    print(f\"\\nKey columns:\")\n",
    "    key_cols = ['patient_id', 'hospitalization_id', 'event_time', 'day_number', 'hosp_id_day_key']\n",
    "    display(clif.wide_df[key_cols].head())\n",
    "    \n",
    "    print(\"\\nüìà Sample clinical data:\")\n",
    "    clinical_cols = ['event_time', 'map', 'heart_rate', 'spo2', 'hemoglobin', 'norepinephrine']\n",
    "    available_clinical = [col for col in clinical_cols if col in clif.wide_df.columns]\n",
    "    display(clif.wide_df[available_clinical].head(10))\n",
    "    \n",
    "    # Show events per hour distribution\n",
    "    clif.wide_df['hour'] = clif.wide_df['event_time'].dt.hour\n",
    "    events_per_hour = clif.wide_df.groupby(['hospitalization_id', 'day_number', 'hour']).size()\n",
    "    print(f\"\\n‚è∞ Events per hour statistics:\")\n",
    "    print(f\"   - Mean: {events_per_hour.mean():.1f}\")\n",
    "    print(f\"   - Max: {events_per_hour.max()}\")\n",
    "    print(f\"   - Min: {events_per_hour.min()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define Aggregation Configuration\n",
    "\n",
    "Specify how each column should be aggregated when converting to hourly buckets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define aggregation configuration\n",
    "aggregation_config = {\n",
    "    'max': ['map', 'temp_c', 'sbp', 'dbp'],\n",
    "    'mean': ['heart_rate', 'respiratory_rate', 'spo2'],\n",
    "    'min': ['spo2'],  # We want both mean and min for SpO2\n",
    "    'median': ['glucose'],\n",
    "    'first': ['gcs_total', 'rass'],\n",
    "    'last': ['sbt_delivery_pass_fail'],\n",
    "    'boolean': ['norepinephrine', 'propofol', 'fentanyl', 'epinephrine'],\n",
    "    # Note: one_hot_encode would be used for categorical columns if we had them\n",
    "}\n",
    "\n",
    "print(\"üìã Aggregation Configuration:\")\n",
    "for method, columns in aggregation_config.items():\n",
    "    print(f\"\\n{method.upper()}:\")\n",
    "    for col in columns:\n",
    "        print(f\"   - {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create Hourly Wide Dataset\n",
    "\n",
    "Convert the wide dataset to hourly aggregation using the defined configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Creating Hourly Wide Dataset ===\")\n",
    "\n",
    "# Create hourly aggregated dataset\n",
    "hourly_df = clif.create_hourly_wide_dataset(aggregation_config)\n",
    "\n",
    "if hourly_df is not None:\n",
    "    print(f\"\\n‚úÖ Hourly dataset created successfully!\")\n",
    "    print(f\"   - Records: {len(hourly_df):,} (from {len(clif.wide_df):,} original)\")\n",
    "    print(f\"   - Reduction: {(1 - len(hourly_df)/len(clif.wide_df))*100:.1f}%\")\n",
    "    print(f\"   - Columns: {len(hourly_df.columns)}\")\n",
    "    print(f\"   - Hospitalizations: {hourly_df['hospitalization_id'].nunique()}\")\n",
    "    \n",
    "    # Check nth_hour range\n",
    "    print(f\"\\n‚è∞ Time coverage:\")\n",
    "    print(f\"   - Max nth_hour: {hourly_df['nth_hour'].max()} (‚âà {hourly_df['nth_hour'].max()/24:.1f} days)\")\n",
    "    print(f\"   - Min nth_hour: {hourly_df['nth_hour'].min()}\")\n",
    "    \n",
    "    # Check that the dataset was stored\n",
    "    print(f\"\\nüìã Hourly dataset stored in clif.hourly_wide_df: {clif.hourly_wide_df is not None}\")\n",
    "else:\n",
    "    print(\"‚ùå Failed to create hourly dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Hourly Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clif.hourly_wide_df is not None:\n",
    "    print(\"üìä Hourly Dataset Structure:\")\n",
    "    \n",
    "    # Show key columns\n",
    "    print(\"\\nüîë Key columns (first 10 hours):\")\n",
    "    key_cols = ['hospitalization_id', 'day_number', 'hour_bucket', 'nth_hour']\n",
    "    display(clif.hourly_wide_df[key_cols].head(10))\n",
    "    \n",
    "    # Show aggregated clinical data for one hospitalization\n",
    "    first_hosp = clif.hourly_wide_df['hospitalization_id'].iloc[0]\n",
    "    hosp_data = clif.hourly_wide_df[clif.hourly_wide_df['hospitalization_id'] == first_hosp]\n",
    "    \n",
    "    print(f\"\\nüìà Clinical data for hospitalization {first_hosp}:\")\n",
    "    clinical_cols = ['nth_hour', 'map', 'heart_rate', 'spo2', 'norepinephrine']\n",
    "    available_cols = [col for col in clinical_cols if col in hosp_data.columns]\n",
    "    display(hosp_data[available_cols].head(24))  # First 24 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Analyze Aggregation Results\n",
    "\n",
    "Let's examine how different aggregation methods affected the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clif.hourly_wide_df is not None:\n",
    "    print(\"üìä Aggregation Analysis:\")\n",
    "    \n",
    "    # 1. Boolean columns (medications)\n",
    "    print(\"\\nüíä Boolean Aggregation (Medication Presence):\")\n",
    "    med_cols = ['norepinephrine', 'propofol', 'fentanyl', 'epinephrine']\n",
    "    available_meds = [col for col in med_cols if col in clif.hourly_wide_df.columns]\n",
    "    \n",
    "    for med in available_meds:\n",
    "        hours_with_med = clif.hourly_wide_df[med].sum()\n",
    "        percent = (hours_with_med / len(clif.hourly_wide_df)) * 100\n",
    "        print(f\"   - {med}: {hours_with_med} hours ({percent:.1f}%)\")\n",
    "    \n",
    "    # 2. Vital signs aggregation\n",
    "    print(\"\\nüìä Vital Signs Aggregation Statistics:\")\n",
    "    vital_stats = clif.hourly_wide_df[['map', 'heart_rate', 'spo2']].describe()\n",
    "    display(vital_stats.round(1))\n",
    "    \n",
    "    # 3. Data completeness by hour\n",
    "    print(\"\\nüìà Data Completeness Analysis:\")\n",
    "    completeness = {}\n",
    "    for col in ['map', 'heart_rate', 'spo2', 'hemoglobin', 'gcs_total']:\n",
    "        if col in clif.hourly_wide_df.columns:\n",
    "            non_null = clif.hourly_wide_df[col].notna().sum()\n",
    "            completeness[col] = (non_null / len(clif.hourly_wide_df)) * 100\n",
    "    \n",
    "    completeness_df = pd.DataFrame(list(completeness.items()), \n",
    "                                  columns=['Variable', 'Completeness %'])\n",
    "    completeness_df = completeness_df.sort_values('Completeness %', ascending=False)\n",
    "    display(completeness_df.round(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Visualize Hourly Trends\n",
    "\n",
    "Let's create visualizations to understand the hourly patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "if clif.hourly_wide_df is not None:\n",
    "    # Set up the plot style\n",
    "    plt.style.use('default')\n",
    "    sns.set_palette(\"husl\")\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('Hourly Wide Dataset Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Plot 1: Vital signs over first 48 hours for one patient\n",
    "    first_hosp = clif.hourly_wide_df['hospitalization_id'].iloc[0]\n",
    "    hosp_data = clif.hourly_wide_df[\n",
    "        (clif.hourly_wide_df['hospitalization_id'] == first_hosp) & \n",
    "        (clif.hourly_wide_df['nth_hour'] <= 48)\n",
    "    ]\n",
    "    \n",
    "    if 'map' in hosp_data.columns and hosp_data['map'].notna().sum() > 0:\n",
    "        axes[0, 0].plot(hosp_data['nth_hour'], hosp_data['map'], 'o-', label='MAP', markersize=4)\n",
    "    if 'heart_rate' in hosp_data.columns and hosp_data['heart_rate'].notna().sum() > 0:\n",
    "        axes[0, 0].plot(hosp_data['nth_hour'], hosp_data['heart_rate'], 's-', label='Heart Rate', markersize=4)\n",
    "    \n",
    "    axes[0, 0].set_title(f'Vital Signs Over Time (First 48h)\\nHospitalization: {first_hosp}')\n",
    "    axes[0, 0].set_xlabel('Hour from Admission')\n",
    "    axes[0, 0].set_ylabel('Value')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Medication usage pattern\n",
    "    med_cols = ['norepinephrine', 'propofol', 'fentanyl', 'epinephrine']\n",
    "    available_meds = [col for col in med_cols if col in clif.hourly_wide_df.columns]\n",
    "    \n",
    "    if available_meds:\n",
    "        med_usage = clif.hourly_wide_df[available_meds].sum()\n",
    "        axes[0, 1].bar(range(len(med_usage)), med_usage.values)\n",
    "        axes[0, 1].set_xticks(range(len(med_usage)))\n",
    "        axes[0, 1].set_xticklabels(med_usage.index, rotation=45)\n",
    "        axes[0, 1].set_title('Medication Usage (Total Hours)')\n",
    "        axes[0, 1].set_ylabel('Hours of Administration')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Data density by hour of day\n",
    "    hour_distribution = clif.hourly_wide_df.groupby('hour_bucket').size()\n",
    "    axes[1, 0].bar(hour_distribution.index, hour_distribution.values, alpha=0.7)\n",
    "    axes[1, 0].set_title('Data Distribution by Hour of Day')\n",
    "    axes[1, 0].set_xlabel('Hour of Day')\n",
    "    axes[1, 0].set_ylabel('Number of Records')\n",
    "    axes[1, 0].set_xticks(range(0, 24, 4))\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Length of stay distribution (in hours)\n",
    "    max_hours = clif.hourly_wide_df.groupby('hospitalization_id')['nth_hour'].max()\n",
    "    axes[1, 1].hist(max_hours, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axes[1, 1].set_title('Length of Stay Distribution')\n",
    "    axes[1, 1].set_xlabel('Hours')\n",
    "    axes[1, 1].set_ylabel('Number of Hospitalizations')\n",
    "    axes[1, 1].axvline(max_hours.mean(), color='red', linestyle='--', \n",
    "                       label=f'Mean: {max_hours.mean():.1f}h')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Example Use Cases\n",
    "\n",
    "Let's demonstrate some practical use cases for the hourly aggregated data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Case 1: Identify Patients on Vasopressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clif.hourly_wide_df is not None:\n",
    "    print(\"üíä Vasopressor Analysis:\")\n",
    "    \n",
    "    vasopressors = ['norepinephrine', 'epinephrine']\n",
    "    available_vaso = [v for v in vasopressors if v in clif.hourly_wide_df.columns]\n",
    "    \n",
    "    if available_vaso:\n",
    "        # Create a column for any vasopressor use\n",
    "        clif.hourly_wide_df['any_vasopressor'] = clif.hourly_wide_df[available_vaso].max(axis=1)\n",
    "        \n",
    "        # Find patients who received vasopressors\n",
    "        vaso_patients = clif.hourly_wide_df[clif.hourly_wide_df['any_vasopressor'] == 1]\n",
    "        unique_vaso_patients = vaso_patients['hospitalization_id'].nunique()\n",
    "        \n",
    "        print(f\"\\nüìä Vasopressor Statistics:\")\n",
    "        print(f\"   - Patients on vasopressors: {unique_vaso_patients}\")\n",
    "        print(f\"   - Total vasopressor hours: {vaso_patients.shape[0]}\")\n",
    "        print(f\"   - Average duration per patient: {vaso_patients.shape[0]/unique_vaso_patients:.1f} hours\")\n",
    "        \n",
    "        # Show when vasopressors are typically started\n",
    "        first_vaso_hour = vaso_patients.groupby('hospitalization_id')['nth_hour'].min()\n",
    "        print(f\"\\n‚è∞ Time to first vasopressor:\")\n",
    "        print(f\"   - Mean: {first_vaso_hour.mean():.1f} hours\")\n",
    "        print(f\"   - Median: {first_vaso_hour.median():.1f} hours\")\n",
    "        print(f\"   - Min: {first_vaso_hour.min()} hours\")\n",
    "        print(f\"   - Max: {first_vaso_hour.max()} hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Case 2: Track Vital Sign Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clif.hourly_wide_df is not None:\n",
    "    print(\"üìä Vital Sign Stability Analysis:\")\n",
    "    \n",
    "    # Calculate hourly changes in vital signs\n",
    "    for vital in ['map', 'heart_rate', 'spo2']:\n",
    "        if vital in clif.hourly_wide_df.columns:\n",
    "            # Calculate hour-to-hour change for each patient\n",
    "            clif.hourly_wide_df[f'{vital}_change'] = (\n",
    "                clif.hourly_wide_df.groupby('hospitalization_id')[vital]\n",
    "                .diff()\n",
    "                .abs()\n",
    "            )\n",
    "    \n",
    "    # Identify periods of instability (large changes)\n",
    "    if 'map_change' in clif.hourly_wide_df.columns:\n",
    "        map_instability_threshold = 10  # mmHg\n",
    "        unstable_hours = clif.hourly_wide_df[\n",
    "            clif.hourly_wide_df['map_change'] > map_instability_threshold\n",
    "        ]\n",
    "        \n",
    "        print(f\"\\nüö® MAP Instability Analysis (change > {map_instability_threshold} mmHg):\")\n",
    "        print(f\"   - Unstable hours: {len(unstable_hours)}\")\n",
    "        print(f\"   - Affected patients: {unstable_hours['hospitalization_id'].nunique()}\")\n",
    "        print(f\"   - % of total hours: {(len(unstable_hours)/len(clif.hourly_wide_df))*100:.1f}%\")\n",
    "        \n",
    "        # Show when instability typically occurs\n",
    "        if len(unstable_hours) > 0:\n",
    "            instability_timing = unstable_hours.groupby('hour_bucket').size()\n",
    "            print(f\"\\n‚è∞ Instability by hour of day:\")\n",
    "            top_hours = instability_timing.nlargest(5)\n",
    "            for hour, count in top_hours.items():\n",
    "                print(f\"   - Hour {hour}: {count} occurrences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Case 3: Create Features for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clif.hourly_wide_df is not None:\n",
    "    print(\"ü§ñ Machine Learning Feature Engineering:\")\n",
    "    \n",
    "    # Create rolling window features\n",
    "    window_size = 6  # 6-hour window\n",
    "    \n",
    "    for vital in ['map', 'heart_rate', 'spo2']:\n",
    "        if vital in clif.hourly_wide_df.columns:\n",
    "            # Rolling mean\n",
    "            clif.hourly_wide_df[f'{vital}_rolling_mean_{window_size}h'] = (\n",
    "                clif.hourly_wide_df.groupby('hospitalization_id')[vital]\n",
    "                .transform(lambda x: x.rolling(window_size, min_periods=1).mean())\n",
    "            )\n",
    "            \n",
    "            # Rolling std (variability)\n",
    "            clif.hourly_wide_df[f'{vital}_rolling_std_{window_size}h'] = (\n",
    "                clif.hourly_wide_df.groupby('hospitalization_id')[vital]\n",
    "                .transform(lambda x: x.rolling(window_size, min_periods=2).std())\n",
    "            )\n",
    "    \n",
    "    # Create time-based features\n",
    "    clif.hourly_wide_df['hours_since_admission'] = clif.hourly_wide_df['nth_hour']\n",
    "    clif.hourly_wide_df['is_night'] = clif.hourly_wide_df['hour_bucket'].isin(range(22, 24)) | clif.hourly_wide_df['hour_bucket'].isin(range(0, 6))\n",
    "    clif.hourly_wide_df['is_weekend'] = pd.to_datetime(clif.hourly_wide_df['admission_dttm']).dt.dayofweek.isin([5, 6]) if 'admission_dttm' in clif.hourly_wide_df.columns else False\n",
    "    \n",
    "    print(\"\\n‚úÖ Created ML features:\")\n",
    "    ml_features = [col for col in clif.hourly_wide_df.columns if 'rolling' in col or col in ['hours_since_admission', 'is_night', 'is_weekend']]\n",
    "    for feature in ml_features:\n",
    "        print(f\"   - {feature}\")\n",
    "    \n",
    "    # Show sample of ML-ready dataset\n",
    "    print(\"\\nüìã Sample ML-ready dataset:\")\n",
    "    ml_cols = ['hospitalization_id', 'nth_hour', 'map', 'map_rolling_mean_6h', 'map_rolling_std_6h', 'is_night', 'any_vasopressor']\n",
    "    available_ml_cols = [col for col in ml_cols if col in clif.hourly_wide_df.columns]\n",
    "    display(clif.hourly_wide_df[available_ml_cols].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Save the Hourly Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clif.hourly_wide_df is not None:\n",
    "    # Save to parquet format\n",
    "    output_path = os.path.join(clif.data_dir, 'hourly_wide_dataset_example.parquet')\n",
    "    clif.hourly_wide_df.to_parquet(output_path, index=False)\n",
    "    \n",
    "    print(f\"üíæ Hourly dataset saved to: {output_path}\")\n",
    "    \n",
    "    # Also save as CSV for easy viewing\n",
    "    csv_path = os.path.join(clif.data_dir, 'hourly_wide_dataset_example.csv')\n",
    "    clif.hourly_wide_df.to_csv(csv_path, index=False)\n",
    "    print(f\"üìÑ CSV version saved to: {csv_path}\")\n",
    "    \n",
    "    # Check file sizes\n",
    "    parquet_size = os.path.getsize(output_path) / (1024 * 1024)  # MB\n",
    "    csv_size = os.path.getsize(csv_path) / (1024 * 1024)  # MB\n",
    "    \n",
    "    print(f\"\\nüìä File sizes:\")\n",
    "    print(f\"   - Parquet: {parquet_size:.2f} MB\")\n",
    "    print(f\"   - CSV: {csv_size:.2f} MB\")\n",
    "    print(f\"   - Compression ratio: {csv_size/parquet_size:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we demonstrated:\n",
    "\n",
    "### üîß **Core Functionality**\n",
    "- Creating a wide dataset from CLIF tables\n",
    "- Converting to hourly aggregation with various methods\n",
    "- Using the `nth_hour` column for chronological tracking\n",
    "\n",
    "### üìä **Aggregation Methods**\n",
    "- **max/min**: Track extremes (e.g., highest MAP, lowest SpO2)\n",
    "- **mean/median**: Central tendency for continuous variables\n",
    "- **first/last**: Assessments and time-sensitive values\n",
    "- **boolean**: Medication presence indicators\n",
    "- **one_hot_encode**: Categorical variable expansion\n",
    "\n",
    "### üéØ **Use Cases**\n",
    "- Vasopressor usage analysis\n",
    "- Vital sign stability tracking\n",
    "- Machine learning feature engineering\n",
    "- Time-series analysis preparation\n",
    "\n",
    "### üí° **Key Benefits**\n",
    "- **Data reduction**: Fewer rows while preserving clinical information\n",
    "- **Regular time intervals**: Easier for time-series modeling\n",
    "- **Flexible aggregation**: Choose appropriate method per variable\n",
    "- **Analysis-ready**: Direct use in statistical and ML workflows\n",
    "\n",
    "The hourly wide dataset format is ideal for:\n",
    "- Predictive modeling with regular time intervals\n",
    "- Trend analysis and pattern recognition\n",
    "- Clinical decision support systems\n",
    "- Research on temporal patterns in critical care"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing BaseTable Implementation and Enhanced Validation\n",
    "\n",
    "This notebook demonstrates the new BaseTable class implementation with comprehensive validation features for pyCLIF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path to import pyclif\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from src.pyclif.clif import CLIF\n",
    "from src.pyclif.tables.patient import patient\n",
    "from src.pyclif.tables.vitals import vitals\n",
    "from src.pyclif.tables.labs import labs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize CLIF with Output Directory\n",
    "\n",
    "The new CLIF class now supports an output directory for validation reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your data directory path\n",
    "data_dir = '../demo_data'  # Update this to your actual data directory\n",
    "output_dir = '../validation_output'  # Directory for validation outputs\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Initialize CLIF with output directory\n",
    "clif = CLIF(\n",
    "    data_dir=data_dir,\n",
    "    filetype='parquet',  # or 'csv' depending on your data\n",
    "    timezone='UTC',\n",
    "    output_dir=output_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Tables with New BaseTable Implementation\n",
    "\n",
    "All tables now inherit from BaseTable and have enhanced validation capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load patient data\n",
    "patient_table = clif.load_patient_data(sample_size=1000)\n",
    "print(f\"Patient table loaded: {len(patient_table.df)} rows\")\n",
    "print(f\"Validation status: {'Valid' if patient_table.isvalid() else 'Invalid'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vitals data\n",
    "vitals_table = clif.load_vitals_data(sample_size=5000)\n",
    "print(f\"Vitals table loaded: {len(vitals_table.df)} rows\")\n",
    "print(f\"Validation status: {'Valid' if vitals_table.isvalid() else 'Invalid'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load multiple tables at once\n",
    "clif.initialize(\n",
    "    tables=['hospitalization', 'adt', 'labs'],\n",
    "    sample_size=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Comprehensive Validation\n",
    "\n",
    "The new validation includes:\n",
    "- Schema validation\n",
    "- Missing data analysis\n",
    "- Duplicate checking on composite keys\n",
    "- Statistical analysis\n",
    "- Unit validation (for labs and vitals)\n",
    "- Range validation (for vitals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run validation on all loaded tables\n",
    "validation_summary = clif.validate_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display detailed validation results for a specific table\n",
    "if clif.vitals and not clif.vitals.isvalid():\n",
    "    print(\"Vitals validation errors:\")\n",
    "    for error in clif.vitals.errors[:5]:  # Show first 5 errors\n",
    "        print(f\"  - {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Direct Table Creation with BaseTable\n",
    "\n",
    "You can also create tables directly using the new BaseTable signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a patient table directly with the new signature\n",
    "patient_direct = patient.from_file(\n",
    "    data_directory=data_dir,\n",
    "    filetype='parquet',\n",
    "    timezone='UTC',\n",
    "    output_directory=output_dir,\n",
    "    sample_size=500\n",
    ")\n",
    "\n",
    "print(f\"Direct patient table loaded: {len(patient_direct.df)} rows\")\n",
    "print(f\"Table name: {patient_direct.table_name}\")\n",
    "print(f\"Output directory: {patient_direct.output_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Access Enhanced Validation Reports\n",
    "\n",
    "Validation reports are automatically saved to the output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get table summary\n",
    "if clif.patient:\n",
    "    summary = clif.patient.get_summary()\n",
    "    print(\"Patient Table Summary:\")\n",
    "    print(f\"  Rows: {summary['num_rows']}\")\n",
    "    print(f\"  Columns: {summary['num_columns']}\")\n",
    "    print(f\"  Memory Usage: {summary['memory_usage_mb']:.2f} MB\")\n",
    "    print(f\"  Validation Errors: {summary['validation_errors']}\")\n",
    "    print(f\"  Is Valid: {summary['is_valid']}\")\n",
    "    \n",
    "    # Save summary to file\n",
    "    clif.patient.save_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List generated validation files\n",
    "print(\"Validation output files:\")\n",
    "for file in os.listdir(output_dir):\n",
    "    if file.endswith(('.csv', '.log', '.json')):\n",
    "        print(f\"  - {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Using Enhanced Validator Functions\n",
    "\n",
    "The enhanced validator module provides comprehensive validation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pyclif.utils import validator\n",
    "\n",
    "# Example: Calculate missing data statistics\n",
    "if clif.vitals:\n",
    "    missing_stats = validator.calculate_missing_stats(clif.vitals.df, format='long')\n",
    "    print(\"\\nMissing Data Statistics (Top 5 columns):\")\n",
    "    print(missing_stats.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Check for duplicates on composite keys\n",
    "if clif.vitals:\n",
    "    duplicate_check = validator.check_for_duplicates(\n",
    "        clif.vitals.df,\n",
    "        composite_keys=['hospitalization_id', 'recorded_dttm', 'vital_category']\n",
    "    )\n",
    "    print(\"\\nDuplicate Check Results:\")\n",
    "    print(f\"  Total rows: {duplicate_check['total_rows']}\")\n",
    "    print(f\"  Duplicate rows: {duplicate_check['duplicate_rows']}\")\n",
    "    print(f\"  Has duplicates: {duplicate_check['has_duplicates']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Calculate cohort sizes\n",
    "if clif.hospitalization:\n",
    "    cohort_sizes = validator.calculate_cohort_sizes(\n",
    "        clif.hospitalization.df,\n",
    "        id_columns=['patient_id', 'hospitalization_id']\n",
    "    )\n",
    "    print(\"\\nCohort Sizes:\")\n",
    "    for key, value in cohort_sizes.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Vitals-Specific Range Validation\n",
    "\n",
    "The vitals table has special range validation for vital signs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clif.vitals:\n",
    "    # Access vital ranges from schema\n",
    "    print(\"Vital Ranges from Schema:\")\n",
    "    for vital, ranges in clif.vitals.vital_ranges.items():\n",
    "        print(f\"  {vital}: {ranges}\")\n",
    "    \n",
    "    # Check range validation errors\n",
    "    if hasattr(clif.vitals, 'range_validation_errors'):\n",
    "        print(f\"\\nRange validation errors: {len(clif.vitals.range_validation_errors)}\")\n",
    "        for error in clif.vitals.range_validation_errors[:3]:\n",
    "            print(f\"  - {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Labs-Specific Unit Validation\n",
    "\n",
    "The labs table validates reference units against expected values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clif.lab:\n",
    "    # Access lab reference units from schema\n",
    "    print(\"Lab Reference Units (first 5):\")\n",
    "    for i, (lab, units) in enumerate(clif.lab.lab_reference_units.items()):\n",
    "        if i >= 5:\n",
    "            break\n",
    "        print(f\"  {lab}: {units}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Backward Compatibility\n",
    "\n",
    "The refactored classes maintain backward compatibility with the old signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data for testing backward compatibility\n",
    "sample_data = pd.DataFrame({\n",
    "    'patient_id': ['P001', 'P002', 'P003'],\n",
    "    'birth_date': pd.to_datetime(['1980-01-01', '1975-05-15', '1990-12-20']),\n",
    "    'death_dttm': [pd.NaT, pd.NaT, pd.NaT],\n",
    "    'race_name': ['White', 'Black', 'Asian'],\n",
    "    'race_category': ['White', 'Black or African American', 'Asian'],\n",
    "    'ethnicity_name': ['Non-Hispanic', 'Non-Hispanic', 'Hispanic'],\n",
    "    'ethnicity_category': ['Non-Hispanic', 'Non-Hispanic', 'Hispanic'],\n",
    "    'sex_name': ['Male', 'Female', 'Male'],\n",
    "    'sex_category': ['Male', 'Female', 'Male'],\n",
    "    'language_name': ['English', 'English', 'Spanish'],\n",
    "    'language_category': ['English', 'English', 'Spanish']\n",
    "})\n",
    "\n",
    "# Old signature still works (for backward compatibility)\n",
    "patient_old_style = patient(data=sample_data)\n",
    "print(f\"Old style initialization works: {patient_old_style.df.shape}\")\n",
    "print(f\"Validation status: {'Valid' if patient_old_style.isvalid() else 'Invalid'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary\n",
    "\n",
    "The new BaseTable implementation provides:\n",
    "\n",
    "1. **Unified Interface**: All tables inherit from BaseTable with consistent methods\n",
    "2. **Enhanced Validation**: Comprehensive data quality checks including:\n",
    "   - Schema validation\n",
    "   - Missing data analysis\n",
    "   - Duplicate detection\n",
    "   - Statistical summaries\n",
    "   - Domain-specific validations (ranges, units)\n",
    "3. **Structured Logging**: All validation activities are logged\n",
    "4. **Output Management**: Validation reports saved to specified directory\n",
    "5. **Backward Compatibility**: Old code continues to work\n",
    "6. **YAML Schemas**: More readable and maintainable than JSON\n",
    "7. **Composite Keys**: Defined in schemas for duplicate detection\n",
    "\n",
    "All validation outputs are saved in the specified output directory for post-processing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
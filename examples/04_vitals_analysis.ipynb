{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Vitals Analysis\n",
    "\n",
    "This notebook demonstrates advanced analysis capabilities for vital signs data using pyCLIF, including filtering, aggregation, visualization, and clinical insights.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The vitals table is one of the most important CLIF tables for clinical analysis. This notebook covers:\n",
    "- Comprehensive vital signs exploration\n",
    "- Time-series analysis\n",
    "- Range validation and outlier detection\n",
    "- Clinical trend analysis\n",
    "- Statistical summaries and visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import pyCLIF components\n",
    "from pyclif.tables.vitals import vitals\n",
    "from pyclif.utils.io import load_data\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"Environment setup complete!\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Matplotlib version: {plt.__version__}\")\n",
    "print(f\"Seaborn version: {sns.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data directory\n",
    "DATA_DIR = \"/Users/vaishvik/downloads/CLIF_MIMIC\"\n",
    "print(f\"Data directory: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Explore Vitals Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vitals data with timezone conversion\n",
    "vitals_table = vitals.from_file(DATA_DIR, \"parquet\")\n",
    "\n",
    "print(f\"✅ Vitals data loaded successfully!\")\n",
    "print(f\"Shape: {vitals_table.df.shape}\")\n",
    "print(f\"Validation status: {vitals_table.isvalid()}\")\n",
    "print(f\"Date range: {vitals_table.df['recorded_dttm'].min()} to {vitals_table.df['recorded_dttm'].max()}\")\n",
    "\n",
    "# Display basic info\n",
    "print(\"\\nColumn information:\")\n",
    "print(vitals_table.df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vital Categories Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get comprehensive vital categories overview\n",
    "vital_categories = vitals_table.get_vital_categories()\n",
    "summary_stats = vitals_table.get_summary_stats()\n",
    "\n",
    "print(f\"=== VITAL CATEGORIES OVERVIEW ===\")\n",
    "print(f\"Total vital categories: {len(vital_categories)}\")\n",
    "print(f\"Total measurements: {summary_stats['total_records']:,}\")\n",
    "print(f\"Unique hospitalizations: {summary_stats['unique_hospitalizations']:,}\")\n",
    "\n",
    "print(\"\\nVital categories available:\")\n",
    "category_counts = summary_stats['vital_category_counts']\n",
    "for category in sorted(category_counts.keys()):\n",
    "    count = category_counts[category]\n",
    "    percentage = (count / summary_stats['total_records']) * 100\n",
    "    print(f\"  {category:<25}: {count:>8,} ({percentage:>5.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize vital category distribution\n",
    "plt.figure(figsize=(12, 8))\n",
    "category_counts = pd.Series(summary_stats['vital_category_counts'])\n",
    "top_categories = category_counts.nlargest(15)\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "top_categories.plot(kind='bar')\n",
    "plt.title('Top 15 Vital Categories by Measurement Count')\n",
    "plt.xlabel('Vital Category')\n",
    "plt.ylabel('Number of Measurements')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "top_categories.plot(kind='pie', autopct='%1.1f%%')\n",
    "plt.title('Distribution of Top Vital Categories')\n",
    "plt.ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Analysis by Vital Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on key vital signs\n",
    "key_vitals = ['heart_rate', 'sbp', 'dbp', 'temp_c', 'oxygen_saturation', 'respiratory_rate']\n",
    "available_key_vitals = [v for v in key_vitals if v in vital_categories]\n",
    "\n",
    "print(f\"=== KEY VITAL SIGNS ANALYSIS ===\")\n",
    "print(f\"Available key vitals: {available_key_vitals}\")\n",
    "\n",
    "vital_stats_summary = []\n",
    "\n",
    "for vital in available_key_vitals:\n",
    "    vital_data = vitals_table.filter_by_vital_category(vital)\n",
    "    \n",
    "    if not vital_data.empty and 'vital_value' in vital_data.columns:\n",
    "        stats = {\n",
    "            'vital': vital,\n",
    "            'count': len(vital_data),\n",
    "            'mean': vital_data['vital_value'].mean(),\n",
    "            'std': vital_data['vital_value'].std(),\n",
    "            'min': vital_data['vital_value'].min(),\n",
    "            'max': vital_data['vital_value'].max(),\n",
    "            'q25': vital_data['vital_value'].quantile(0.25),\n",
    "            'q50': vital_data['vital_value'].quantile(0.50),\n",
    "            'q75': vital_data['vital_value'].quantile(0.75)\n",
    "        }\n",
    "        vital_stats_summary.append(stats)\n",
    "        \n",
    "        print(f\"\\n{vital.upper()}:\")\n",
    "        print(f\"  Count: {stats['count']:,}\")\n",
    "        print(f\"  Mean ± SD: {stats['mean']:.1f} ± {stats['std']:.1f}\")\n",
    "        print(f\"  Range: {stats['min']:.1f} - {stats['max']:.1f}\")\n",
    "        print(f\"  IQR: {stats['q25']:.1f} - {stats['q75']:.1f}\")\n",
    "\n",
    "# Convert to DataFrame for easier manipulation\n",
    "vital_stats_df = pd.DataFrame(vital_stats_summary)\n",
    "print(f\"\\nSummary statistics calculated for {len(vital_stats_df)} vital signs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create box plots for key vitals\n",
    "if not vital_stats_df.empty:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, vital in enumerate(available_key_vitals[:6]):\n",
    "        vital_data = vitals_table.filter_by_vital_category(vital)\n",
    "        \n",
    "        if not vital_data.empty and 'vital_value' in vital_data.columns:\n",
    "            # Remove extreme outliers for visualization\n",
    "            q1 = vital_data['vital_value'].quantile(0.01)\n",
    "            q99 = vital_data['vital_value'].quantile(0.99)\n",
    "            filtered_data = vital_data[\n",
    "                (vital_data['vital_value'] >= q1) & \n",
    "                (vital_data['vital_value'] <= q99)\n",
    "            ]\n",
    "            \n",
    "            axes[i].boxplot(filtered_data['vital_value'])\n",
    "            axes[i].set_title(f'{vital.replace(\"_\", \" \").title()}')\n",
    "            axes[i].set_ylabel('Value')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for j in range(i+1, len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "    \n",
    "    plt.suptitle('Distribution of Key Vital Signs (1st-99th percentile)', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Range Validation and Outlier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze range validation results\n",
    "range_report = vitals_table.get_range_validation_report()\n",
    "\n",
    "print(\"=== RANGE VALIDATION ANALYSIS ===\")\n",
    "if not range_report.empty:\n",
    "    print(f\"Total range validation issues: {len(range_report)}\")\n",
    "    \n",
    "    # Group by error type\n",
    "    error_type_counts = range_report['error_type'].value_counts()\n",
    "    print(\"\\nError types:\")\n",
    "    for error_type, count in error_type_counts.items():\n",
    "        print(f\"  {error_type}: {count}\")\n",
    "    \n",
    "    # Show most problematic vitals\n",
    "    if 'affected_rows' in range_report.columns:\n",
    "        problematic_vitals = range_report.groupby('vital_category')['affected_rows'].sum().sort_values(ascending=False)\n",
    "        print(\"\\nVitals with most range validation issues:\")\n",
    "        for vital, affected_rows in problematic_vitals.head(5).items():\n",
    "            print(f\"  {vital}: {affected_rows:,} affected measurements\")\n",
    "    \n",
    "    # Display detailed report\n",
    "    print(\"\\nDetailed range validation report:\")\n",
    "    display_cols = ['vital_category', 'error_type', 'affected_rows', 'message']\n",
    "    available_cols = [col for col in display_cols if col in range_report.columns]\n",
    "    print(range_report[available_cols].head(10))\n",
    "else:\n",
    "    print(\"✅ No range validation issues found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze extreme values for a specific vital\n",
    "def analyze_extreme_values(vital_category, percentile_threshold=0.01):\n",
    "    \"\"\"Analyze extreme values for a specific vital category.\"\"\"\n",
    "    vital_data = vitals_table.filter_by_vital_category(vital_category)\n",
    "    \n",
    "    if vital_data.empty or 'vital_value' not in vital_data.columns:\n",
    "        print(f\"No data available for {vital_category}\")\n",
    "        return\n",
    "    \n",
    "    # Calculate percentiles\n",
    "    low_threshold = vital_data['vital_value'].quantile(percentile_threshold)\n",
    "    high_threshold = vital_data['vital_value'].quantile(1 - percentile_threshold)\n",
    "    \n",
    "    extreme_low = vital_data[vital_data['vital_value'] <= low_threshold]\n",
    "    extreme_high = vital_data[vital_data['vital_value'] >= high_threshold]\n",
    "    \n",
    "    print(f\"=== EXTREME VALUES ANALYSIS: {vital_category.upper()} ===\")\n",
    "    print(f\"Total measurements: {len(vital_data):,}\")\n",
    "    print(f\"Threshold percentiles: {percentile_threshold*100:.1f}% and {(1-percentile_threshold)*100:.1f}%\")\n",
    "    print(f\"Low threshold: ≤{low_threshold:.1f} ({len(extreme_low):,} measurements)\")\n",
    "    print(f\"High threshold: ≥{high_threshold:.1f} ({len(extreme_high):,} measurements)\")\n",
    "    \n",
    "    if not extreme_low.empty:\n",
    "        print(f\"\\nExtreme low values (sample):\")\n",
    "        sample_low = extreme_low.nsmallest(5, 'vital_value')[['patient_id', 'vital_value', 'recorded_dttm']]\n",
    "        print(sample_low.to_string(index=False))\n",
    "    \n",
    "    if not extreme_high.empty:\n",
    "        print(f\"\\nExtreme high values (sample):\")\n",
    "        sample_high = extreme_high.nlargest(5, 'vital_value')[['patient_id', 'vital_value', 'recorded_dttm']]\n",
    "        print(sample_high.to_string(index=False))\n",
    "\n",
    "# Analyze extreme values for heart rate\n",
    "if 'heart_rate' in available_key_vitals:\n",
    "    analyze_extreme_values('heart_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze temporal patterns in vital signs\n",
    "def analyze_temporal_patterns(vital_category, sample_patients=5):\n",
    "    \"\"\"Analyze temporal patterns for a specific vital category.\"\"\"\n",
    "    vital_data = vitals_table.filter_by_vital_category(vital_category)\n",
    "    \n",
    "    if vital_data.empty:\n",
    "        print(f\"No data available for {vital_category}\")\n",
    "        return\n",
    "    \n",
    "    # Convert datetime column\n",
    "    vital_data = vital_data.copy()\n",
    "    vital_data['recorded_dttm'] = pd.to_datetime(vital_data['recorded_dttm'])\n",
    "    \n",
    "    print(f\"=== TEMPORAL ANALYSIS: {vital_category.upper()} ===\")\n",
    "    print(f\"Date range: {vital_data['recorded_dttm'].min()} to {vital_data['recorded_dttm'].max()}\")\n",
    "    \n",
    "    # Daily measurement counts\n",
    "    daily_counts = vital_data.set_index('recorded_dttm').resample('D').size()\n",
    "    print(f\"\\nDaily measurement statistics:\")\n",
    "    print(f\"  Mean measurements/day: {daily_counts.mean():.1f}\")\n",
    "    print(f\"  Max measurements/day: {daily_counts.max()}\")\n",
    "    print(f\"  Days with measurements: {(daily_counts > 0).sum()}\")\n",
    "    \n",
    "    # Hourly patterns\n",
    "    vital_data['hour'] = vital_data['recorded_dttm'].dt.hour\n",
    "    hourly_counts = vital_data['hour'].value_counts().sort_index()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    daily_counts.plot()\n",
    "    plt.title(f'{vital_category} - Daily Measurement Counts')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Number of Measurements')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    hourly_counts.plot(kind='bar')\n",
    "    plt.title(f'{vital_category} - Hourly Distribution')\n",
    "    plt.xlabel('Hour of Day')\n",
    "    plt.ylabel('Number of Measurements')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return vital_data\n",
    "\n",
    "# Analyze temporal patterns for available vitals\n",
    "if available_key_vitals:\n",
    "    temporal_data = analyze_temporal_patterns(available_key_vitals[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patient-Level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze vital patterns for individual patients\n",
    "def analyze_patient_vitals(patient_id, vital_categories=None):\n",
    "    \"\"\"Analyze vital signs for a specific patient.\"\"\"\n",
    "    if vital_categories is None:\n",
    "        vital_categories = available_key_vitals[:3]  # Top 3 available vitals\n",
    "    \n",
    "    patient_data = vitals_table.df[vitals_table.df['patient_id'] == patient_id].copy()\n",
    "    \n",
    "    if patient_data.empty:\n",
    "        print(f\"No vital data found for patient {patient_id}\")\n",
    "        return\n",
    "    \n",
    "    patient_data['recorded_dttm'] = pd.to_datetime(patient_data['recorded_dttm'])\n",
    "    \n",
    "    print(f\"=== PATIENT ANALYSIS: {patient_id} ===\")\n",
    "    print(f\"Total vital measurements: {len(patient_data):,}\")\n",
    "    print(f\"Date range: {patient_data['recorded_dttm'].min()} to {patient_data['recorded_dttm'].max()}\")\n",
    "    print(f\"Vital categories: {patient_data['vital_category'].nunique()}\")\n",
    "    \n",
    "    # Plot vital trends\n",
    "    fig, axes = plt.subplots(len(vital_categories), 1, figsize=(12, 4*len(vital_categories)))\n",
    "    if len(vital_categories) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, vital in enumerate(vital_categories):\n",
    "        vital_subset = patient_data[patient_data['vital_category'] == vital]\n",
    "        \n",
    "        if not vital_subset.empty:\n",
    "            vital_subset = vital_subset.sort_values('recorded_dttm')\n",
    "            axes[i].plot(vital_subset['recorded_dttm'], vital_subset['vital_value'], 'o-', alpha=0.7)\n",
    "            axes[i].set_title(f'{vital.replace(\"_\", \" \").title()} Trend')\n",
    "            axes[i].set_ylabel('Value')\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add summary stats\n",
    "            mean_val = vital_subset['vital_value'].mean()\n",
    "            axes[i].axhline(y=mean_val, color='red', linestyle='--', alpha=0.5, label=f'Mean: {mean_val:.1f}')\n",
    "            axes[i].legend()\n",
    "        else:\n",
    "            axes[i].text(0.5, 0.5, f'No {vital} data', ha='center', va='center', transform=axes[i].transAxes)\n",
    "            axes[i].set_title(f'{vital.replace(\"_\", \" \").title()} - No Data')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return patient_data\n",
    "\n",
    "# Get a sample patient for analysis\n",
    "sample_patients = vitals_table.df['patient_id'].value_counts().head(5).index.tolist()\n",
    "if sample_patients:\n",
    "    print(f\"\\nTop 5 patients by measurement count:\")\n",
    "    for i, patient_id in enumerate(sample_patients):\n",
    "        count = vitals_table.df[vitals_table.df['patient_id'] == patient_id].shape[0]\n",
    "        print(f\"  {i+1}. {patient_id}: {count:,} measurements\")\n",
    "    \n",
    "    # Analyze the patient with most measurements\n",
    "    if sample_patients:\n",
    "        patient_analysis = analyze_patient_vitals(sample_patients[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clinical Insights and Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze correlations between vital signs\n",
    "def analyze_vital_correlations(vital_list):\n",
    "    \"\"\"Analyze correlations between different vital signs.\"\"\"\n",
    "    correlation_data = []\n",
    "    \n",
    "    for vital in vital_list:\n",
    "        vital_subset = vitals_table.filter_by_vital_category(vital)\n",
    "        if not vital_subset.empty and 'patient_id' in vital_subset.columns:\n",
    "            # Get average vital value per patient\n",
    "            patient_avg = vital_subset.groupby('patient_id')['vital_value'].mean().reset_index()\n",
    "            patient_avg['vital_category'] = vital\n",
    "            correlation_data.append(patient_avg)\n",
    "    \n",
    "    if not correlation_data:\n",
    "        print(\"Insufficient data for correlation analysis\")\n",
    "        return\n",
    "    \n",
    "    # Combine all vital data\n",
    "    combined_data = pd.concat(correlation_data, ignore_index=True)\n",
    "    \n",
    "    # Pivot to get vitals as columns\n",
    "    pivot_data = combined_data.pivot(index='patient_id', columns='vital_category', values='vital_value')\n",
    "    \n",
    "    # Calculate correlations\n",
    "    correlations = pivot_data.corr()\n",
    "    \n",
    "    print(\"=== VITAL SIGN CORRELATIONS ===\")\n",
    "    print(f\"Patients with complete data: {len(pivot_data.dropna())}\")\n",
    "    print(f\"Vitals analyzed: {list(pivot_data.columns)}\")\n",
    "    \n",
    "    # Plot correlation heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(correlations, annot=True, cmap='coolwarm', center=0, \n",
    "                square=True, fmt='.2f', cbar_kws={'label': 'Correlation Coefficient'})\n",
    "    plt.title('Correlation Matrix of Vital Signs\\n(Patient-Level Averages)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return pivot_data, correlations\n",
    "\n",
    "# Analyze correlations for available key vitals\n",
    "if len(available_key_vitals) >= 2:\n",
    "    vital_correlations = analyze_vital_correlations(available_key_vitals[:4])  # Top 4 vitals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Filtering and Cohort Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cohorts based on vital sign characteristics\n",
    "def create_vital_cohorts(vital_category, threshold_percentiles=[25, 75]):\n",
    "    \"\"\"Create patient cohorts based on vital sign values.\"\"\"\n",
    "    vital_data = vitals_table.filter_by_vital_category(vital_category)\n",
    "    \n",
    "    if vital_data.empty:\n",
    "        print(f\"No data available for {vital_category}\")\n",
    "        return\n",
    "    \n",
    "    # Calculate patient-level statistics\n",
    "    patient_stats = vital_data.groupby('patient_id')['vital_value'].agg([\n",
    "        'count', 'mean', 'std', 'min', 'max'\n",
    "    ]).reset_index()\n",
    "    \n",
    "    # Define cohorts based on mean values\n",
    "    low_threshold = patient_stats['mean'].quantile(threshold_percentiles[0]/100)\n",
    "    high_threshold = patient_stats['mean'].quantile(threshold_percentiles[1]/100)\n",
    "    \n",
    "    patient_stats['cohort'] = 'Normal'\n",
    "    patient_stats.loc[patient_stats['mean'] <= low_threshold, 'cohort'] = 'Low'\n",
    "    patient_stats.loc[patient_stats['mean'] >= high_threshold, 'cohort'] = 'High'\n",
    "    \n",
    "    print(f\"=== COHORT ANALYSIS: {vital_category.upper()} ===\")\n",
    "    print(f\"Cohort definitions (based on {threshold_percentiles[0]}th and {threshold_percentiles[1]}th percentiles):\")\n",
    "    print(f\"  Low: ≤{low_threshold:.1f}\")\n",
    "    print(f\"  Normal: {low_threshold:.1f} - {high_threshold:.1f}\")\n",
    "    print(f\"  High: ≥{high_threshold:.1f}\")\n",
    "    \n",
    "    cohort_summary = patient_stats.groupby('cohort').agg({\n",
    "        'patient_id': 'count',\n",
    "        'mean': ['mean', 'std'],\n",
    "        'count': ['mean', 'std']\n",
    "    }).round(2)\n",
    "    \n",
    "    print(\"\\nCohort summary:\")\n",
    "    print(cohort_summary)\n",
    "    \n",
    "    # Visualize cohorts\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    patient_stats['cohort'].value_counts().plot(kind='bar')\n",
    "    plt.title('Patient Count by Cohort')\n",
    "    plt.ylabel('Number of Patients')\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    for cohort in patient_stats['cohort'].unique():\n",
    "        cohort_data = patient_stats[patient_stats['cohort'] == cohort]['mean']\n",
    "        plt.hist(cohort_data, alpha=0.7, label=cohort, bins=20)\n",
    "    plt.xlabel(f'Mean {vital_category}')\n",
    "    plt.ylabel('Number of Patients')\n",
    "    plt.title('Distribution of Mean Values by Cohort')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    sns.boxplot(data=patient_stats, x='cohort', y='mean')\n",
    "    plt.title(f'Mean {vital_category} by Cohort')\n",
    "    plt.ylabel(f'Mean {vital_category}')\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    sns.boxplot(data=patient_stats, x='cohort', y='count')\n",
    "    plt.title('Number of Measurements by Cohort')\n",
    "    plt.ylabel('Measurement Count')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return patient_stats\n",
    "\n",
    "# Create cohorts for heart rate if available\n",
    "if 'heart_rate' in available_key_vitals:\n",
    "    hr_cohorts = create_vital_cohorts('heart_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Clinical Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive summary report\n",
    "def generate_vitals_summary_report():\n",
    "    \"\"\"Generate a comprehensive summary of vitals analysis.\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"              VITALS ANALYSIS SUMMARY REPORT\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"Data source: {DATA_DIR}\")\n",
    "    \n",
    "    # Basic statistics\n",
    "    summary = vitals_table.get_summary_stats()\n",
    "    print(f\"\\n📊 DATASET OVERVIEW:\")\n",
    "    print(f\"  • Total measurements: {summary['total_records']:,}\")\n",
    "    print(f\"  • Unique patients: {vitals_table.df['patient_id'].nunique():,}\")\n",
    "    print(f\"  • Unique hospitalizations: {summary['unique_hospitalizations']:,}\")\n",
    "    print(f\"  • Vital categories: {len(vital_categories)}\")\n",
    "    print(f\"  • Date range: {summary['date_range']['earliest']} to {summary['date_range']['latest']}\")\n",
    "    \n",
    "    # Data quality\n",
    "    print(f\"\\n🔍 DATA QUALITY:\")\n",
    "    print(f\"  • Validation passed: {vitals_table.isvalid()}\")\n",
    "    print(f\"  • Schema errors: {len(vitals_table.errors)}\")\n",
    "    print(f\"  • Range validation errors: {len(vitals_table.range_validation_errors)}\")\n",
    "    print(f\"  • Missing values: {vitals_table.df.isnull().sum().sum():,} cells\")\n",
    "    print(f\"  • Duplicate records: {vitals_table.df.duplicated().sum():,}\")\n",
    "    \n",
    "    # Top vital categories\n",
    "    print(f\"\\n📈 TOP VITAL CATEGORIES:\")\n",
    "    top_categories = pd.Series(summary['vital_category_counts']).nlargest(5)\n",
    "    for vital, count in top_categories.items():\n",
    "        percentage = (count / summary['total_records']) * 100\n",
    "        print(f\"  • {vital}: {count:,} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Clinical insights\n",
    "    print(f\"\\n🏥 CLINICAL INSIGHTS:\")\n",
    "    \n",
    "    if 'heart_rate' in available_key_vitals:\n",
    "        hr_data = vitals_table.filter_by_vital_category('heart_rate')\n",
    "        hr_mean = hr_data['vital_value'].mean()\n",
    "        hr_std = hr_data['vital_value'].std()\n",
    "        print(f\"  • Average heart rate: {hr_mean:.1f} ± {hr_std:.1f} bpm\")\n",
    "    \n",
    "    if 'temp_c' in available_key_vitals:\n",
    "        temp_data = vitals_table.filter_by_vital_category('temp_c')\n",
    "        temp_mean = temp_data['vital_value'].mean()\n",
    "        print(f\"  • Average temperature: {temp_mean:.1f}°C\")\n",
    "    \n",
    "    # Measurement frequency\n",
    "    measurements_per_patient = vitals_table.df.groupby('patient_id').size()\n",
    "    print(f\"  • Avg measurements per patient: {measurements_per_patient.mean():.1f}\")\n",
    "    print(f\"  • Max measurements per patient: {measurements_per_patient.max():,}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"End of Report\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Generate the summary report\n",
    "generate_vitals_summary_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps and Advanced Usage\n",
    "\n",
    "This notebook demonstrated:\n",
    "- Comprehensive vital signs data exploration\n",
    "- Range validation and outlier detection\n",
    "- Temporal pattern analysis\n",
    "- Patient-level vital trends\n",
    "- Correlation analysis between vitals\n",
    "- Cohort creation based on vital characteristics\n",
    "- Clinical insights and summary reporting\n",
    "\n",
    "### Potential Extensions:\n",
    "1. **Predictive Modeling**: Use vital trends to predict clinical outcomes\n",
    "2. **Anomaly Detection**: Identify unusual vital sign patterns\n",
    "3. **Severity Scoring**: Calculate clinical severity scores (SOFA, APACHE)\n",
    "4. **Time-to-Event Analysis**: Analyze vital changes before critical events\n",
    "5. **Multi-Modal Analysis**: Combine vitals with other CLIF tables\n",
    "\n",
    "### Clinical Applications:\n",
    "- Early warning systems\n",
    "- Quality improvement initiatives\n",
    "- Research on physiological patterns\n",
    "- Benchmarking and outcome analysis\n",
    "\n",
    "### Explore Other Notebooks:\n",
    "- `01_basic_usage.ipynb` - Basic pyCLIF usage\n",
    "- `02_individual_tables.ipynb` - Individual table classes\n",
    "- `03_data_validation.ipynb` - Data validation techniques\n",
    "- `05_timezone_handling.ipynb` - Timezone conversion\n",
    "- `06_data_filtering.ipynb` - Advanced filtering techniques"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
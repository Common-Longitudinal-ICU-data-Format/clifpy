{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide Dataset Creation with pyCLIF\n",
    "\n",
    "This notebook demonstrates how to create wide datasets using the pyCLIF library with data from the CLIF_MIMIC directory. The wide dataset function automatically loads required tables and supports various configuration options.\n",
    "\n",
    "**Author:** pyCLIF Team  \n",
    "**Date:** 2024\n",
    "\n",
    "## Overview\n",
    "\n",
    "The wide dataset functionality allows you to:\n",
    "- **Automatically join** multiple CLIF tables (patient, hospitalization, ADT, and optional tables)\n",
    "- **Pivot category-based data** from vitals, labs, medications, and assessments\n",
    "- **Sample or filter** hospitalizations for targeted analysis\n",
    "- **Handle time-based alignment** of events across different tables\n",
    "- **Save results** in multiple formats (DataFrame, CSV, Parquet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "from pyclif import CLIF\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=== pyCLIF Wide Dataset Example ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Data Directory\n",
    "\n",
    "Update the `data_dir` variable to point to your CLIF data location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CLIF with MIMIC data\n",
    "data_dir = \"/Users/vaishvik/Downloads/CLIF_MIMIC\"\n",
    "\n",
    "# Check if data directory exists\n",
    "if not os.path.exists(data_dir):\n",
    "    print(f\"‚ö†Ô∏è  Warning: Data directory {data_dir} does not exist.\")\n",
    "    print(\"Please update the data_dir variable to point to your CLIF data location.\")\n",
    "else:\n",
    "    print(f\"‚úÖ Data directory found: {data_dir}\")\n",
    "    \n",
    "    # List available files\n",
    "    clif_files = [f for f in os.listdir(data_dir) if f.startswith('clif_') and f.endswith('.parquet')]\n",
    "    print(f\"üìÅ Available CLIF files: {len(clif_files)}\")\n",
    "    for file in sorted(clif_files):\n",
    "        print(f\"   - {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize CLIF Object\n",
    "\n",
    "Configure pyCLIF with your data directory, file format, and timezone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Initializing CLIF with data from: {data_dir}\")\n",
    "clif = CLIF(\n",
    "    data_dir=data_dir,\n",
    "    filetype='parquet',\n",
    "    timezone=\"US/Eastern\"\n",
    ")\n",
    "print(\"üöÄ CLIF object initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Sample Mode (20 Random Hospitalizations)\n",
    "\n",
    "This example demonstrates creating a wide dataset with a random sample of 20 hospitalizations, including vitals and labs data with specific category filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Example 1: Sample Mode (20 Random Hospitalizations) ===\")\n",
    "\n",
    "try:\n",
    "    wide_df_sample = clif.create_wide_dataset(\n",
    "        optional_tables=['vitals', 'labs'],\n",
    "        category_filters={\n",
    "            'vitals': ['map', 'heart_rate', 'spo2', 'respiratory_rate'],\n",
    "            'labs': ['hemoglobin', 'wbc', 'sodium', 'potassium']\n",
    "        },\n",
    "        sample=True,\n",
    "        save_to_data_location=True,\n",
    "        output_filename='sample_wide_dataset',\n",
    "        output_format='parquet'\n",
    "    )\n",
    "    \n",
    "    if wide_df_sample is not None:\n",
    "        print(f\"‚úÖ Sample wide dataset created with {len(wide_df_sample):,} records and {len(wide_df_sample.columns)} columns\")\n",
    "        print(f\"üë• Unique hospitalizations: {wide_df_sample['hospitalization_id'].nunique()}\")\n",
    "        print(f\"üìÖ Date range: {wide_df_sample['event_time'].min()} to {wide_df_sample['event_time'].max()}\")\n",
    "        \n",
    "        # Show column breakdown\n",
    "        vital_cols = [col for col in wide_df_sample.columns if col in ['map', 'heart_rate', 'spo2', 'respiratory_rate']]\n",
    "        lab_cols = [col for col in wide_df_sample.columns if col in ['hemoglobin', 'wbc', 'sodium', 'potassium']]\n",
    "        \n",
    "        print(f\"\\nüìä Available vital columns: {vital_cols}\")\n",
    "        print(f\"üß™ Available lab columns: {lab_cols}\")\n",
    "    else:\n",
    "        print(\"‚úÖ Sample wide dataset saved to file successfully\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in Example 1: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_df_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Sample Data\n",
    "\n",
    "Let's examine the structure of the sample dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'wide_df_sample' in locals() and wide_df_sample is not None:\n",
    "    print(\"üìã Sample Data Structure:\")\n",
    "    print(f\"Shape: {wide_df_sample.shape}\")\n",
    "    \n",
    "    # Show key columns\n",
    "    key_cols = ['patient_id', 'hospitalization_id', 'event_time', 'day_number', 'hosp_id_day_key']\n",
    "    available_key_cols = [col for col in key_cols if col in wide_df_sample.columns]\n",
    "    \n",
    "    print(f\"\\nüîë Key columns (first 5 rows):\")\n",
    "    display(wide_df_sample[available_key_cols].head())\n",
    "    \n",
    "    # Show data availability for vitals and labs\n",
    "    vital_cols = [col for col in wide_df_sample.columns if col in ['map', 'heart_rate', 'spo2', 'respiratory_rate']]\n",
    "    lab_cols = [col for col in wide_df_sample.columns if col in ['hemoglobin', 'wbc', 'sodium', 'potassium']]\n",
    "    \n",
    "    if vital_cols:\n",
    "        print(f\"\\nüìä Vital signs data availability:\")\n",
    "        for col in vital_cols:\n",
    "            non_null_count = wide_df_sample[col].notna().sum()\n",
    "            percentage = (non_null_count / len(wide_df_sample)) * 100\n",
    "            print(f\"   {col}: {non_null_count:,} records ({percentage:.1f}%)\")\n",
    "    \n",
    "    if lab_cols:\n",
    "        print(f\"\\nüß™ Lab data availability:\")\n",
    "        for col in lab_cols:\n",
    "            non_null_count = wide_df_sample[col].notna().sum()\n",
    "            percentage = (non_null_count / len(wide_df_sample)) * 100\n",
    "            print(f\"   {col}: {non_null_count:,} records ({percentage:.1f}%)\")\n",
    "else:\n",
    "    print(\"No sample data available to display\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Specific Hospitalization IDs\n",
    "\n",
    "This example shows how to create a wide dataset for specific hospitalization encounters, focusing on medications and assessments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Example 2: Specific Hospitalization IDs ===\")\n",
    "\n",
    "try:\n",
    "    # First, let's get some hospitalization IDs from the sample\n",
    "    clif.load_hospitalization_data()\n",
    "    sample_ids = clif.hospitalization.df['hospitalization_id'].head(5).tolist()\n",
    "    print(f\"üéØ Using sample hospitalization IDs: {sample_ids}\")\n",
    "    \n",
    "    wide_df_targeted = clif.create_wide_dataset(\n",
    "        hospitalization_ids=sample_ids,\n",
    "        optional_tables=['medication_admin_continuous', 'patient_assessments'],\n",
    "        category_filters={\n",
    "            'medication_admin_continuous': ['norepinephrine', 'propofol', 'fentanyl'],\n",
    "            'patient_assessments': ['gcs_total', 'rass', 'sbt_delivery_pass_fail']\n",
    "        },\n",
    "        save_to_data_location=True,\n",
    "        output_filename='targeted_encounters_wide',\n",
    "        output_format='csv'\n",
    "    )\n",
    "    \n",
    "    if wide_df_targeted is not None:\n",
    "        print(f\"‚úÖ Targeted wide dataset created with {len(wide_df_targeted):,} records\")\n",
    "        print(f\"üë• Hospitalizations included: {wide_df_targeted['hospitalization_id'].nunique()}\")\n",
    "        \n",
    "        # Show medication and assessment availability\n",
    "        med_cols = [col for col in wide_df_targeted.columns if col in ['norepinephrine', 'propofol', 'fentanyl']]\n",
    "        assess_cols = [col for col in wide_df_targeted.columns if col in ['gcs_total', 'rass', 'sbt_delivery_pass_fail']]\n",
    "        \n",
    "        print(f\"\\nüíä Available medication columns: {med_cols}\")\n",
    "        print(f\"üìã Available assessment columns: {assess_cols}\")\n",
    "    else:\n",
    "        print(\"‚úÖ Targeted wide dataset saved to file successfully\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in Example 2: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Targeted Dataset\n",
    "\n",
    "Let's examine the medication and assessment data for the targeted hospitalizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'wide_df_targeted' in locals() and wide_df_targeted is not None:\n",
    "    print(\"üìä Targeted Dataset Analysis:\")\n",
    "    \n",
    "    # Medication usage analysis\n",
    "    med_cols = [col for col in wide_df_targeted.columns if col in ['norepinephrine', 'propofol', 'fentanyl']]\n",
    "    if med_cols:\n",
    "        print(\"\\nüíä Medication Usage:\")\n",
    "        for med in med_cols:\n",
    "            if med in wide_df_targeted.columns:\n",
    "                usage_count = wide_df_targeted[med].notna().sum()\n",
    "                if usage_count > 0:\n",
    "                    mean_dose = wide_df_targeted[med].mean()\n",
    "                    print(f\"   {med}: {usage_count} administrations, mean dose: {mean_dose:.2f}\")\n",
    "                else:\n",
    "                    print(f\"   {med}: No data available\")\n",
    "    \n",
    "    # Assessment analysis\n",
    "    assess_cols = [col for col in wide_df_targeted.columns if col in ['gcs_total', 'rass', 'sbt_delivery_pass_fail']]\n",
    "    if assess_cols:\n",
    "        print(\"\\nüìã Assessment Data:\")\n",
    "        for assess in assess_cols:\n",
    "            if assess in wide_df_targeted.columns:\n",
    "                non_null_count = wide_df_targeted[assess].notna().sum()\n",
    "                if non_null_count > 0:\n",
    "                    if assess in ['gcs_total', 'rass']:\n",
    "                        mean_val = wide_df_targeted[assess].mean()\n",
    "                        print(f\"   {assess}: {non_null_count} assessments, mean: {mean_val:.1f}\")\n",
    "                    else:\n",
    "                        print(f\"   {assess}: {non_null_count} assessments\")\n",
    "                else:\n",
    "                    print(f\"   {assess}: No data available\")\n",
    "    \n",
    "    # Show sample of the targeted data\n",
    "    print(\"\\nüìã Sample of targeted data (first 3 rows):\")\n",
    "    display_cols = ['hospitalization_id', 'event_time', 'day_number'] + med_cols + assess_cols\n",
    "    available_display_cols = [col for col in display_cols if col in wide_df_targeted.columns]\n",
    "    display(wide_df_targeted[available_display_cols].head(3))\n",
    "else:\n",
    "    print(\"No targeted data available to display\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Comprehensive Wide Dataset\n",
    "\n",
    "This example creates a comprehensive wide dataset including all optional tables with extensive category filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Example 3: Comprehensive Wide Dataset ===\")\n",
    "\n",
    "try:\n",
    "    wide_df_full = clif.create_wide_dataset(\n",
    "        optional_tables=['vitals', 'labs', 'medication_admin_continuous', 'patient_assessments', 'respiratory_support'],\n",
    "        category_filters={\n",
    "            'vitals': ['map', 'heart_rate', 'spo2', 'respiratory_rate', 'temp_c'],\n",
    "            'labs': ['hemoglobin', 'wbc', 'sodium', 'potassium', 'creatinine'],\n",
    "            'medication_admin_continuous': ['norepinephrine', 'epinephrine', 'propofol', 'fentanyl'],\n",
    "            'patient_assessments': ['gcs_total', 'rass', 'sbt_delivery_pass_fail', 'sat_delivery_pass_fail']\n",
    "        },\n",
    "        sample=True,  # Use sample for demo purposes\n",
    "        save_to_data_location=True,\n",
    "        output_filename='comprehensive_wide_dataset',\n",
    "        output_format='parquet'\n",
    "    )\n",
    "    \n",
    "    if wide_df_full is not None:\n",
    "        print(f\"‚úÖ Comprehensive wide dataset created with {len(wide_df_full):,} records and {len(wide_df_full.columns)} columns\")\n",
    "        \n",
    "        # Show some statistics\n",
    "        print(\"\\nüìä Dataset Statistics:\")\n",
    "        print(f\"   üë• Unique patients: {wide_df_full['patient_id'].nunique()}\")\n",
    "        print(f\"   üè• Unique hospitalizations: {wide_df_full['hospitalization_id'].nunique()}\")\n",
    "        print(f\"   üìÖ Date range: {wide_df_full['event_time'].min()} to {wide_df_full['event_time'].max()}\")\n",
    "        print(f\"   üìà Max days per hospitalization: {wide_df_full['day_number'].max()}\")\n",
    "        \n",
    "        # Show available columns by category\n",
    "        vital_cols = [col for col in wide_df_full.columns if col in ['map', 'heart_rate', 'spo2', 'respiratory_rate', 'temp_c']]\n",
    "        lab_cols = [col for col in wide_df_full.columns if col in ['hemoglobin', 'wbc', 'sodium', 'potassium', 'creatinine']]\n",
    "        med_cols = [col for col in wide_df_full.columns if col in ['norepinephrine', 'epinephrine', 'propofol', 'fentanyl']]\n",
    "        assess_cols = [col for col in wide_df_full.columns if col in ['gcs_total', 'rass', 'sbt_delivery_pass_fail', 'sat_delivery_pass_fail']]\n",
    "        \n",
    "        print(f\"\\nüìä Available vital columns: {vital_cols}\")\n",
    "        print(f\"üß™ Available lab columns: {lab_cols}\")\n",
    "        print(f\"üíä Available medication columns: {med_cols}\")\n",
    "        print(f\"üìã Available assessment columns: {assess_cols}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚úÖ Comprehensive wide dataset saved to file successfully\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in Example 3: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehensive Dataset Analysis\n",
    "\n",
    "Let's analyze the comprehensive dataset in detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'wide_df_full' in locals() and wide_df_full is not None:\n",
    "    print(\"üìä Comprehensive Dataset Analysis:\")\n",
    "    \n",
    "    # Data completeness analysis\n",
    "    categories = {\n",
    "        'Vitals': ['map', 'heart_rate', 'spo2', 'respiratory_rate', 'temp_c'],\n",
    "        'Labs': ['hemoglobin', 'wbc', 'sodium', 'potassium', 'creatinine'],\n",
    "        'Medications': ['norepinephrine', 'epinephrine', 'propofol', 'fentanyl'],\n",
    "        'Assessments': ['gcs_total', 'rass', 'sbt_delivery_pass_fail', 'sat_delivery_pass_fail']\n",
    "    }\n",
    "    \n",
    "    completeness_data = []\n",
    "    \n",
    "    for category, columns in categories.items():\n",
    "        available_cols = [col for col in columns if col in wide_df_full.columns]\n",
    "        if available_cols:\n",
    "            print(f\"\\n{category} Data Completeness:\")\n",
    "            for col in available_cols:\n",
    "                non_null_count = wide_df_full[col].notna().sum()\n",
    "                percentage = (non_null_count / len(wide_df_full)) * 100\n",
    "                completeness_data.append({\n",
    "                    'Category': category,\n",
    "                    'Variable': col,\n",
    "                    'Non-null Count': non_null_count,\n",
    "                    'Completeness %': percentage\n",
    "                })\n",
    "                print(f\"   {col}: {non_null_count:,} records ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Create completeness summary\n",
    "    if completeness_data:\n",
    "        completeness_df = pd.DataFrame(completeness_data)\n",
    "        print(\"\\nüìã Data Completeness Summary:\")\n",
    "        display(completeness_df.round(1))\n",
    "    \n",
    "    # Show sample data with key columns\n",
    "    print(\"\\nüìã Sample data (first 3 rows, key columns):\")\n",
    "    key_cols = ['patient_id', 'hospitalization_id', 'event_time', 'day_number', 'hosp_id_day_key']\n",
    "    available_key_cols = [col for col in key_cols if col in wide_df_full.columns]\n",
    "    display(wide_df_full[available_key_cols].head(3))\n",
    "    \n",
    "else:\n",
    "    print(\"No comprehensive data available to display\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Return DataFrame (No Saving)\n",
    "\n",
    "This example demonstrates creating a wide dataset in memory without saving to disk, useful for immediate analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Example 4: Return DataFrame (No Saving) ===\")\n",
    "\n",
    "try:\n",
    "    wide_df_memory = clif.create_wide_dataset(\n",
    "        optional_tables=['vitals'],\n",
    "        category_filters={\n",
    "            'vitals': ['map', 'heart_rate']\n",
    "        },\n",
    "        sample=True,\n",
    "        save_to_data_location=False  # Don't save, just return DataFrame\n",
    "    )\n",
    "    \n",
    "    if wide_df_memory is not None:\n",
    "        print(f\"‚úÖ In-memory wide dataset created with {len(wide_df_memory):,} records\")\n",
    "        print(\"üíæ This dataset is available for immediate analysis and has not been saved to disk.\")\n",
    "        \n",
    "        # Example analysis\n",
    "        if 'map' in wide_df_memory.columns:\n",
    "            map_stats = wide_df_memory['map'].describe()\n",
    "            print(f\"\\nüìä MAP (Mean Arterial Pressure) Statistics:\")\n",
    "            print(map_stats.round(2))\n",
    "            \n",
    "            # MAP distribution by day\n",
    "            if 'day_number' in wide_df_memory.columns:\n",
    "                map_by_day = wide_df_memory.groupby('day_number')['map'].agg(['count', 'mean', 'std']).round(2)\n",
    "                print(f\"\\nüìà MAP by Hospital Day:\")\n",
    "                display(map_by_day.head(10))\n",
    "        \n",
    "        if 'heart_rate' in wide_df_memory.columns:\n",
    "            hr_stats = wide_df_memory['heart_rate'].describe()\n",
    "            print(f\"\\nüíì Heart Rate Statistics:\")\n",
    "            print(hr_stats.round(2))\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå Failed to create in-memory dataset\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in Example 4: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'wide_df_filtered' in locals() and wide_df_filtered is not None:\n",
    "    print(\"üìä Column Selection Analysis:\")\n",
    "    \n",
    "    # Analyze the demographics included\n",
    "    demo_cols = ['age', 'sex', 'race']\n",
    "    available_demo = [col for col in demo_cols if col in wide_df_filtered.columns]\n",
    "    \n",
    "    if available_demo:\n",
    "        print(f\"\\nüë• Demographics Summary:\")\n",
    "        for col in available_demo:\n",
    "            if col == 'age':\n",
    "                age_stats = wide_df_filtered[col].describe()\n",
    "                print(f\"   {col}: mean={age_stats['mean']:.1f}, std={age_stats['std']:.1f}\")\n",
    "            else:\n",
    "                value_counts = wide_df_filtered[col].value_counts()\n",
    "                print(f\"   {col}: {dict(value_counts.head(3))}\")\n",
    "    \n",
    "    # Analyze temporal coverage\n",
    "    time_cols = ['admit_dttm', 'event_time']\n",
    "    available_time = [col for col in time_cols if col in wide_df_filtered.columns]\n",
    "    \n",
    "    if available_time:\n",
    "        print(f\"\\nüìÖ Temporal Coverage:\")\n",
    "        for col in available_time:\n",
    "            if wide_df_filtered[col].notna().sum() > 0:\n",
    "                min_time = wide_df_filtered[col].min()\n",
    "                max_time = wide_df_filtered[col].max()\n",
    "                print(f\"   {col}: {min_time} to {max_time}\")\n",
    "    \n",
    "    # Show column efficiency\n",
    "    print(f\"\\n‚ö° Efficiency Metrics:\")\n",
    "    print(f\"   Total columns: {len(wide_df_filtered.columns)}\")\n",
    "    print(f\"   Memory usage per row reduced by focusing on essential columns\")\n",
    "    print(f\"   Processing speed improved with targeted column selection\")\n",
    "    \n",
    "    # Demonstrate focused analysis capability\n",
    "    vital_cols = [col for col in ['map', 'heart_rate', 'spo2'] if col in wide_df_filtered.columns]\n",
    "    if vital_cols:\n",
    "        print(f\"\\nüîç Focused Analysis - Vital Signs:\")\n",
    "        vital_summary = wide_df_filtered[vital_cols].describe().round(2)\n",
    "        display(vital_summary)\n",
    "        \n",
    "        # Show correlation if multiple vitals available\n",
    "        if len(vital_cols) > 1:\n",
    "            print(f\"\\nüìà Vital Signs Correlations:\")\n",
    "            vital_corr = wide_df_filtered[vital_cols].corr().round(3)\n",
    "            display(vital_corr)\n",
    "    \n",
    "else:\n",
    "    print(\"No filtered dataset available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis: Column Selection Benefits\n",
    "\n",
    "Let's analyze the benefits of base table column selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Example 5: Base Table Column Selection ===\")\n",
    "\n",
    "try:\n",
    "    # Define which columns to include from base tables for memory efficiency\n",
    "    base_columns = {\n",
    "        'patient': ['patient_id', 'age', 'sex', 'race'],\n",
    "        'hospitalization': ['hospitalization_id', 'patient_id', 'admit_dttm', 'discharge_dttm'],\n",
    "        'adt': ['hospitalization_id', 'in_dttm', 'out_dttm', 'location']\n",
    "    }\n",
    "    \n",
    "    print(\"üéØ Selected base table columns:\")\n",
    "    for table, cols in base_columns.items():\n",
    "        print(f\"   {table}: {cols}\")\n",
    "    \n",
    "    # Create wide dataset with filtered base columns\n",
    "    wide_df_filtered = clif.create_wide_dataset(\n",
    "        optional_tables=['vitals'],\n",
    "        category_filters={\n",
    "            'vitals': ['map', 'heart_rate', 'spo2']\n",
    "        },\n",
    "        sample=True,\n",
    "        base_table_columns=base_columns,\n",
    "        save_to_data_location=True,\n",
    "        output_filename='filtered_columns_wide_dataset',\n",
    "        output_format='parquet'\n",
    "    )\n",
    "    \n",
    "    if wide_df_filtered is not None:\n",
    "        print(f\"\\n‚úÖ Filtered wide dataset created with {len(wide_df_filtered):,} records and {len(wide_df_filtered.columns)} columns\")\n",
    "        \n",
    "        # Show which base table columns were included\n",
    "        print(f\"\\nüìä Base table columns included in final dataset:\")\n",
    "        for table, cols in base_columns.items():\n",
    "            available_cols = [col for col in cols if col in wide_df_filtered.columns]\n",
    "            print(f\"   {table}: {available_cols}\")\n",
    "        \n",
    "        # Show memory efficiency benefits\n",
    "        print(f\"\\nüíæ Memory Efficiency Benefits:\")\n",
    "        print(f\"   - Focused on essential demographics and timestamps\")\n",
    "        print(f\"   - Reduced memory footprint compared to loading all columns\")\n",
    "        print(f\"   - Faster processing with fewer columns to handle\")\n",
    "        \n",
    "        # Display sample of the filtered dataset\n",
    "        print(f\"\\nüìã Sample of filtered dataset:\")\n",
    "        display_cols = ['patient_id', 'age', 'sex', 'hospitalization_id', 'admit_dttm', 'event_time', 'map', 'heart_rate']\n",
    "        available_display_cols = [col for col in display_cols if col in wide_df_filtered.columns]\n",
    "        display(wide_df_filtered[available_display_cols].head())\n",
    "        \n",
    "    else:\n",
    "        print(\"‚úÖ Filtered wide dataset saved to file successfully\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in Example 5: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Base Table Column Selection\n",
    "\n",
    "This example demonstrates how to select specific columns from base tables (patient, hospitalization, adt) for memory efficiency and focused analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Features Demonstrated\n",
    "\n",
    "This notebook demonstrated the following key features of the pyCLIF wide dataset functionality:\n",
    "\n",
    "### üîß **Core Functionality**\n",
    "- **Auto-loading**: Tables are automatically loaded as needed\n",
    "- **Multi-table joining**: Seamless integration of patient, hospitalization, ADT, and optional tables\n",
    "- **Category-based pivoting**: Automatic pivoting of vitals, labs, medications, and assessments\n",
    "- **Time-based alignment**: Events are aligned by timestamp across all tables\n",
    "- **Base table column selection**: Choose specific columns from base tables for memory efficiency\n",
    "\n",
    "### üìä **Flexible Configuration**\n",
    "- **Sampling modes**: Random sampling or specific hospitalization targeting\n",
    "- **Category filters**: Specify which categories to include for each table type\n",
    "- **Base table filtering**: Select only needed columns from patient, hospitalization, and ADT tables\n",
    "- **Output formats**: DataFrame, CSV, or Parquet\n",
    "- **Save options**: In-memory analysis or file output\n",
    "\n",
    "### üìà **Analysis-Ready Structure**\n",
    "- **Day-based aggregation**: `day_number` and `hosp_id_day_key` for temporal analysis\n",
    "- **Complete patient context**: Demographics, hospitalization details, and clinical data\n",
    "- **Missing data handling**: Proper NaN handling for missing categories\n",
    "- **Time-series ready**: Event timestamps preserved for longitudinal analysis\n",
    "- **Memory efficient**: Reduced memory footprint with column selection\n",
    "\n",
    "### üéØ **Use Cases**\n",
    "- **Exploratory analysis**: Quick sampling for data exploration\n",
    "- **Targeted studies**: Focus on specific patient populations\n",
    "- **Comprehensive research**: Full datasets with all available data\n",
    "- **Real-time analysis**: In-memory processing for immediate insights\n",
    "- **Memory-constrained environments**: Efficient processing with column selection\n",
    "\n",
    "### üí° **New Feature: Base Table Column Selection**\n",
    "- **Memory efficiency**: Load only required columns from base tables\n",
    "- **Focused analysis**: Include only relevant demographics and timestamps\n",
    "- **Performance optimization**: Faster processing with fewer columns\n",
    "- **Flexible configuration**: Specify different column sets for different analyses\n",
    "\n",
    "**Example Usage:**\n",
    "```python\n",
    "base_columns = {\n",
    "    'patient': ['patient_id', 'age', 'sex', 'race'],\n",
    "    'hospitalization': ['hospitalization_id', 'patient_id', 'admit_dttm', 'discharge_dttm'],\n",
    "    'adt': ['hospitalization_id', 'in_dttm', 'out_dttm', 'location']\n",
    "}\n",
    "\n",
    "wide_df = clif.create_wide_dataset(\n",
    "    optional_tables=['vitals'],\n",
    "    base_table_columns=base_columns,\n",
    "    sample=True\n",
    ")\n",
    "```\n",
    "\n",
    "For more information, refer to the documentation at `docs/wide_dataset.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "if 'wide_df_memory' in locals() and wide_df_memory is not None:\n",
    "    print(\"üìä Creating visualizations for time-series analysis...\")\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('Wide Dataset Time-Series Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Plot 1: MAP over time for a single hospitalization\n",
    "    if 'map' in wide_df_memory.columns and wide_df_memory['map'].notna().sum() > 0:\n",
    "        # Get one hospitalization with MAP data\n",
    "        hosp_with_map = wide_df_memory[wide_df_memory['map'].notna()]['hospitalization_id'].iloc[0]\n",
    "        single_hosp = wide_df_memory[wide_df_memory['hospitalization_id'] == hosp_with_map].copy()\n",
    "        single_hosp = single_hosp.sort_values('event_time')\n",
    "        \n",
    "        axes[0, 0].plot(single_hosp['day_number'], single_hosp['map'], 'o-', linewidth=2, markersize=4)\n",
    "        axes[0, 0].set_title(f'MAP Over Time (Hospitalization: {hosp_with_map})')\n",
    "        axes[0, 0].set_xlabel('Hospital Day')\n",
    "        axes[0, 0].set_ylabel('MAP (mmHg)')\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "    else:\n",
    "        axes[0, 0].text(0.5, 0.5, 'No MAP data available', ha='center', va='center', transform=axes[0, 0].transAxes)\n",
    "        axes[0, 0].set_title('MAP Over Time')\n",
    "    \n",
    "    # Plot 2: Heart Rate distribution\n",
    "    if 'heart_rate' in wide_df_memory.columns and wide_df_memory['heart_rate'].notna().sum() > 0:\n",
    "        hr_data = wide_df_memory['heart_rate'].dropna()\n",
    "        axes[0, 1].hist(hr_data, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        axes[0, 1].set_title('Heart Rate Distribution')\n",
    "        axes[0, 1].set_xlabel('Heart Rate (bpm)')\n",
    "        axes[0, 1].set_ylabel('Frequency')\n",
    "        axes[0, 1].axvline(hr_data.mean(), color='red', linestyle='--', label=f'Mean: {hr_data.mean():.1f}')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "    else:\n",
    "        axes[0, 1].text(0.5, 0.5, 'No Heart Rate data available', ha='center', va='center', transform=axes[0, 1].transAxes)\n",
    "        axes[0, 1].set_title('Heart Rate Distribution')\n",
    "    \n",
    "    # Plot 3: Data availability by hospital day\n",
    "    if 'day_number' in wide_df_memory.columns:\n",
    "        day_data = wide_df_memory.groupby('day_number').size()\n",
    "        axes[1, 0].bar(day_data.index, day_data.values, alpha=0.7, color='lightgreen')\n",
    "        axes[1, 0].set_title('Number of Records by Hospital Day')\n",
    "        axes[1, 0].set_xlabel('Hospital Day')\n",
    "        axes[1, 0].set_ylabel('Number of Records')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "    else:\n",
    "        axes[1, 0].text(0.5, 0.5, 'No day number data available', ha='center', va='center', transform=axes[1, 0].transAxes)\n",
    "        axes[1, 0].set_title('Records by Hospital Day')\n",
    "    \n",
    "    # Plot 4: Data completeness heatmap\n",
    "    vital_cols = [col for col in ['map', 'heart_rate'] if col in wide_df_memory.columns]\n",
    "    if vital_cols and 'hospitalization_id' in wide_df_memory.columns:\n",
    "        # Create completeness matrix for top hospitalizations\n",
    "        top_hosps = wide_df_memory['hospitalization_id'].value_counts().head(10).index\n",
    "        completeness_matrix = []\n",
    "        \n",
    "        for hosp in top_hosps:\n",
    "            hosp_data = wide_df_memory[wide_df_memory['hospitalization_id'] == hosp]\n",
    "            completeness = [(hosp_data[col].notna().sum() / len(hosp_data)) * 100 for col in vital_cols]\n",
    "            completeness_matrix.append(completeness)\n",
    "        \n",
    "        if completeness_matrix:\n",
    "            im = axes[1, 1].imshow(completeness_matrix, cmap='RdYlGn', aspect='auto', vmin=0, vmax=100)\n",
    "            axes[1, 1].set_title('Data Completeness by Hospitalization (%)')\n",
    "            axes[1, 1].set_xlabel('Vital Signs')\n",
    "            axes[1, 1].set_ylabel('Hospitalizations (Top 10)')\n",
    "            axes[1, 1].set_xticks(range(len(vital_cols)))\n",
    "            axes[1, 1].set_xticklabels(vital_cols, rotation=45)\n",
    "            axes[1, 1].set_yticks(range(min(10, len(top_hosps))))\n",
    "            axes[1, 1].set_yticklabels([f\"{hosp[:8]}...\" for hosp in top_hosps[:10]])\n",
    "            \n",
    "            # Add colorbar\n",
    "            cbar = plt.colorbar(im, ax=axes[1, 1])\n",
    "            cbar.set_label('Completeness (%)')\n",
    "        else:\n",
    "            axes[1, 1].text(0.5, 0.5, 'Insufficient data for heatmap', ha='center', va='center', transform=axes[1, 1].transAxes)\n",
    "    else:\n",
    "        axes[1, 1].text(0.5, 0.5, 'No vital signs data available', ha='center', va='center', transform=axes[1, 1].transAxes)\n",
    "        axes[1, 1].set_title('Data Completeness Heatmap')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"No in-memory dataset available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "Let's summarize what we've accomplished and check for saved files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Wide Dataset Examples Complete ===\")\n",
    "print(f\"üìÅ Check the data directory {data_dir} for saved output files.\")\n",
    "\n",
    "# Check for saved files\n",
    "if os.path.exists(data_dir):\n",
    "    output_files = [\n",
    "        'sample_wide_dataset.parquet',\n",
    "        'targeted_encounters_wide.csv',\n",
    "        'comprehensive_wide_dataset.parquet'\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nüìã Generated Output Files:\")\n",
    "    for filename in output_files:\n",
    "        filepath = os.path.join(data_dir, filename)\n",
    "        if os.path.exists(filepath):\n",
    "            file_size = os.path.getsize(filepath) / (1024 * 1024)  # MB\n",
    "            print(f\"   ‚úÖ {filename} ({file_size:.1f} MB)\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå {filename} (not found)\")\n",
    "\n",
    "print(\"\\nüéâ Examples completed successfully!\")\n",
    "print(\"\\nüìö Next Steps:\")\n",
    "print(\"   1. Adapt these examples for your specific research questions\")\n",
    "print(\"   2. Experiment with different category filters\")\n",
    "print(\"   3. Try different sampling strategies\")\n",
    "print(\"   4. Integrate wide datasets into your analysis workflows\")\n",
    "print(\"   5. Create custom functions based on these patterns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Features Demonstrated\n",
    "\n",
    "This notebook demonstrated the following key features of the pyCLIF wide dataset functionality:\n",
    "\n",
    "### üîß **Core Functionality**\n",
    "- **Auto-loading**: Tables are automatically loaded as needed\n",
    "- **Multi-table joining**: Seamless integration of patient, hospitalization, ADT, and optional tables\n",
    "- **Category-based pivoting**: Automatic pivoting of vitals, labs, medications, and assessments\n",
    "- **Time-based alignment**: Events are aligned by timestamp across all tables\n",
    "\n",
    "### üìä **Flexible Configuration**\n",
    "- **Sampling modes**: Random sampling or specific hospitalization targeting\n",
    "- **Category filters**: Specify which categories to include for each table type\n",
    "- **Output formats**: DataFrame, CSV, or Parquet\n",
    "- **Save options**: In-memory analysis or file output\n",
    "\n",
    "### üìà **Analysis-Ready Structure**\n",
    "- **Day-based aggregation**: `day_number` and `hosp_id_day_key` for temporal analysis\n",
    "- **Complete patient context**: Demographics, hospitalization details, and clinical data\n",
    "- **Missing data handling**: Proper NaN handling for missing categories\n",
    "- **Time-series ready**: Event timestamps preserved for longitudinal analysis\n",
    "\n",
    "### üéØ **Use Cases**\n",
    "- **Exploratory analysis**: Quick sampling for data exploration\n",
    "- **Targeted studies**: Focus on specific patient populations\n",
    "- **Comprehensive research**: Full datasets with all available data\n",
    "- **Real-time analysis**: In-memory processing for immediate insights\n",
    "\n",
    "For more information, refer to the documentation at `docs/wide_dataset.md`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

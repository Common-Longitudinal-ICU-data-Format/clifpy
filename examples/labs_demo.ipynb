{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Step 0 â€” Environment setup and imports  \n",
    "# This cell brings in standard libraries and adds the project root to `sys.path`  \n",
    "# so that we can import the local `clifpy` package from within the notebook.\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from clifpy import Adt, Hospitalization, Labs, Patient, Position\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Step 1 â€” Load the Labs table  \n",
    "# The `Labs.from_file` helper reads the Parquet files, attaches the DataFrame to  \n",
    "# `labs.df`, and sets up logging & schema information automatically.\n",
    "labs = Labs.from_file(data_directory=\"/samplepath\", filetype=\"parquet\", timezone=\"UTC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Step 2 â€” Optional data wrangling  \n",
    "# 1. Convert timezone-aware datetime columns to your preferred zone.  \n",
    "# 2. Drop columns you no longer need (`lab_order_dttm`).  \n",
    "# 3. Display the first few rows to verify the changes.\n",
    "datetime_cols = labs.df.select_dtypes(include=[\"datetimetz\"]).columns\n",
    "labs.df[datetime_cols] = labs.df[datetime_cols].apply(lambda col: col.dt.tz_convert(\"America/New_York\"))\n",
    "labs.df = labs.df.drop(columns=['lab_order_dttm'])\n",
    "labs.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Step 3 â€” Quick table summary  \n",
    "# Produces a dictionary with counts, memory usage, missing-data metrics, and validity flag.\n",
    "labs.get_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Step 4 â€” Persist the summary to disk  \n",
    "# Saves the dictionary above to `output/summary_labs.json`.\n",
    "labs.save_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Step 5 â€” Run full validation suite  \n",
    "# Executes all schema and data-quality checks for the Labs table.\n",
    "labs.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Step 6 â€” Inspect validation errors (if any)\n",
    "for error in labs.errors:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Step 7 â€” Explore lab statistics by category  \n",
    "# Provides count, central-tendency, dispersion metrics, missingness, and unique-patient counts per lab variable.\n",
    "labs.get_lab_category_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Step 8 â€” Explore lab statistics by specimen type  \n",
    "# Similar to the previous cell but grouped by `lab_specimen_category`.\n",
    "labs.get_lab_specimen_stats()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
